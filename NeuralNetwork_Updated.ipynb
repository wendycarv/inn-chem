{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    IPython.notebook.save_checkpoint();\n    setInterval(function() {\n        IPython.notebook.save_checkpoint();\n        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n    }, 300000);\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "# Auto-save every 5 minutes\n",
    "display(Javascript('''\n",
    "    IPython.notebook.save_checkpoint();\n",
    "    setInterval(function() {\n",
    "        IPython.notebook.save_checkpoint();\n",
    "        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n",
    "    }, 300000);\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from cddd.inference import InferenceModel\n",
    "from cddd.preprocessing import preprocess_smiles\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smiles to Embedding via cddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created model\n",
      "spectra_and_embeddings_full.csv already exists. loading data... \n",
      "spectra shape:  (85506, 1801)\n",
      "embedded smiles shape:  (85506, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import and preprocess dataset\n",
    "\n",
    "input_csv = \"computed_spectra.csv\"\n",
    "output_csv = \"spectra_and_embeddings_full.csv\"\n",
    "row_num = 0\n",
    "\n",
    "# create an instance of the model\n",
    "inference_model = InferenceModel()\n",
    "print(\"created model\")\n",
    "\n",
    "# skip preprocessing if file already exists\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"{output_csv} already exists. loading data... \")\n",
    "\n",
    "    df = pd.read_csv(output_csv)\n",
    "    smiles_list = df[\"smiles\"].tolist() # FIX\n",
    "\n",
    "    spectra_array = df.iloc[:, 1:1802].values   # spectra columns\n",
    "    embedded_smiles = df.iloc[:, 1802:].values  # embedded SMILES columns\n",
    "\n",
    "    print(\"spectra shape: \", spectra_array.shape)\n",
    "    print(\"embedded smiles shape: \", embedded_smiles.shape)\n",
    "\n",
    "else:\n",
    "    print(\"Processing raw SMILES and spectra...\")\n",
    "\n",
    "    smiles_list = []\n",
    "    spectra_list = []\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        total_rows = sum(1 for _ in f) - 1  # minus 1 for header\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)  # e.g., [\"smiles\", \"spectrum_0\", ..., \"spectrum_1800\"]\n",
    "        for row in reader:\n",
    "            row_num += 1\n",
    "            if row_num % 1000 == 0:\n",
    "                print(f\"Processed {row_num}/{total_rows}\")\n",
    "            smiles = row[0].strip()\n",
    "            spectrum = [float(val) for val in row[1:]]\n",
    "            try:\n",
    "                smiles_list.append(smiles)\n",
    "                spectra_list.append(spectrum)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    spectra_array = np.array(spectra_list)  # shape (N, 1801)\n",
    "\n",
    "\n",
    "    # encode all SMILES into the continuous embedding --> size 512\n",
    "    print(\"encoding SMILES...\")\n",
    "    embedded_smiles = inference_model.seq_to_emb(smiles_list)  # shape (N, 512)\n",
    "    print(\"embedding shape:\", embedded_smiles.shape)\n",
    "\n",
    "    # combine all data: smiles + spectra + embeddings\n",
    "    combined_array = np.hstack((np.array(smiles_list).reshape(-1, 1), spectra_array, embedded_smiles))\n",
    "\n",
    "    # create headers\n",
    "    spectra_headers = [f\"spectrum_{i}\" for i in range(spectra_array.shape[1])]\n",
    "    embed_headers = [f\"emb_{i}\" for i in range(embedded_smiles.shape[1])]\n",
    "    headers = [\"smiles\"] + spectra_headers + embed_headers\n",
    "\n",
    "    # create DataFrame and save\n",
    "    combined_df = pd.DataFrame(combined_array, columns=headers)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"saved new file: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create a smiles list of 6000\\nsmiles_list = []\\n\\nwith open(\"computed_spectra.csv\", \"r\") as f:\\n    reader = csv.reader(f)\\n    next(reader)  # skip header line\\n    for i, row in enumerate(reader):\\n        if i >= 6000:\\n            break\\n        smiles = row[0].strip()\\n        try:\\n            smiles_list.append(smiles)\\n        except:\\n            continue\\n\\n# make instance of autoencoder model\\ninference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\\n\\n# embed the smiles\\n# get 512-dim CDDD embeddings\\nsmiles_embedding = inference_model.seq_to_emb(smiles_list)\\n\\n\\n# print example to see if it works\\nfor i in range(5):\\n    print(f\"SMILES: {smiles_list[i]}\") # full smiles\\n    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# create a smiles list of 6000\n",
    "smiles_list = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header line\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 6000:\n",
    "            break\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            smiles_list.append(smiles)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# make instance of autoencoder model\n",
    "inference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\n",
    "\n",
    "# embed the smiles\n",
    "# get 512-dim CDDD embeddings\n",
    "smiles_embedding = inference_model.seq_to_emb(smiles_list)\n",
    "\n",
    "\n",
    "# print example to see if it works\n",
    "for i in range(5):\n",
    "    print(f\"SMILES: {smiles_list[i]}\") # full smiles\n",
    "    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Spectra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized spectra shape: (85506, 1801)\n",
      "Sample normalized spectrum: [0.0086403  0.00853724 0.00871799 0.00868892 0.00868103 0.00868275\n",
      " 0.00859874 0.00842945 0.00839367 0.00825264]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "spec_len = 1801\n",
    "spectra_list = []\n",
    "\n",
    "# Load spectra from CSV\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header\n",
    "    for i, row in enumerate(reader):\n",
    "        #if i >= 6000:\n",
    "            #break\n",
    "        try:\n",
    "            spectrum = [float(x) for x in row[1:]]\n",
    "            if len(spectrum) == spec_len:\n",
    "                spectra_list.append(spectrum)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# convert to np array\n",
    "spectra_array = np.array(spectra_list)\n",
    "\n",
    "# normalize using minmax scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_spectra = scaler.fit_transform(spectra_array)\n",
    "\n",
    "# the input for the model\n",
    "X = normalized_spectra\n",
    "\n",
    "# check if it worked :)))\n",
    "print(\"Normalized spectra shape:\", X.shape)\n",
    "print(\"Sample normalized spectrum:\", X[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape: (85506, 1801), Y shape: (85506, 512)\n",
      "Train size: 59854 Test size: 12826 Val size: 12826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up X and Y\n",
    "X = np.array(normalized_spectra)\n",
    "Y = np.array(embedded_smiles)\n",
    "\n",
    "# fit to right length\n",
    "min_len = min(len(X), len(Y))\n",
    "X = X[:min_len]\n",
    "Y = Y[:min_len]\n",
    "\n",
    "# debug rqqq\n",
    "print(f\" shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "\n",
    "# train and temp split (val+test)\n",
    "X_train, X_temp, Y_train, Y_temp, smiles_train, smiles_temp = train_test_split(X, Y, smiles_list, test_size=0.3, random_state=42)\n",
    "\n",
    "# temp split into test and val\n",
    "X_val, X_test, Y_val, Y_test, smiles_val, smiles_test = train_test_split(\n",
    "    X_temp, Y_temp, smiles_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test), \"Val size:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpectraToSMILESDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# wrap train/test sets\n",
    "train_dataset = SpectraToSMILESDataset(X_train, Y_train)\n",
    "test_dataset = SpectraToSMILESDataset(X_test, Y_test)\n",
    "val_dataset = SpectraToSMILESDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SpectraToEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim=1801, output_dim=512, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SpectraToEmbedding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport torch.nn.functional as F\\n\\n# Optimizer\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\\n\\n# Scheduler (optional but helpful for long training)\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\\n\\ntest_losses = []\\ntrain_losses = []\\n# Hybrid loss function (MSE + Cosine)\\ndef hybrid_loss(y_pred, y_true):\\n    mse = F.mse_loss(y_pred, y_true)\\n    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\\n    return 0.5 * mse + 0.5 * cos\\n\\n# Training loop\\nnum_epochs = 200\\nfor epoch in range(num_epochs):\\n    model.train()\\n    total_loss = 0\\n    for X_batch, Y_batch in train_loader:\\n        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n        optimizer.zero_grad()\\n        Y_pred = model(X_batch)\\n\\n        loss = hybrid_loss(Y_pred, Y_batch)\\n\\n        loss.backward()\\n        optimizer.step()\\n        total_loss += loss.item()\\n\\n    train_losses.append(total_loss)\\n\\n    avg_loss = total_loss / len(train_loader)\\n    scheduler.step(avg_loss)\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n    model.eval()\\n    test_loss = 0\\n    with torch.no_grad():\\n        for X_batch, Y_batch in test_loader:\\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n            Y_pred = model(X_batch)\\n            test_loss += hybrid_loss(Y_pred, Y_batch)\\n\\n    test_losses.append(test_loss)\\n\\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Scheduler (optional but helpful for long training)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "# Hybrid loss function (MSE + Cosine)\n",
    "def hybrid_loss(y_pred, y_true):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\n",
    "    return 0.5 * mse + 0.5 * cos\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        loss = hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_loss)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            Y_pred = model(X_batch)\n",
    "            test_loss += hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train za Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss = 322.4453, Val Loss = 61.0085\n",
      "Epoch 2/200, Train Loss = 279.4316, Val Loss = 57.3850\n",
      "Epoch 3/200, Train Loss = 266.5187, Val Loss = 56.1228\n",
      "Epoch 4/200, Train Loss = 259.4852, Val Loss = 54.5580\n",
      "Epoch 5/200, Train Loss = 251.9251, Val Loss = 53.5890\n",
      "Epoch 6/200, Train Loss = 247.4638, Val Loss = 51.3334\n",
      "Epoch 7/200, Train Loss = 244.0924, Val Loss = 51.5787\n",
      "Epoch 8/200, Train Loss = 241.2281, Val Loss = 49.9951\n",
      "Epoch 9/200, Train Loss = 238.0727, Val Loss = 49.9948\n",
      "Epoch 10/200, Train Loss = 235.1552, Val Loss = 49.1086\n",
      "Epoch 11/200, Train Loss = 233.1146, Val Loss = 48.8800\n",
      "Epoch 12/200, Train Loss = 231.0358, Val Loss = 48.3319\n",
      "Epoch 13/200, Train Loss = 229.6614, Val Loss = 48.0364\n",
      "Epoch 14/200, Train Loss = 226.6851, Val Loss = 48.5891\n",
      "Epoch 15/200, Train Loss = 225.4883, Val Loss = 47.5588\n",
      "Epoch 16/200, Train Loss = 226.1094, Val Loss = 47.9050\n",
      "Epoch 17/200, Train Loss = 222.7096, Val Loss = 46.9630\n",
      "Epoch 18/200, Train Loss = 222.2019, Val Loss = 49.0319\n",
      "Epoch 19/200, Train Loss = 220.8790, Val Loss = 48.5413\n",
      "Epoch 20/200, Train Loss = 223.2171, Val Loss = 46.9876\n",
      "Epoch 21/200, Train Loss = 220.4406, Val Loss = 48.6315\n",
      "Epoch 22/200, Train Loss = 218.1014, Val Loss = 47.6067\n",
      "Epoch    23: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 23/200, Train Loss = 218.9609, Val Loss = 47.1963\n",
      "Epoch 24/200, Train Loss = 215.0517, Val Loss = 45.9137\n",
      "Epoch 25/200, Train Loss = 212.1515, Val Loss = 45.7364\n",
      "Epoch 26/200, Train Loss = 211.2828, Val Loss = 46.6634\n",
      "Epoch 27/200, Train Loss = 209.8435, Val Loss = 45.7701\n",
      "Epoch 28/200, Train Loss = 209.6959, Val Loss = 45.6291\n",
      "Epoch 29/200, Train Loss = 208.2991, Val Loss = 45.3755\n",
      "Epoch 30/200, Train Loss = 208.2756, Val Loss = 45.3830\n",
      "Epoch 31/200, Train Loss = 207.7601, Val Loss = 46.4375\n",
      "Epoch 32/200, Train Loss = 207.3430, Val Loss = 45.5526\n",
      "Epoch 33/200, Train Loss = 206.6714, Val Loss = 45.4283\n",
      "Epoch 34/200, Train Loss = 206.3075, Val Loss = 45.5796\n",
      "Epoch 35/200, Train Loss = 205.6912, Val Loss = 45.0651\n",
      "Epoch 36/200, Train Loss = 205.1537, Val Loss = 45.3813\n",
      "Epoch 37/200, Train Loss = 204.6175, Val Loss = 45.0636\n",
      "Epoch 38/200, Train Loss = 204.8635, Val Loss = 45.6754\n",
      "Epoch 39/200, Train Loss = 204.6895, Val Loss = 45.1476\n",
      "Epoch 40/200, Train Loss = 204.2131, Val Loss = 45.8534\n",
      "Epoch    41: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 41/200, Train Loss = 204.1082, Val Loss = 45.1506\n",
      "Epoch 42/200, Train Loss = 201.4187, Val Loss = 44.8986\n",
      "Epoch 43/200, Train Loss = 200.6461, Val Loss = 44.6834\n",
      "Epoch 44/200, Train Loss = 199.9157, Val Loss = 44.3880\n",
      "Epoch 45/200, Train Loss = 200.0156, Val Loss = 45.1025\n",
      "Epoch 46/200, Train Loss = 199.4444, Val Loss = 46.5134\n",
      "Epoch 47/200, Train Loss = 199.3053, Val Loss = 47.6092\n",
      "Epoch 48/200, Train Loss = 199.0677, Val Loss = 44.7986\n",
      "Epoch 49/200, Train Loss = 198.8946, Val Loss = 44.5678\n",
      "Epoch    50: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 50/200, Train Loss = 198.2986, Val Loss = 47.2060\n",
      "Epoch 51/200, Train Loss = 197.2392, Val Loss = 44.6478\n",
      "Epoch 52/200, Train Loss = 197.2662, Val Loss = 45.8149\n",
      "Epoch 53/200, Train Loss = 196.8472, Val Loss = 44.4128\n",
      "Epoch 54/200, Train Loss = 196.6732, Val Loss = 46.2423\n",
      "Early stopping triggered at epoch 54\n",
      "Best model restored.\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# scheduler: reduce LR by factor=0.5 if no improvement in 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CosineEmbeddingLoss()\n",
    "\n",
    "# to track losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# early stopping params\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "wait = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        loss = loss_fn(Y_pred, Y_batch, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            Y_pred = model(X_batch)\n",
    "            target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "            val_loss += loss_fn(Y_pred, Y_batch, target).item()\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_loss - 1e-4:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Best model restored.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 46.0859\n"
     ]
    }
   ],
   "source": [
    "# remove any warnings\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# eval\n",
    "model.eval()\n",
    "predicted_embeddings = []\n",
    "test_losses = []\n",
    "test_loss = 0\n",
    "\n",
    "# pred embeddings from test spectra\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        pred = model(X_batch)\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        test_loss += loss_fn(pred, _, target).item()\n",
    "        predicted_embeddings.append(pred)\n",
    "    test_losses.append(test_loss)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12826\n",
      "INFO:tensorflow:Restoring parameters from /home/undergrad/2026/wcarvalh/Documents/uvsq/cddd/cddd/data/default_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "predicted_embeddings = torch.cat(predicted_embeddings, dim=0).cpu().numpy()\n",
    "\n",
    "# decode embeddings\n",
    "print(len(predicted_embeddings))\n",
    "\n",
    "pred_smiles = inference_model.emb_to_seq(predicted_embeddings)\n",
    "\n",
    "print(\"Finished decoding predictions\")\n",
    "\n",
    "# eval metrics\n",
    "tanimoto_scores = []\n",
    "valid_count = 0\n",
    "exact_match_count = 0\n",
    "total = len(smiles_test)\n",
    "\n",
    "for pred, true in zip(pred_smiles, smiles_test):\n",
    "    try:\n",
    "        pred_mol = Chem.MolFromSmiles(pred)\n",
    "        true_mol = Chem.MolFromSmiles(true)\n",
    "        \n",
    "        # validity check\n",
    "        if pred_mol is not None:\n",
    "            valid_count += 1\n",
    "\n",
    "        # exact match?\n",
    "        if pred == true:\n",
    "            exact_match_count += 1\n",
    "\n",
    "        # tanimoto sim\n",
    "        if pred_mol is not None and true_mol is not None:\n",
    "            fp_pred = AllChem.GetMorganFingerprintAsBitVect(pred_mol, 2, nBits=2048)\n",
    "            fp_true = AllChem.GetMorganFingerprintAsBitVect(true_mol, 2, nBits=2048)\n",
    "            similarity = DataStructs.TanimotoSimilarity(fp_pred, fp_true)\n",
    "            tanimoto_scores.append(similarity)\n",
    "        else:\n",
    "            tanimoto_scores.append(0.0)\n",
    "    except:\n",
    "        tanimoto_scores.append(0.0)\n",
    "\n",
    "# print final metrics\n",
    "valid_percent = 100 * valid_count / total\n",
    "exact_match_percent = 100 * exact_match_count / total\n",
    "avg_tanimoto = np.mean(tanimoto_scores)\n",
    "\n",
    "print(f\"Average Tanimoto Similarity: {avg_tanimoto:.4f}\")\n",
    "print(f\"Valid SMILES: {valid_count}/{total} ({valid_percent:.2f}%)\")\n",
    "print(f\"Exact Matches: {exact_match_count}/{total} ({exact_match_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"True_SMILES\": smiles_test,\n",
    "    \"Predicted_SMILES\": pred_smiles\n",
    "})\n",
    "\n",
    "# save to CSV\n",
    "df.to_csv(\"smiles_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
