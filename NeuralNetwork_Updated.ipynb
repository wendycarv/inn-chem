{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    IPython.notebook.save_checkpoint();\n    setInterval(function() {\n        IPython.notebook.save_checkpoint();\n        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n    }, 300000);\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "# Auto-save every 5 minutes\n",
    "display(Javascript('''\n",
    "    IPython.notebook.save_checkpoint();\n",
    "    setInterval(function() {\n",
    "        IPython.notebook.save_checkpoint();\n",
    "        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n",
    "    }, 300000);\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from cddd.inference import InferenceModel\n",
    "from cddd.preprocessing import preprocess_smiles\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smiles to Embedding via cddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created model\n",
      "spectra_and_embeddings_full.csv already exists. loading data... \n",
      "spectra shape:  (85506, 1801)\n",
      "embedded smiles shape:  (85506, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import and preprocess dataset\n",
    "\n",
    "input_csv = \"computed_spectra.csv\"\n",
    "output_csv = \"spectra_and_embeddings_full.csv\"\n",
    "row_num = 0\n",
    "\n",
    "# create an instance of the model\n",
    "inference_model = InferenceModel()\n",
    "print(\"created model\")\n",
    "\n",
    "# skip preprocessing if file already exists\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"{output_csv} already exists. loading data... \")\n",
    "\n",
    "    df = pd.read_csv(output_csv)\n",
    "    smiles_list = df[\"smiles\"].tolist() # FIX\n",
    "\n",
    "    spectra_array = df.iloc[:, 1:1802].values   # spectra columns\n",
    "    embedded_smiles = df.iloc[:, 1802:].values  # embedded SMILES columns\n",
    "\n",
    "    print(\"spectra shape: \", spectra_array.shape)\n",
    "    print(\"embedded smiles shape: \", embedded_smiles.shape)\n",
    "\n",
    "else:\n",
    "    print(\"Processing raw SMILES and spectra...\")\n",
    "\n",
    "    smiles_list = []\n",
    "    spectra_list = []\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        total_rows = sum(1 for _ in f) - 1  # minus 1 for header\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)  # e.g., [\"smiles\", \"spectrum_0\", ..., \"spectrum_1800\"]\n",
    "        for row in reader:\n",
    "            row_num += 1\n",
    "            if row_num % 1000 == 0:\n",
    "                print(f\"Processed {row_num}/{total_rows}\")\n",
    "            smiles = row[0].strip()\n",
    "            spectrum = [float(val) for val in row[1:]]\n",
    "            try:\n",
    "                smiles_list.append(smiles)\n",
    "                spectra_list.append(spectrum)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    spectra_array = np.array(spectra_list)  # shape (N, 1801)\n",
    "\n",
    "\n",
    "    # encode all SMILES into the continuous embedding --> size 512\n",
    "    print(\"encoding SMILES...\")\n",
    "    embedded_smiles = inference_model.seq_to_emb(smiles_list)  # shape (N, 512)\n",
    "    print(\"embedding shape:\", embedded_smiles.shape)\n",
    "\n",
    "    # combine all data: smiles + spectra + embeddings\n",
    "    combined_array = np.hstack((np.array(smiles_list).reshape(-1, 1), spectra_array, embedded_smiles))\n",
    "\n",
    "    # create headers\n",
    "    spectra_headers = [f\"spectrum_{i}\" for i in range(spectra_array.shape[1])]\n",
    "    embed_headers = [f\"emb_{i}\" for i in range(embedded_smiles.shape[1])]\n",
    "    headers = [\"smiles\"] + spectra_headers + embed_headers\n",
    "\n",
    "    # create DataFrame and save\n",
    "    combined_df = pd.DataFrame(combined_array, columns=headers)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"saved new file: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create a smiles list of 6000\\nsmiles_list = []\\n\\nwith open(\"computed_spectra.csv\", \"r\") as f:\\n    reader = csv.reader(f)\\n    next(reader)  # skip header line\\n    for i, row in enumerate(reader):\\n        if i >= 6000:\\n            break\\n        smiles = row[0].strip()\\n        try:\\n            smiles_list.append(smiles)\\n        except:\\n            continue\\n\\n# make instance of autoencoder model\\ninference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\\n\\n# embed the smiles\\n# get 512-dim CDDD embeddings\\nsmiles_embedding = inference_model.seq_to_emb(smiles_list)\\n\\n\\n# print example to see if it works\\nfor i in range(5):\\n    print(f\"SMILES: {smiles_list[i]}\") # full smiles\\n    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# create a smiles list of 6000\n",
    "smiles_list = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header line\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 6000:\n",
    "            break\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            smiles_list.append(smiles)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# make instance of autoencoder model\n",
    "inference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\n",
    "\n",
    "# embed the smiles\n",
    "# get 512-dim CDDD embeddings\n",
    "smiles_embedding = inference_model.seq_to_emb(smiles_list)\n",
    "\n",
    "\n",
    "# print example to see if it works\n",
    "for i in range(5):\n",
    "    print(f\"SMILES: {smiles_list[i]}\") # full smiles\n",
    "    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Spectra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized spectra shape: (85506, 1801)\n",
      "Sample normalized spectrum: [0.0086403  0.00853724 0.00871799 0.00868892 0.00868103 0.00868275\n",
      " 0.00859874 0.00842945 0.00839367 0.00825264]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "spec_len = 1801\n",
    "spectra_list = []\n",
    "\n",
    "# Load spectra from CSV\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header\n",
    "    for i, row in enumerate(reader):\n",
    "        #if i >= 6000:\n",
    "            #break\n",
    "        try:\n",
    "            spectrum = [float(x) for x in row[1:]]\n",
    "            if len(spectrum) == spec_len:\n",
    "                spectra_list.append(spectrum)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# convert to np array\n",
    "spectra_array = np.array(spectra_list)\n",
    "\n",
    "# normalize using minmax scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_spectra = scaler.fit_transform(spectra_array)\n",
    "\n",
    "# the input for the model\n",
    "X = normalized_spectra\n",
    "\n",
    "# check if it worked :)))\n",
    "print(\"Normalized spectra shape:\", X.shape)\n",
    "print(\"Sample normalized spectrum:\", X[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape: (85506, 1801), Y shape: (85506, 512)\n",
      "Train size: 59854 Test size: 12826 Val size: 12826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up X and Y\n",
    "X = np.array(normalized_spectra)\n",
    "Y = np.array(embedded_smiles)\n",
    "\n",
    "# fit to right length\n",
    "min_len = min(len(X), len(Y))\n",
    "X = X[:min_len]\n",
    "Y = Y[:min_len]\n",
    "\n",
    "# debug rqqq\n",
    "print(f\" shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "\n",
    "# train and temp split (val+test)\n",
    "X_train, X_temp, Y_train, Y_temp, smiles_train, smiles_temp = train_test_split(X, Y, smiles_list, test_size=0.3, random_state=42)\n",
    "\n",
    "# temp split into test and val\n",
    "X_val, X_test, Y_val, Y_test, smiles_val, smiles_test = train_test_split(\n",
    "    X_temp, Y_temp, smiles_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test), \"Val size:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpectraToSMILESDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# wrap train/test sets\n",
    "train_dataset = SpectraToSMILESDataset(X_train, Y_train)\n",
    "test_dataset = SpectraToSMILESDataset(X_test, Y_test)\n",
    "val_dataset = SpectraToSMILESDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SpectraToEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim=1801, output_dim=512, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SpectraToEmbedding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport torch.nn.functional as F\\n\\n# Optimizer\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\\n\\n# Scheduler (optional but helpful for long training)\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\\n\\ntest_losses = []\\ntrain_losses = []\\n# Hybrid loss function (MSE + Cosine)\\ndef hybrid_loss(y_pred, y_true):\\n    mse = F.mse_loss(y_pred, y_true)\\n    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\\n    return 0.5 * mse + 0.5 * cos\\n\\n# Training loop\\nnum_epochs = 200\\nfor epoch in range(num_epochs):\\n    model.train()\\n    total_loss = 0\\n    for X_batch, Y_batch in train_loader:\\n        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n        optimizer.zero_grad()\\n        Y_pred = model(X_batch)\\n\\n        loss = hybrid_loss(Y_pred, Y_batch)\\n\\n        loss.backward()\\n        optimizer.step()\\n        total_loss += loss.item()\\n\\n    train_losses.append(total_loss)\\n\\n    avg_loss = total_loss / len(train_loader)\\n    scheduler.step(avg_loss)\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n    model.eval()\\n    test_loss = 0\\n    with torch.no_grad():\\n        for X_batch, Y_batch in test_loader:\\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n            Y_pred = model(X_batch)\\n            test_loss += hybrid_loss(Y_pred, Y_batch)\\n\\n    test_losses.append(test_loss)\\n\\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Scheduler (optional but helpful for long training)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "# Hybrid loss function (MSE + Cosine)\n",
    "def hybrid_loss(y_pred, y_true):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\n",
    "    return 0.5 * mse + 0.5 * cos\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        loss = hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_loss)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            Y_pred = model(X_batch)\n",
    "            test_loss += hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train za Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss = 322.4152, Val Loss = 60.2390\n",
      "Epoch 2/200, Train Loss = 281.6196, Val Loss = 57.2055\n",
      "Epoch 3/200, Train Loss = 267.7411, Val Loss = 56.2496\n",
      "Epoch 4/200, Train Loss = 259.7954, Val Loss = 53.6468\n",
      "Epoch 5/200, Train Loss = 254.2832, Val Loss = 52.8165\n",
      "Epoch 6/200, Train Loss = 250.1929, Val Loss = 51.3286\n",
      "Epoch 7/200, Train Loss = 245.6813, Val Loss = 51.2621\n",
      "Epoch 8/200, Train Loss = 243.9825, Val Loss = 50.2648\n",
      "Epoch 9/200, Train Loss = 239.6026, Val Loss = 52.3064\n",
      "Epoch 10/200, Train Loss = 237.0218, Val Loss = 50.2293\n",
      "Epoch 11/200, Train Loss = 234.4197, Val Loss = 48.9331\n",
      "Epoch 12/200, Train Loss = 232.6609, Val Loss = 49.6252\n",
      "Epoch 13/200, Train Loss = 230.6438, Val Loss = 49.0860\n",
      "Epoch 14/200, Train Loss = 230.8674, Val Loss = 48.2214\n",
      "Epoch 15/200, Train Loss = 228.3494, Val Loss = 47.8061\n",
      "Epoch 16/200, Train Loss = 226.7407, Val Loss = 48.1022\n",
      "Epoch 17/200, Train Loss = 225.6775, Val Loss = 47.8462\n",
      "Epoch 18/200, Train Loss = 223.5014, Val Loss = 47.2364\n",
      "Epoch 19/200, Train Loss = 224.7132, Val Loss = 46.9889\n",
      "Epoch 20/200, Train Loss = 222.2152, Val Loss = 49.0346\n",
      "Epoch 21/200, Train Loss = 221.5391, Val Loss = 46.8523\n",
      "Epoch 22/200, Train Loss = 220.2293, Val Loss = 46.8357\n",
      "Epoch 23/200, Train Loss = 220.9144, Val Loss = 47.0401\n",
      "Epoch 24/200, Train Loss = 218.0867, Val Loss = 48.0335\n",
      "Epoch 25/200, Train Loss = 217.7958, Val Loss = 47.2794\n",
      "Epoch 26/200, Train Loss = 217.5230, Val Loss = 46.7020\n",
      "Epoch 27/200, Train Loss = 221.7311, Val Loss = 48.9688\n",
      "Epoch 28/200, Train Loss = 215.7687, Val Loss = 46.3606\n",
      "Epoch 29/200, Train Loss = 216.4421, Val Loss = 46.4160\n",
      "Epoch 30/200, Train Loss = 214.8349, Val Loss = 46.1640\n",
      "Epoch 31/200, Train Loss = 215.2940, Val Loss = 46.0136\n",
      "Epoch 32/200, Train Loss = 214.4588, Val Loss = 46.0849\n",
      "Epoch 33/200, Train Loss = 212.6382, Val Loss = 47.2001\n",
      "Epoch 34/200, Train Loss = 212.4633, Val Loss = 46.1607\n",
      "Epoch 35/200, Train Loss = 212.3121, Val Loss = 46.2087\n",
      "Epoch 36/200, Train Loss = 211.8818, Val Loss = 46.9028\n",
      "Epoch 37/200, Train Loss = 211.9418, Val Loss = 45.8326\n",
      "Epoch 38/200, Train Loss = 210.9921, Val Loss = 45.7446\n",
      "Epoch 39/200, Train Loss = 210.4288, Val Loss = 45.8640\n",
      "Epoch 40/200, Train Loss = 208.6395, Val Loss = 45.7608\n",
      "Epoch 41/200, Train Loss = 208.7334, Val Loss = 45.6120\n",
      "Epoch 42/200, Train Loss = 209.4591, Val Loss = 46.7907\n",
      "Epoch 43/200, Train Loss = 210.4526, Val Loss = 45.6917\n",
      "Epoch 44/200, Train Loss = 208.7539, Val Loss = 45.4436\n",
      "Epoch 45/200, Train Loss = 210.4491, Val Loss = 45.7771\n",
      "Epoch 46/200, Train Loss = 207.5761, Val Loss = 45.1822\n",
      "Epoch 47/200, Train Loss = 208.8399, Val Loss = 45.2958\n",
      "Epoch 48/200, Train Loss = 208.4271, Val Loss = 48.0108\n",
      "Epoch 49/200, Train Loss = 208.7723, Val Loss = 45.3327\n",
      "Epoch 50/200, Train Loss = 207.1527, Val Loss = 45.2229\n",
      "Epoch 51/200, Train Loss = 206.4030, Val Loss = 45.6303\n",
      "Epoch    52: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 52/200, Train Loss = 205.5779, Val Loss = 45.4048\n",
      "Epoch 53/200, Train Loss = 202.8801, Val Loss = 44.7682\n",
      "Epoch 54/200, Train Loss = 201.2418, Val Loss = 44.6261\n",
      "Epoch 55/200, Train Loss = 201.6825, Val Loss = 44.6668\n",
      "Epoch 56/200, Train Loss = 200.7083, Val Loss = 44.5992\n",
      "Epoch 57/200, Train Loss = 199.8471, Val Loss = 44.6792\n",
      "Epoch 58/200, Train Loss = 199.2146, Val Loss = 44.8944\n",
      "Epoch 59/200, Train Loss = 198.7690, Val Loss = 44.9892\n",
      "Epoch 60/200, Train Loss = 199.3761, Val Loss = 44.4832\n",
      "Epoch 61/200, Train Loss = 198.9487, Val Loss = 44.7505\n",
      "Epoch 62/200, Train Loss = 198.3313, Val Loss = 44.5574\n",
      "Epoch 63/200, Train Loss = 198.2532, Val Loss = 45.6534\n",
      "Epoch 64/200, Train Loss = 198.2174, Val Loss = 44.4879\n",
      "Epoch 65/200, Train Loss = 197.9393, Val Loss = 45.1742\n",
      "Epoch    66: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 66/200, Train Loss = 198.1465, Val Loss = 46.1367\n",
      "Epoch 67/200, Train Loss = 195.8514, Val Loss = 44.3884\n",
      "Epoch 68/200, Train Loss = 195.2900, Val Loss = 44.0983\n",
      "Epoch 69/200, Train Loss = 195.0477, Val Loss = 44.2857\n",
      "Epoch 70/200, Train Loss = 194.7094, Val Loss = 44.1502\n",
      "Epoch 71/200, Train Loss = 194.6746, Val Loss = 43.8848\n",
      "Epoch 72/200, Train Loss = 194.0693, Val Loss = 44.0407\n",
      "Epoch 73/200, Train Loss = 194.6127, Val Loss = 44.1199\n",
      "Epoch 74/200, Train Loss = 193.9829, Val Loss = 44.1370\n",
      "Epoch 75/200, Train Loss = 193.7641, Val Loss = 44.0628\n",
      "Epoch 76/200, Train Loss = 193.7588, Val Loss = 44.2485\n",
      "Epoch    77: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 77/200, Train Loss = 193.5111, Val Loss = 44.5289\n",
      "Epoch 78/200, Train Loss = 192.7155, Val Loss = 43.9948\n",
      "Epoch 79/200, Train Loss = 192.5894, Val Loss = 44.1038\n",
      "Epoch 80/200, Train Loss = 192.2862, Val Loss = 43.9355\n",
      "Epoch 81/200, Train Loss = 192.1569, Val Loss = 44.2354\n",
      "Early stopping triggered at epoch 81\n",
      "Best model restored.\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# scheduler: reduce LR by factor=0.5 if no improvement in 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CosineEmbeddingLoss()\n",
    "\n",
    "# to track losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# early stopping params\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "wait = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        loss = loss_fn(Y_pred, Y_batch, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            Y_pred = model(X_batch)\n",
    "            target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "            val_loss += loss_fn(Y_pred, Y_batch, target).item()\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_loss - 1e-4:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Best model restored.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3c25949ce717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredicted_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# remove any warnings\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# eval\n",
    "model.eval()\n",
    "predicted_embeddings = []\n",
    "test_loss = 0\n",
    "\n",
    "# pred embeddings from test spectra\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        pred = model(X_batch)\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        test_loss += loss_fn(pred, Y_batch, target).item()\n",
    "        predicted_embeddings.append(pred)\n",
    "\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_embeddings = torch.cat(predicted_embeddings, dim=0).cpu().numpy()\n",
    "\n",
    "# decode embeddings\n",
    "print(len(predicted_embeddings))\n",
    "\n",
    "pred_smiles = inference_model.emb_to_seq(predicted_embeddings)\n",
    "\n",
    "print(\"Finished decoding predictions\")\n",
    "\n",
    "# eval metrics\n",
    "tanimoto_scores = []\n",
    "valid_count = 0\n",
    "exact_match_count = 0\n",
    "total = len(smiles_test)\n",
    "\n",
    "for pred, true in zip(pred_smiles, smiles_test):\n",
    "    try:\n",
    "        pred_mol = Chem.MolFromSmiles(pred)\n",
    "        true_mol = Chem.MolFromSmiles(true)\n",
    "        \n",
    "        # validity check\n",
    "        if pred_mol is not None:\n",
    "            valid_count += 1\n",
    "\n",
    "        # exact match?\n",
    "        if pred == true:\n",
    "            exact_match_count += 1\n",
    "\n",
    "        # tanimoto sim\n",
    "        if pred_mol is not None and true_mol is not None:\n",
    "            fp_pred = AllChem.GetMorganFingerprintAsBitVect(pred_mol, 2, nBits=2048)\n",
    "            fp_true = AllChem.GetMorganFingerprintAsBitVect(true_mol, 2, nBits=2048)\n",
    "            similarity = DataStructs.TanimotoSimilarity(fp_pred, fp_true)\n",
    "            tanimoto_scores.append(similarity)\n",
    "        else:\n",
    "            tanimoto_scores.append(0.0)\n",
    "    except:\n",
    "        tanimoto_scores.append(0.0)\n",
    "\n",
    "# print final metrics\n",
    "valid_percent = 100 * valid_count / total\n",
    "exact_match_percent = 100 * exact_match_count / total\n",
    "avg_tanimoto = np.mean(tanimoto_scores)\n",
    "\n",
    "print(f\"Average Tanimoto Similarity: {avg_tanimoto:.4f}\")\n",
    "print(f\"Valid SMILES: {valid_count}/{total} ({valid_percent:.2f}%)\")\n",
    "print(f\"Exact Matches: {exact_match_count}/{total} ({exact_match_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"True_SMILES\": smiles_test,\n",
    "    \"Predicted_SMILES\": pred_smiles\n",
    "})\n",
    "\n",
    "# save to CSV\n",
    "df.to_csv(\"smiles_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
