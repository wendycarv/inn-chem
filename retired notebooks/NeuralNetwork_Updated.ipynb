{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    IPython.notebook.save_checkpoint();\n    setInterval(function() {\n        IPython.notebook.save_checkpoint();\n        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n    }, 300000);\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "# Auto-save every 5 minutes\n",
    "display(Javascript('''\n",
    "    IPython.notebook.save_checkpoint();\n",
    "    setInterval(function() {\n",
    "        IPython.notebook.save_checkpoint();\n",
    "        console.log(\"Auto-saved notebook at \" + new Date().toLocaleTimeString());\n",
    "    }, 300000);\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "from cddd.inference import InferenceModel\n",
    "from cddd.preprocessing import preprocess_smiles\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smiles to Embedding via cddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import and preprocess dataset\n",
    "\n",
    "input_csv = \"computed_spectra.csv\"\n",
    "output_csv = \"spectra_and_embeddings_full.csv\"\n",
    "row_num = 0\n",
    "\n",
    "# create an instance of the model\n",
    "inference_model = InferenceModel()\n",
    "print(\"created model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectra_and_embeddings_full.csv already exists. loading data... \n",
      "spectra shape:  (85506, 1801)\n",
      "embedded smiles shape:  (85506, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# skip preprocessing if file already exists\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"{output_csv} already exists. loading data... \")\n",
    "\n",
    "    df = pd.read_csv(output_csv)\n",
    "    smiles_list = df[\"smiles\"].tolist() # FIX\n",
    "\n",
    "    spectra_array = df.iloc[:, 1:1802].values   # spectra columns\n",
    "    embedded_smiles = df.iloc[:, 1802:].values  # embedded SMILES columns\n",
    "\n",
    "    print(\"spectra shape: \", spectra_array.shape)\n",
    "    print(\"embedded smiles shape: \", embedded_smiles.shape)\n",
    "\n",
    "else:\n",
    "    print(\"Processing raw SMILES and spectra...\")\n",
    "\n",
    "    smiles_list = []\n",
    "    spectra_list = []\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        total_rows = sum(1 for _ in f) - 1  # minus 1 for header\n",
    "\n",
    "    with open(input_csv, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)  # e.g., [\"smiles\", \"spectrum_0\", ..., \"spectrum_1800\"]\n",
    "        for row in reader:\n",
    "            row_num += 1\n",
    "            if row_num % 1000 == 0:\n",
    "                print(f\"Processed {row_num}/{total_rows}\")\n",
    "            smiles = row[0].strip()\n",
    "            spectrum = [float(val) for val in row[1:]]\n",
    "            try:\n",
    "                smiles_list.append(smiles)\n",
    "                spectra_list.append(spectrum)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    spectra_array = np.array(spectra_list)  # shape (N, 1801)\n",
    "\n",
    "\n",
    "    # encode all SMILES into the continuous embedding --> size 512\n",
    "    print(\"encoding SMILES...\")\n",
    "    embedded_smiles = inference_model.seq_to_emb(smiles_list)  # shape (N, 512)\n",
    "    print(\"embedding shape:\", embedded_smiles.shape)\n",
    "\n",
    "    # combine all data: smiles + spectra + embeddings\n",
    "    combined_array = np.hstack((np.array(smiles_list).reshape(-1, 1), spectra_array, embedded_smiles))\n",
    "\n",
    "    # create headers\n",
    "    spectra_headers = [f\"spectrum_{i}\" for i in range(spectra_array.shape[1])]\n",
    "    embed_headers = [f\"emb_{i}\" for i in range(embedded_smiles.shape[1])]\n",
    "    headers = [\"smiles\"] + spectra_headers + embed_headers\n",
    "\n",
    "    # create DataFrame and save\n",
    "    combined_df = pd.DataFrame(combined_array, columns=headers)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"saved new file: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create a smiles list of 6000\\nsmiles_list = []\\n\\nwith open(\"computed_spectra.csv\", \"r\") as f:\\n    reader = csv.reader(f)\\n    next(reader)  # skip header line\\n    for i, row in enumerate(reader):\\n        if i >= 6000:\\n            break\\n        smiles = row[0].strip()\\n        try:\\n            smiles_list.append(smiles)\\n        except:\\n            continue\\n\\n# make instance of autoencoder model\\ninference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\\n\\n# embed the smiles\\n# get 512-dim CDDD embeddings\\nsmiles_embedding = inference_model.seq_to_emb(smiles_list)\\n\\n\\n# print example to see if it works\\nfor i in range(5):\\n    print(f\"SMILES: {smiles_list[i]}\") # full smiles\\n    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# create a smiles list of 6000\n",
    "smiles_list = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header line\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 6000:\n",
    "            break\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            smiles_list.append(smiles)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# make instance of autoencoder model\n",
    "inference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\n",
    "\n",
    "# embed the smiles\n",
    "# get 512-dim CDDD embeddings\n",
    "smiles_embedding = inference_model.seq_to_emb(smiles_list)\n",
    "\n",
    "\n",
    "# print example to see if it works\n",
    "for i in range(5):\n",
    "    print(f\"SMILES: {smiles_list[i]}\") # full smiles\n",
    "    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Spectra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized spectra shape: (85506, 1801)\n",
      "Sample normalized spectrum: [0.0086403  0.00853724 0.00871799 0.00868892 0.00868103 0.00868275\n",
      " 0.00859874 0.00842945 0.00839367 0.00825264]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "spec_len = 1801\n",
    "spectra_list = []\n",
    "\n",
    "# Load spectra from CSV\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header\n",
    "    for i, row in enumerate(reader):\n",
    "        #if i >= 6000:\n",
    "            #break\n",
    "        try:\n",
    "            spectrum = [float(x) for x in row[1:]]\n",
    "            if len(spectrum) == spec_len:\n",
    "                spectra_list.append(spectrum)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# convert to np array\n",
    "spectra_array = np.array(spectra_list)\n",
    "\n",
    "# normalize using minmax scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_spectra = scaler.fit_transform(spectra_array)\n",
    "\n",
    "# the input for the model\n",
    "X = normalized_spectra\n",
    "\n",
    "# check if it worked :)))\n",
    "print(\"Normalized spectra shape:\", X.shape)\n",
    "print(\"Sample normalized spectrum:\", X[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape: (85506, 1801), Y shape: (85506, 512)\n",
      "Train size: 59854 Test size: 12826 Val size: 12826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up X and Y\n",
    "X = np.array(normalized_spectra)\n",
    "Y = np.array(embedded_smiles)\n",
    "\n",
    "# fit to right length\n",
    "min_len = min(len(X), len(Y))\n",
    "X = X[:min_len]\n",
    "Y = Y[:min_len]\n",
    "\n",
    "# debug rqqq\n",
    "print(f\" shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "\n",
    "# train and temp split (val+test)\n",
    "X_train, X_temp, Y_train, Y_temp, smiles_train, smiles_temp = train_test_split(X, Y, smiles_list, test_size=0.3, random_state=42)\n",
    "\n",
    "# temp split into test and val\n",
    "X_val, X_test, Y_val, Y_test, smiles_val, smiles_test = train_test_split(\n",
    "    X_temp, Y_temp, smiles_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test), \"Val size:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpectraToSMILESDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# wrap train/test sets\n",
    "train_dataset = SpectraToSMILESDataset(X_train, Y_train)\n",
    "test_dataset = SpectraToSMILESDataset(X_test, Y_test)\n",
    "val_dataset = SpectraToSMILESDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SpectraToEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim=1801, output_dim=512, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SpectraToEmbedding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport torch.nn.functional as F\\n\\n# Optimizer\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\\n\\n# Scheduler (optional but helpful for long training)\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\\n\\ntest_losses = []\\ntrain_losses = []\\n# Hybrid loss function (MSE + Cosine)\\ndef hybrid_loss(y_pred, y_true):\\n    mse = F.mse_loss(y_pred, y_true)\\n    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\\n    return 0.5 * mse + 0.5 * cos\\n\\n# Training loop\\nnum_epochs = 200\\nfor epoch in range(num_epochs):\\n    model.train()\\n    total_loss = 0\\n    for X_batch, Y_batch in train_loader:\\n        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n        optimizer.zero_grad()\\n        Y_pred = model(X_batch)\\n\\n        loss = hybrid_loss(Y_pred, Y_batch)\\n\\n        loss.backward()\\n        optimizer.step()\\n        total_loss += loss.item()\\n\\n    train_losses.append(total_loss)\\n\\n    avg_loss = total_loss / len(train_loader)\\n    scheduler.step(avg_loss)\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n    model.eval()\\n    test_loss = 0\\n    with torch.no_grad():\\n        for X_batch, Y_batch in test_loader:\\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\\n            Y_pred = model(X_batch)\\n            test_loss += hybrid_loss(Y_pred, Y_batch)\\n\\n    test_losses.append(test_loss)\\n\\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\\n    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Scheduler (optional but helpful for long training)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "# Hybrid loss function (MSE + Cosine)\n",
    "def hybrid_loss(y_pred, y_true):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    cos = 1 - F.cosine_similarity(y_pred, y_true, dim=1).mean()\n",
    "    return 0.5 * mse + 0.5 * cos\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        loss = hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_loss)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            Y_pred = model(X_batch)\n",
    "            test_loss += hybrid_loss(Y_pred, Y_batch)\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {total_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train za Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss = 322.3222, Val Loss = 60.2141\n",
      "Epoch 2/200, Train Loss = 279.9213, Val Loss = 59.9237\n",
      "Epoch 3/200, Train Loss = 267.3234, Val Loss = 55.4378\n",
      "Epoch 4/200, Train Loss = 259.6148, Val Loss = 53.3432\n",
      "Epoch 5/200, Train Loss = 253.8676, Val Loss = 53.1345\n",
      "Epoch 6/200, Train Loss = 248.6898, Val Loss = 51.6512\n",
      "Epoch 7/200, Train Loss = 244.2138, Val Loss = 53.7273\n",
      "Epoch 8/200, Train Loss = 241.6224, Val Loss = 50.8200\n",
      "Epoch 9/200, Train Loss = 239.5758, Val Loss = 49.8179\n",
      "Epoch 10/200, Train Loss = 236.6266, Val Loss = 49.4744\n",
      "Epoch 11/200, Train Loss = 235.1170, Val Loss = 49.5125\n",
      "Epoch 12/200, Train Loss = 234.5315, Val Loss = 48.6236\n",
      "Epoch 13/200, Train Loss = 230.7206, Val Loss = 49.7103\n",
      "Epoch 14/200, Train Loss = 231.0629, Val Loss = 48.9540\n",
      "Epoch 15/200, Train Loss = 229.9071, Val Loss = 51.0349\n",
      "Epoch 16/200, Train Loss = 225.9406, Val Loss = 47.4062\n",
      "Epoch 17/200, Train Loss = 226.9299, Val Loss = 50.0303\n",
      "Epoch 18/200, Train Loss = 224.5196, Val Loss = 48.4797\n",
      "Epoch 19/200, Train Loss = 222.1451, Val Loss = 46.9658\n",
      "Epoch 20/200, Train Loss = 222.4718, Val Loss = 47.1453\n",
      "Epoch 21/200, Train Loss = 222.4534, Val Loss = 47.1322\n",
      "Epoch 22/200, Train Loss = 220.8450, Val Loss = 47.8014\n",
      "Epoch 23/200, Train Loss = 220.4941, Val Loss = 47.5782\n",
      "Epoch 24/200, Train Loss = 219.8945, Val Loss = 47.9697\n",
      "Epoch 25/200, Train Loss = 219.6748, Val Loss = 46.8754\n",
      "Epoch 26/200, Train Loss = 216.7328, Val Loss = 46.3620\n",
      "Epoch 27/200, Train Loss = 216.2075, Val Loss = 51.5095\n",
      "Epoch 28/200, Train Loss = 216.8127, Val Loss = 46.2463\n",
      "Epoch 29/200, Train Loss = 215.2540, Val Loss = 46.3861\n",
      "Epoch 30/200, Train Loss = 214.4111, Val Loss = 45.9137\n",
      "Epoch 31/200, Train Loss = 213.3007, Val Loss = 46.2174\n",
      "Epoch 32/200, Train Loss = 213.4652, Val Loss = 46.6613\n",
      "Epoch 33/200, Train Loss = 213.4181, Val Loss = 45.9005\n",
      "Epoch 34/200, Train Loss = 212.6397, Val Loss = 51.3199\n",
      "Epoch 35/200, Train Loss = 213.7943, Val Loss = 46.1155\n",
      "Epoch 36/200, Train Loss = 211.2231, Val Loss = 47.8193\n",
      "Epoch 37/200, Train Loss = 211.7521, Val Loss = 46.3905\n",
      "Epoch 38/200, Train Loss = 210.2818, Val Loss = 46.0333\n",
      "Epoch    39: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 39/200, Train Loss = 211.5306, Val Loss = 47.1223\n",
      "Epoch 40/200, Train Loss = 206.3686, Val Loss = 45.1067\n",
      "Epoch 41/200, Train Loss = 204.4191, Val Loss = 44.7802\n",
      "Epoch 42/200, Train Loss = 204.2701, Val Loss = 45.2708\n",
      "Epoch 43/200, Train Loss = 204.5005, Val Loss = 44.8418\n",
      "Epoch 44/200, Train Loss = 203.1319, Val Loss = 45.5694\n",
      "Epoch 45/200, Train Loss = 203.4805, Val Loss = 44.8618\n",
      "Epoch 46/200, Train Loss = 203.1894, Val Loss = 44.6723\n",
      "Epoch 47/200, Train Loss = 203.0085, Val Loss = 44.9260\n",
      "Epoch 48/200, Train Loss = 202.0370, Val Loss = 44.6741\n",
      "Epoch 49/200, Train Loss = 201.6856, Val Loss = 44.7123\n",
      "Epoch 50/200, Train Loss = 201.9550, Val Loss = 44.8454\n",
      "Epoch 51/200, Train Loss = 201.4757, Val Loss = 44.5329\n",
      "Epoch 52/200, Train Loss = 200.6129, Val Loss = 44.9084\n",
      "Epoch 53/200, Train Loss = 200.4296, Val Loss = 46.7134\n",
      "Epoch 54/200, Train Loss = 201.1607, Val Loss = 44.6829\n",
      "Epoch 55/200, Train Loss = 201.1864, Val Loss = 44.7781\n",
      "Epoch 56/200, Train Loss = 201.0032, Val Loss = 44.6262\n",
      "Epoch    57: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 57/200, Train Loss = 200.0863, Val Loss = 45.0137\n",
      "Epoch 58/200, Train Loss = 198.3905, Val Loss = 44.6308\n",
      "Epoch 59/200, Train Loss = 197.6357, Val Loss = 44.6681\n",
      "Epoch 60/200, Train Loss = 197.2536, Val Loss = 44.3049\n",
      "Epoch 61/200, Train Loss = 196.7994, Val Loss = 44.1706\n",
      "Epoch 62/200, Train Loss = 196.8097, Val Loss = 44.2623\n",
      "Epoch 63/200, Train Loss = 196.7038, Val Loss = 44.3917\n",
      "Epoch 64/200, Train Loss = 196.2709, Val Loss = 44.2699\n",
      "Epoch 65/200, Train Loss = 196.3284, Val Loss = 44.2016\n",
      "Epoch 66/200, Train Loss = 195.7419, Val Loss = 44.2982\n",
      "Epoch 67/200, Train Loss = 195.7768, Val Loss = 44.1613\n",
      "Epoch 68/200, Train Loss = 195.6347, Val Loss = 45.2492\n",
      "Epoch 69/200, Train Loss = 195.1574, Val Loss = 44.2236\n",
      "Epoch 70/200, Train Loss = 195.4563, Val Loss = 44.3926\n",
      "Epoch 71/200, Train Loss = 195.3005, Val Loss = 44.1499\n",
      "Epoch 72/200, Train Loss = 195.1202, Val Loss = 44.1137\n",
      "Epoch 73/200, Train Loss = 195.1418, Val Loss = 44.0864\n",
      "Epoch 74/200, Train Loss = 195.2888, Val Loss = 44.5343\n",
      "Epoch 75/200, Train Loss = 194.3802, Val Loss = 44.3786\n",
      "Epoch 76/200, Train Loss = 194.7555, Val Loss = 44.1922\n",
      "Epoch 77/200, Train Loss = 194.5019, Val Loss = 44.9584\n",
      "Epoch 78/200, Train Loss = 194.5520, Val Loss = 45.2260\n",
      "Epoch    79: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 79/200, Train Loss = 194.4550, Val Loss = 44.4014\n",
      "Epoch 80/200, Train Loss = 193.1961, Val Loss = 44.0070\n",
      "Epoch 81/200, Train Loss = 193.2776, Val Loss = 44.0950\n",
      "Epoch 82/200, Train Loss = 192.7082, Val Loss = 45.8419\n",
      "Epoch 83/200, Train Loss = 192.5184, Val Loss = 44.0668\n",
      "Epoch 84/200, Train Loss = 192.8259, Val Loss = 43.9706\n",
      "Epoch 85/200, Train Loss = 192.5713, Val Loss = 44.1212\n",
      "Epoch 86/200, Train Loss = 192.5291, Val Loss = 44.1298\n",
      "Epoch 87/200, Train Loss = 192.1378, Val Loss = 44.0136\n",
      "Epoch 88/200, Train Loss = 192.1450, Val Loss = 46.4959\n",
      "Epoch 89/200, Train Loss = 191.9784, Val Loss = 44.0668\n",
      "Epoch    90: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 90/200, Train Loss = 192.1169, Val Loss = 43.9987\n",
      "Epoch 91/200, Train Loss = 191.5284, Val Loss = 44.0425\n",
      "Epoch 92/200, Train Loss = 191.3666, Val Loss = 44.0390\n",
      "Epoch 93/200, Train Loss = 191.2014, Val Loss = 44.0056\n",
      "Epoch 94/200, Train Loss = 191.2736, Val Loss = 44.0665\n",
      "Early stopping triggered at epoch 94\n",
      "Best model restored.\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# scheduler: reduce LR by factor=0.5 if no improvement in 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CosineEmbeddingLoss()\n",
    "\n",
    "# to track losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# early stopping params\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "wait = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        loss = loss_fn(Y_pred, Y_batch, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            Y_pred = model(X_batch)\n",
    "            target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "            val_loss += loss_fn(Y_pred, Y_batch, target).item()\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_loss - 1e-4:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Best model restored.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEWCAYAAADIE4vrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9OElEQVR4nO3deZyVdd3/8dfnbLMPM8AAAwMCggKyKopr4tKmJplLmpVYd91ZabYvv7syy/u2btusuyxTszLNykgz09wtTQUUBcFEFhn2bfblbN/fH9/rzBxwGIblzJlh3s8H53Gda/+ec83hvM/3+72uy5xziIiIiEj+hPJdABEREZGBToFMREREJM8UyERERETyTIFMREREJM8UyERERETyTIFMREREJM8UyERkr8zsATO77GAv29+YmTOzCcHzm8zsqz1Zdj/2c6mZPbS/5RSR/sd0HTKRQ5OZNWWNFgPtQCoY/0/n3B29X6r8MrO/Ac8557622/R5wM+AGudcspv1HTDRObeyB/vq0bJmNhZYDUS72/fBYGZzgd8452pyuR8R2XeqIRM5RDnnSjMP4A3gXVnTOsKYmUXyV8pedzvwfjOz3aZ/ALgj14FIRGRPFMhEBhgzm2tmtWb2RTPbBNxmZpVm9hcz22pmO4PnNVnrPG5m/xE8n29m/zCzG4JlV5vZO/dz2XFm9qSZNZrZw2b2f2b2mz2Ue7mZnZM1HgnKe7SZFZrZb8xsu5nVmdnzZja8i80sAIYAp2RtpxI4B/iVmR1nZs8E29hoZj82s9geyvNLM/tW1vjng3U2mNmHdlv2bDN7wcwazGydmV2TNfvJYFhnZk1mdkLmfcta/8TgNdUHwxN3e7+/aWb/DN7Hh8xsaFdl7o6ZTQ62VWdmy8zs3Kx5Z5nZK8H215vZ54LpQ4O/lToz22FmT5mZvldE9oM+OCID0whgMHAY8FH8/wW3BeNjgFbgx92sPwd4FRgKfAe4pYtap54s+1vgOXxIugZfU7UndwKXZI2/HdjmnFsMXAYMAkYH2/pY8Bp24ZxrBe4GPpg1+SJghXNuCb5J99NBWU8AzgA+3k2ZADCzdwCfA94KTATO3G2R5mCfFcDZwBVm9u5g3luCYUVQe/nMbtseDNwP3Bi8tu8B95vZkKzF3gdcDgwDYkFZeszMosB9wEPBNq4E7jCzI4NFbsE3c5cBU4FHg+mfBWqBKmA48BVA/WBE9oMCmcjAlAa+7pxrd861Oue2O+f+6Jxrcc41AtcBp3az/lrn3M3OuRS+GbAa/4Xc42XNbAxwLPA151zcOfcP4N5u9vlb4FwzKw7G34cPaQAJfFiZ4JxLOecWOeca9rCd24ELzKwwGP9gMI1gvX8555LOuTX4fmXdvQ8ZFwG3OeeWOuea8eGyg3Pucefcy865tHPupaDcPdku+AD3mnPu10G57gRWAO/KWuY259y/swLnzB5uO+N4oBS4PjgWjwJ/oTMAJ4ApZlbunNsZhODM9GrgMOdcwjn3lFPHZJH9okAmMjBtdc61ZUbMrNjMfmZma82sAd+MVmFm4T2svynzxDnXEjwt3cdlRwI7sqYBrNtTgYPO8cuBdwWh7Fx8SAP4NfAgcFfQZPidoNanq+38A9gGvNvMDgeOy2zHzI4ImuA2Be/Df+Nry/Zm5G5lX5s908zmmNljQRNrPb4Gr6fNiiN3314wPiprfFPW8xb2fCy628c651x6D/s4HzgLWGtmT5jZCcH0/wVWAg+Z2Soz+9I+7ldEAgpkIgPT7rUYnwWOBOY458rpbEbbUzPkwbARGJxV4wW+ybE7mWbLecArmTMYg9qZbzjnpgAn4vuEfXDPm+FXwfz3Aw865zYH03+Kr32aGLwPX6Fn78HG3co+Zrf5v8XX/o12zg0Cbsra7t5qlDbgm5KzjQHW96BcPbUBGL1b/6+OfTjnnnfOzcM3Zy7A18LhnGt0zn3WOTceH5A/Y2ZnHMRyiQwYCmQiAlCG73NVF/RZ+nqud+icWwssBK4xs1hQ6/Kuvax2F/A24Ao6a8cws9PMbFpQo9eAb0pLd70JwAeyM4GPEDRXBsqC9ZvMbFKwn564G5hvZlOCgLn7+1eGrw1sM7Pj8M2tGVuDso7fw7b/ChxhZu8LTmR4LzAF36S4X4KTIDoe+H58LcAXzCxq/vIY78LXOMbMXxdtkHMugX9/0sF2zjGzCUGfwHp8H7zu3ncR2QMFMhEB+AFQhG/K+xfwt17a76X4zvPbgW8Bv8NfL61LzrmNwDP4WrDfZc0aAfwBHxaWA0/gmzH3tJ01wNNACbv2W/scPiw1Ajfvto89cs49gH8PH8U34T262yIfB641s0bgawQ1TMG6Lfg+e/8MzlY8frdtb8fX+H0W/z59ATjHObetJ2Xrwih8+M5+jMYHsHfi/wZ+AnzQObciWOcDwJqgGfdj+OMG/gSGh4Em/HH5iXPusf0sl8iApgvDikifYWa/w5/xmPMaOhGRvkQ1ZCKSN2Z2rJkdbmah4NIR8/B9lEREBpSBdIVuEel7RgD34C9ZUQtc4Zx7Ib9FEhHpfWqyFBEREckzNVmKiIiI5Fm/brIcOnSoGzt2bL6LISIiIrJXixYt2uacq+pqXr8OZGPHjmXhwoX5LoaIiIjIXpnZ7nfd6KAmSxEREZE8UyATERERyTMFMhEREZE869d9yERERA51iUSC2tpa2tra8l0U6aHCwkJqamqIRqM9XkeBTEREpA+rra2lrKyMsWPH4u/jLn2Zc47t27dTW1vLuHHjeryemixFRET6sLa2NoYMGaIw1k+YGUOGDNnnGk0FMhERkT5OYax/2Z/jpUDWjY31rXz3oVdZs60530URERGRQ5gCWTea21P86NGVLFy7M99FERER6XXbt29n5syZzJw5kxEjRjBq1KiO8Xg83u26Cxcu5Kqrrtqn/Y0dO5Zt27YdSJH7LXXq78a4oSUUREKs2NiQ76KIiIj0uiFDhvDiiy8CcM0111BaWsrnPve5jvnJZJJIpOsoMXv2bGbPnt0bxTwkqIasG+GQceSIMpZvUiATEREBmD9/Ph/72MeYM2cOX/jCF3juuec44YQTmDVrFieeeCKvvvoqAI8//jjnnHMO4MPchz70IebOncv48eO58cYbe7y/NWvWcPrppzN9+nTOOOMM3njjDQB+//vfM3XqVGbMmMFb3vIWAJYtW8Zxxx3HzJkzmT59Oq+99tpBfvW5oxqyvZg0ooyHl2/BOadOlSIiklffuG8Zr2w4uJUEU0aW8/V3HbVP69TW1vL0008TDodpaGjgqaeeIhKJ8PDDD/OVr3yFP/7xj29aZ8WKFTz22GM0NjZy5JFHcsUVV/ToOl1XXnkll112GZdddhm33norV111FQsWLODaa6/lwQcfZNSoUdTV1QFw00038alPfYpLL72UeDxOKpXap9eVT6oh24vJ1eXsaI6ztbE930URERHpEy688ELC4TAA9fX1XHjhhUydOpVPf/rTLFu2rMt1zj77bAoKChg6dCjDhg1j8+bNPdrXM888w/ve9z4APvCBD/CPf/wDgJNOOon58+dz8803dwSvE044gf/+7//m29/+NmvXrqWoqOhAX2qvUQ3ZXkwaUQ7A8k2NDCsvzHNpRERkINvXmqxcKSkp6Xj+1a9+ldNOO40//elPrFmzhrlz53a5TkFBQcfzcDhMMpk8oDLcdNNNPPvss9x///0cc8wxLFq0iPe9733MmTOH+++/n7POOouf/exnnH766Qe0n96iGrK9mFxdBqCO/SIiIl2or69n1KhRAPzyl7886Ns/8cQTueuuuwC44447OOWUUwB4/fXXmTNnDtdeey1VVVWsW7eOVatWMX78eK666irmzZvHSy+9dNDLkysKZHtRURyjelAhyxXIRERE3uQLX/gCX/7yl5k1a9YB13oBTJ8+nZqaGmpqavjMZz7Dj370I2677TamT5/Or3/9a374wx8C8PnPf55p06YxdepUTjzxRGbMmMHdd9/N1KlTmTlzJkuXLuWDH/zgAZent5hzLt9l2G+zZ892CxcuzPl+Lr/tOTbWt/G3q9+S832JiIhkW758OZMnT853MWQfdXXczGyRc67La4GohqwHJleXs3JLE/FkOt9FERERkUOQAlkPTKouJ5l2rNzSlO+iiIiIyCFIgawHJo8IOvbrArEiIiKSAwpkPTBuaAmxSIgVmxrzXRQRERE5BOUskJlZoZk9Z2ZLzGyZmX0jmD7OzJ41s5Vm9jsziwXTC4LxlcH8sbkq276KhEMcMbxUZ1qKiIhITuSyhqwdON05NwOYCbzDzI4Hvg183zk3AdgJfDhY/sPAzmD694Pl+ozJI8pZvlE1ZCIiInLw5SyQOS/TCz4aPBxwOvCHYPrtwLuD5/OCcYL5Z1gfunnkpOpytjW16xZKIiIyoJx22mk8+OCDu0z7wQ9+wBVXXLHHdebOnUvmslRnnXVWx70ms11zzTXccMMN3e57wYIFvPLKKx3jX/va13j44Yf3ofRdy77xeV+R0z5kZhY2sxeBLcDfgdeBOudc5spxtcCo4PkoYB1AML8eGNLFNj9qZgvNbOHWrVtzWfxdqGO/iIgMRJdccknHlfIz7rrrLi655JIerf/Xv/6VioqK/dr37oHs2muv5cwzz9yvbfV1OQ1kzrmUc24mUAMcB0w6CNv8uXNutnNudlVV1YFurscmVft7Wq5Qs6WIiAwgF1xwAffffz/xeByANWvWsGHDBk455RSuuOIKZs+ezVFHHcXXv/71LtcfO3Ys27ZtA+C6667jiCOO4OSTT+bVV1/tWObmm2/m2GOPZcaMGZx//vm0tLTw9NNPc++99/L5z3+emTNn8vrrrzN//nz+8AffyPbII48wa9Yspk2bxoc+9CHa29s79vf1r3+do48+mmnTprFixYoev9Y777yz4+r/X/ziFwFIpVLMnz+fqVOnMm3aNL7//e8DcOONNzJlyhSmT5/OxRdfvI/v6pv1ys3FnXN1ZvYYcAJQYWaRoBasBlgfLLYeGA3UmlkEGARs743y9cTgkhjDywvUsV9ERPLngS/BppcP7jZHTIN3Xr/H2YMHD+a4447jgQceYN68edx1111cdNFFmBnXXXcdgwcPJpVKccYZZ/DSSy8xffr0LrezaNEi7rrrLl588UWSySRHH300xxxzDADvec97+MhHPgLAf/3Xf3HLLbdw5ZVXcu6553LOOedwwQUX7LKttrY25s+fzyOPPMIRRxzBBz/4QX76059y9dVXAzB06FAWL17MT37yE2644QZ+8Ytf7PVt2LBhA1/84hdZtGgRlZWVvO1tb2PBggWMHj2a9evXs3TpUoCO5tfrr7+e1atXU1BQ0GWT7L7K5VmWVWZWETwvAt4KLAceAzLv7GXAn4Pn9wbjBPMfdX3svk6Tq8tZrktfiIjIAJPdbJndXHn33Xdz9NFHM2vWLJYtW7ZL8+LunnrqKc477zyKi4spLy/n3HPP7Zi3dOlSTjnlFKZNm8Ydd9zBsmXLui3Pq6++yrhx4zjiiCMAuOyyy3jyySc75r/nPe8B4JhjjmHNmjU9eo3PP/88c+fOpaqqikgkwqWXXsqTTz7J+PHjWbVqFVdeeSV/+9vfKC/3LWbTp0/n0ksv5Te/+Q2RyIHXb+WyhqwauN3Mwvjgd7dz7i9m9gpwl5l9C3gBuCVY/hbg12a2EtgBHHj930E2aUQ5/1y5ikQqTTSsS7iJiEgv66YmK5fmzZvHpz/9aRYvXkxLSwvHHHMMq1ev5oYbbuD555+nsrKS+fPn09bWtl/bnz9/PgsWLGDGjBn88pe/5PHHHz+g8hYUFAAQDocP+IbnlZWVLFmyhAcffJCbbrqJu+++m1tvvZX777+fJ598kvvuu4/rrruOl19++YCCWS7PsnzJOTfLOTfdOTfVOXdtMH2Vc+4459wE59yFzrn2YHpbMD4hmL8qV2XbX5Ory0ikHK9v1S2URERk4CgtLeW0007jQx/6UEftWENDAyUlJQwaNIjNmzfzwAMPdLuNt7zlLSxYsIDW1lYaGxu57777OuY1NjZSXV1NIpHgjjvu6JheVlZGY+ObW6aOPPJI1qxZw8qVKwH49a9/zamnnnpAr/G4447jiSeeYNu2baRSKe68805OPfVUtm3bRjqd5vzzz+db3/oWixcvJp1Os27dOk477TS+/e1vU19fT1PTgWWDXulDdqiYnNWxf9KI8jyXRkREpPdccsklnHfeeR1NlzNmzGDWrFlMmjSJ0aNHc9JJJ3W7/tFHH8173/teZsyYwbBhwzj22GM75n3zm99kzpw5VFVVMWfOnI4QdvHFF/ORj3yEG2+8saMzP0BhYSG33XYbF154IclkkmOPPZaPfexj+/R6HnnkEWpqajrGf//733P99ddz2mmn4Zzj7LPPZt68eSxZsoTLL7+cdDoNwP/8z/+QSqV4//vfT319Pc45rrrqqv0+kzTD+lg3rX0ye/Zsl7nOSW9IpNIc9bUHufzksXz5nZN7bb8iIjJwLV++nMmT9Z3T33R13MxskXNudlfLqyPUPoiGQ0wcXqor9ouIiMhBpUC2jyaNKGeFLn0hIiIiB5EC2T6aXF3GlsZ2tjfpFkoiItI7+nP3ooFof46XAtk+6ujYr+uRiYhILygsLGT79u0KZf2Ec47t27dTWFi4T+vpLMt9NCm4p+XyjQ2cNGFonksjIiKHupqaGmpra+nN+zfLgSksLNzlDM6eUCDbR0NKC6gqK1DHfhER6RXRaJRx48bluxiSY2qy3A8zR1fw2KtbqGuJ57soIiIicghQINsPn3nrEdS3JvjOg6/ufWERERGRvVAg2w+Tq8uZf+JY7nzuDV54Y2e+iyMiIiL9nALZfrr6zIkMKyvgvxYsJZXWmS8iIiKy/xTI9lNZYZSvnjOFZRsa+M2/1ua7OCIiItKPKZAdgLOnVXPKxKHc8OCrbGlsy3dxREREpJ9SIDsAZsY3zj2K9mSa/75/eb6LIyIiIv2UAtkBGl9VysdOHc+CFzfw9Ovb8l0cERER6YcUyA6Cj582gTGDi/nqgqW0JVL5Lo6IiIj0MwpkB0FhNMy1847i9a3NfPyOxbQnFcpERESk5xTIDpK5Rw7juvOm8uiKLVzxG4UyERER6TkFsoPo0jmH8a13+1D2cYUyERER6SEFsoPs/cf7UPbIii18Qs2XIiIi0gMKZDnw/uMP45vvnsrDy30oiyfT+S6SiIiI9GEKZDnygeMP45vzjuLh5VuYf9tzbG1sz3eRREREpI9SIMuhD5wwlv+9YDqL1u7krBuf0nXKREREpEsKZDl24ezRLPjESZQVRnj/L57lxkde083IRUREZBcKZL1gcnU5933yZObNHMX3/v5vLrtVTZgiIiLSKWeBzMxGm9ljZvaKmS0zs08F068xs/Vm9mLwOCtrnS+b2Uoze9XM3p6rsuVDSUGE7100g++cP53n1+zgnT98ikeWb853sURERKQPyGUNWRL4rHNuCnA88AkzmxLM+75zbmbw+CtAMO9i4CjgHcBPzCycw/L1OjPjomNH8+dPnsTQ0hgfvn0hn/v9EupbE/kumoiIiORRzgKZc26jc25x8LwRWA6M6maVecBdzrl259xqYCVwXK7Kl0+TRpRz7ydP5pOnTeBPL6znHT94kif+vTXfxRIREZE86ZU+ZGY2FpgFPBtM+qSZvWRmt5pZZTBtFLAua7Vaug9w/VosEuJzbz+Se644kZKCCJfd+hxfvudlGttUWyYiIjLQ5DyQmVkp8EfgaudcA/BT4HBgJrAR+O4+bu+jZrbQzBZu3dr/a5VmjK7gL1eezH+eOp7fPf8GZ3z3Cf64qJa0zsQUEREZMHIayMwsig9jdzjn7gFwzm12zqWcc2ngZjqbJdcDo7NWrwmm7cI593Pn3Gzn3OyqqqpcFr/XFEbDfPmdk7nn4ydRXVHEZ3+/hPNvepol6+ryXTQRERHpBbk8y9KAW4DlzrnvZU2vzlrsPGBp8Pxe4GIzKzCzccBE4Llcla8vmjm6gj9dcSI3XDiD2p2tzPu/f/L53y/RJTJEREQOcZEcbvsk4APAy2b2YjDtK8AlZjYTcMAa4D8BnHPLzOxu4BX8GZqfcM4NuDtzh0LGBcfU8PajhvPjx1Zy6z9Wc++SDZw+aRhnT6/m9EnDKI7l8rCJiIhIbzPn+m9fpdmzZ7uFCxfmuxg5tXpbM7/852r+unQTWxvbKYqGOX3yMN41vZpTJlZRUqBwJiIi0h+Y2SLn3Owu5ymQ9Q+ptOP5NTv4y0sbeODlTWxvjhMJGUePqeTkiUM5acJQZtQMIhLWzRdERET6IgWyQ0wylea5NTt46rVt/OO1bSzdUI9zUFoQ4eQJQ7ngmBrmHlmlcCYiItKHKJAd4nY2x3lm1Xaeem0bf39lE9ua4lSVFXD+0TVcOLuGw6tK811EERGRAU+BbABJpNI8tmILdy+s5bFXt5BKO2YfVslJE4YybdQgpo4axPDyAvxJsCIiItJbugtk6hF+iImGQ7ztqBG87agRbGls457F61nwwnp+9OhrZK41O7Q0xtRRgzi8qpTBJTEqi2NUFkepKI5RVVbA4VUlCmwiIiK9SDVkA0RLPMnyjQ0sXd/Ay+vrWbq+nrXbW2hNvPnKIjNGV3D1GROZe2SVgpmIiMhBohoyoTgW4ZjDBnPMYYN3md6WSFHXkmBHc5y6ljivbWni5qdWcfkvn2d6zSCuOn0iZ0wepmAmIiKSQ6ohkzdJpNLcs7iWHz26ktqdrUwdVc5bJ4+gLZmiNZ6iuT1JSyJFMpWmprKYcUNLGF9VwuFVpQwrU/80ERGRrqhTv+yXRCrNnxav58ePreSNHS1EQkZxLExxLEJxQZiwGet2ttCWSHesUxILc+qRVXzqjCM4ckRZHksvIiLStyiQyQFxzpFIOWKRN1/XLJ12bGxoY/XWZlZta+LfmxtZ8MIGmuNJzp0xkqvPPIJxQ0vyUGoREZG+RYFMetXO5jg/e3IVtz+9hngqzflHj+LDJ4+nJZ5k3c5W1u1ooXZnC7U7Wxk9uJi3TRnOiYcP7TLwiYiIHCoUyCQvtja285PHV3LHv94gnkrvMm9ISYyRFUW8vrWJlniKsoIIcycN4+1HDWfukcMo1T06RUTkEKNAJnm1sb6Vx1ZsZVhZAaMHF1NTWdRxU/S2RIqnX9/Gg0s38/DyzWxvjhMLhzjh8CG8dcpw3jplOMPLC/P8CkRERA6cApn0C6m0Y/EbO3lo2SYeemUza7e3ADCjZhBnTh7O4NIYrfEULcGjNZ4knur8+zUDA0JmHF5VwozRFUyuLqcwGs7TKxIREemkQCb9jnOO17Y08fdXNvPQK5tZsq5ul/nRsFEUDROLhDED/2fs/5bjyTQNbcmO5SaNKGfGaH9ngpLgDNGSWISimB9WFEcZXBKjOBbWJTtERCRnFMik39vRHCeRSlMUC1MUDRMN7/kEAOccmxraWLKuniW1dSxZV8fLtfU0tie73UcsEmJwcYzKkhhlBREKoiFi4RCxSIiCSIjSwghvmzKCkyYMJRxScBMRkX2jQCYDXjrtqGtN0BJPdjR5trQnaWpPUteaYGdznB0tcT9sjtPUniSeTNOeTHcMM9NHDirkgmNquOCY0YwZUpzvlyYiIv2Ebp0kA14oZAwuiTG4JLbf22hLpHh4+WbuXljLjx5byY2PruTEw4dw/PghVBRHGVTU+SiKhalvSbCzJc6OZj/c2RxnaFkB00cN4qhRgxhUFD2Ir1BERPoz1ZCJ7IcNda38cVEtf1hc23Hywd4URcO73Mx93NASpo4axJTqckZWFFI9qIjqQYUMLy/UNdlERA5BarIUySF/EkGCupYE9a0J6lvjtMRTVBbHqCz2tXIVxVEKo2F2Nsd5eX29f9T64fq61jdtc2hpAaMHFzFuSAljh/rHuCElDCsvIJl2JFNpEilHIpUmGZxpauYfITPMoDgaYVh5wR7PMq1vSfD6tiZWb22mrDDCW46o0hmpIiI5pEAm0oc1tiXYVN/Gxvq2juHG+lbWbm9hzfZmNta3HdD2BxVFGVZWwPDyQiqKo2yqb2PVtmZ2NMd3Wa4kFubMKcM5a1o1pyqciYgcdOpDJtKHlRVGKSuMMnF41zdjb42nWLujmTXbmtnWFCcaNiKhENFIiGjIiARnnDrnSAeX/0g7aGpPsrWxnc0NbcGjnXU7WxhRXsjbjxrO+KGljBtawriqEjbWtXH/yxv529KN/PnFDZQWRDhpwhCcg7rWBPVB7V9da5xBRVGOGjmIo0aWB49BjKwoonZnCyu3NPHaliZWbmli9bZm5owbzFVnTFS4ExHZC9WQiUiHRCrNv1Zt5/6XNvLMqu0URcOUF0WpKIp2nLiwrSnOsg31rNzSFARACBkdzwGGlRVQXVHEknV1TBhWyncvnMGM0RV5eU0iIn2FmixF5KBrjadYsamBZRsa2FDXymFDipkwrIwJw0o7ziB94t9b+eIfXmJrUzsfO3U8V50xkYKIastEZGBSIBORvKlvTfCtv7zC7xfVcuTwMr59wXRm1AzSXRFEZMBRIBORvHt0xWa+9MeX2dLYzqiKIo4fP4QTDvePURVF+S6eiEjOKZCJSJ9Q35Lgz0vW88zr2/nXqu3sbEkAMHpwEcPLComEjWg4RCQ4WcEg624JKdqT/jIfNZVFHDmijEnV5UweUca4oSUdJzeA7wvX0p6iLZkiGg5RFA1TEAkR0i2vRCSP8hLIzGw08CtgOP6uzz93zv3QzAYDvwPGAmuAi5xzO823X/wQOAtoAeY75xZ3tw8FMpH+K512/HtLI8+8vp3n1+ygriVBMuVIpH3oSqYdzjkKIiEKIuGOe4qGQsba7c2s2tpMMjiTIBYOMaQ0FtwWK0ki1fX/awWREEUxH86iYX+v0mg4RDRiFEbCVFcUUVPpH6Mri6mpLGJIaQElsfAuga8riVSaSMjUFCsie5SvQFYNVDvnFptZGbAIeDcwH9jhnLvezL4EVDrnvmhmZwFX4gPZHOCHzrk53e1DgUxk4GpPpnh9SzMrNjWwYlMjO5rjlMTCFBdEKI76YWE0RCKZpi2ZpjWeoi3h72MaT6ZJpIOL6ybTvkYtnmJDfSsb6lq7DHSxSIjiWJiSWISCSIj2ZJq2hN9mWzJNKu0Imb+MyaCiKOVFEcoL/dmpI8qLGFlRyIhBnXdkKC2MdATCzM3qnXPUtSTY0tjO1sZ2tja1sa0xTiKdJvNfdeb/bDML1jd/CZSwD6zDygqpqSxixKBConsJkSLSu/JyHTLn3EZgY/C80cyWA6OAecDcYLHbgceBLwbTf+X8/zb/MrMKM6sOtiMisouCSJgpI8uZMrL8oG43lXZsbmijdmcr63a0sLMl3nlD+niS5vYU7ckUBZEwhdEQhVE/LIiESaTS1LcmaGhN0NCWpKE1wYqNjTy2Yusut83aXcggGg6Rdm6PtXv7ygyGlxUyqrKIw6tKmDWmklljKpg4rKwjAIpI39ErF4Y1s7HALOBZYHhWyNqEb9IEH9bWZa1WG0zbJZCZ2UeBjwKMGTMmd4UWkQEpHDJGVhQxsqKI48YNPijbdM7R0JpkQ30rG+tb2VjfRms81XH7q0QqTTyVxjCqygoYVlbQMRxaVkAsqOkyA8PfGiuV9s26mRq+eMrX2G2qb2dDXSu1db62b/3OVv7+ymbuXlgLQGlBhJmjK5gx2l/Qd1hZYcedHIaWxvbaNCsiuZHzQGZmpcAfgaudcw3Z/Succ87M9unnoHPu58DPwTdZHsyyiojkgpkxqDjKoOIok6sPTo1ex80PCnadPmHYm+/44JxjzfYWFq/dyQvrdrJ4bR0/ffz1XS7m68sJZQURSrIfsTClBRFKC30TbFnWMPsuEdkiYSNk/o4S4ZARCRnFsTClhRFKCyLB3Sl80y/4iwqnncM5cDhi4ZD64smAk9NAZmZRfBi7wzl3TzB5c6YpMuhntiWYvh4YnbV6TTBNREQOgJn522QNLeH8Y2oAfxLCtqZ2tjS0s6WxnS2N/vZaDa0JmtqTNLcnaY6naG5Psr2phab2JA1tfl6uT86PhUNUlkSpLI5RWRxjcEmMoli4I7AF/3DOEQ5lzsrtPEO3KBamvLCzH195UZTiWJh4Mk1r0O+vNZGiNZ4m7XwAjIT9mb3RkAUnevj+eR0nfoRDhEL4MmTKgX+eSKV9bWXKn5CSSjsqS2KMrChkaEmBzu6VHslZIAvOmrwFWO6c+17WrHuBy4Drg+Gfs6Z/0szuwnfqr1f/MRGR3IiGQ8EJBvt2Dbh02tEcT9LYliS1exVbINOcmnYuOGPWnzTR1JakqT1JY1uCxvYkbYk0IYOQGSGjo1asoS1BXXOCHS1xdjbHWbGpgdZ4qmN+KOSbbjv35YNQJhi1JVJvqv3Ll1gkxMhBhYysKKKiOEpzu++L2NTe2ScxErKOfoiZYSRspDP3p83UIOL7G4ZDRjjkayHDIWNwcYwJw0uZUFXKxOFljBlcrH6C/VCPzrI0sxKg1TmXNrMjgEnAA865RDfrnAw8BbwMpIPJX8H3I7sbGAOsxV/2YkcQ4H4MvAN/2YvLnXPdnkKpsyxFRGR3mdCYObGioTVBczwZBJ4wRdEwRTEffkJmHTVbycyZt6n0Lv37Eil/LbzM16XPhRb06fPhNhL2TbTRsBEKGTua4myob2V90I9vQ10rDW1JSmJhSgoiFMcilBaEKYpFSKXTHWftZobJlCMU8rEzZEYolHltkHKOdNqRcr42bmtjOxvr2zpefywSYszgYiIhIxUE47Tz4bUwGqKiOEZlsa+BrCiOMagoSiwS8o+wEQvO2k2lHS3xFK3xTI1iikQ6TUE4REFwbb/CYJgJiBYEa/++WEfTd2lWE3hXNYaZ9zH7rONsLnitybTruE5hf3TAl70ws0XAKUAl8E/geSDunLv0YBZ0XymQiYiIQGNbgpVbmnhtSxMrtzSxdnszkAlzRjiohWxNpNjZkqCuJd4x7OmZvSGDSDhEPJne+8IHILOfaMhIddSy7lrG8sIIg0tiVJbEGJwVKjPhOBpcEiYS8kEzEuqcFg6FcPhQmwmqaeeYXF3OSROG5vS1HYzLXphzrsXMPgz8xDn3HTN78aCVUERERPZbWWE0uLRJ5T6t55yjNZEikXTEg7N1E0k/zPTHK45GKIyFOk62cM4FZ/UGd9BI+OvwObJOzgiWaYmnOvsktvsm2nQXFUHO4a8NmPQ1lfGg1jISNM9Gwp19BdsTaepa4uwIAuXmxjZe3dxIPJnuPPM4qO3cU7N6V95//JicB7Lu9DiQmdkJwKXAh4Np4W6WFxERkT7OzCiORSC2b+sURMIURMJANGdlOxjSmcvDBAEvnuq8iLNZpi8ehELWcXmZfOlpILsa+DLwJ+fcMjMbDzyWs1KJiIiIHKBQyIiFfL+4vq5Hgcw59wTwBICZhYBtzrmrclkwERERkYGiR5HRzH5rZuXB2ZZLgVfM7PO5LZqIiIjIwNDTOrwpzrkG/M3BHwDGAR/IVaFEREREBpKeBrJocNX9dwP3Btcf6yOX3RMRERHp33oayH4GrAFKgCfN7DCgIVeFEhERERlIetqp/0bgxqxJa83stNwUSURERGRg6Wmn/kFm9j0zWxg8vouvLRMRERGRA9TTJstbgUbgouDRANyWq0KJiIiIDCQ9vTDs4c6587PGv6FbJ4mIiIgcHD2tIWs1s5MzI2Z2EtCamyKJiIiIDCw9rSH7GPArMxsUjO8ELstNkUREREQGlp6eZbkEmGFm5cF4g5ldDbyUw7KJiIiIDAj7dLdN51xDcMV+gM/koDwiIiIiA86B3P7cDlopRERERAawAwlkunWSiIiIyEHQbR8yM2uk6+BlQFFOSiQiIiIywHQbyJxzZb1VEBEREZGB6kCaLEVERETkIFAgExEREckzBTIRERGRPFMgExEREckzBTIRERGRPFMgExEREcmznAUyM7vVzLaY2dKsadeY2XozezF4nJU178tmttLMXjWzt+eqXCIiIiJ9TS5ryH4JvKOL6d93zs0MHn8FMLMpwMXAUcE6PzGzcA7LJiIiItJn5CyQOeeeBHb0cPF5wF3OuXbn3GpgJXBcrsomIiIi0pfkow/ZJ83spaBJszKYNgpYl7VMbTBNRERE5JDX24Hsp8DhwExgI/Ddfd2AmX3UzBaa2cKtW7ce5OKJiIiI9L5eDWTOuc3OuZRzLg3cTGez5HpgdNaiNcG0rrbxc+fcbOfc7KqqqtwWWERERKQX9GogM7PqrNHzgMwZmPcCF5tZgZmNAyYCz/Vm2URERETyJZKrDZvZncBcYKiZ1QJfB+aa2UzAAWuA/wRwzi0zs7uBV4Ak8AnnXCpXZRMRERHpS8w5l+8y7LfZs2e7hQsX5rsYIiIiIntlZoucc7O7mqcr9YuIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkWc4CmZndamZbzGxp1rTBZvZ3M3stGFYG083MbjSzlWb2kpkdnatyiYiIiPQ1uawh+yXwjt2mfQl4xDk3EXgkGAd4JzAxeHwU+GkOyyUiIiLSp+QskDnnngR27DZ5HnB78Px24N1Z03/lvH8BFWZWnauyiYiIiPQlvd2HbLhzbmPwfBMwPHg+CliXtVxtMO1NzOyjZrbQzBZu3bo1dyUVERER6SV569TvnHOA24/1fu6cm+2cm11VVZWDkomIiIj0rt4OZJszTZHBcEswfT0wOmu5mmCaiIiIyCGvtwPZvcBlwfPLgD9nTf9gcLbl8UB9VtOmiIiIyCEtkqsNm9mdwFxgqJnVAl8HrgfuNrMPA2uBi4LF/wqcBawEWoDLc1UuERERkb4mZ4HMOXfJHmad0cWyDvhErsoiIiIi0pfpSv0iIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieaZAJiIiIpJnCmQiIiIieRbJdwH6tNadsOKvEC2EaDFEiyBS5IeDx0FBWb5LKCIiIocABbLu1L0Bf/541/OKKuG0/wfHXA5hvY0iIiKy/5QkulM1GT61BBJtkGiBZDBsb4KFt8BfPwcLb4N3fhvGnZLv0oqIiEg/pUDWnUgMKsd2PW/KPFh+Hzz4/+D2c/z4274FFWN6tYgiIiLS/ymQ7S8zmHIuTHwrPP0jeOp78OoDcNhJcPjpcPhpMHyqX05ERESkG+ac6/2dmq0BGoEUkHTOzTazwcDvgLHAGuAi59zO7rYze/Zst3DhwtwWtqfq1sGzN8HKR2Drcj+tZJgPZkMnQrgAIsEjXAAFpTBsClSOg1AXJ7u21cPqp2DVY9Cw0dfATX4XxIp793WJiIjIQWFmi5xzs7ucl8dANts5ty1r2neAHc65683sS0Clc+6L3W2nTwWybA0b4PXH4PVHfaBq2b7nZWNlMGIaVM+AEVN9sFv1GNQuBJeCaAkUVUDDeigoh6POg1nvh5pjVfvWV6XT0LQJykfmuyRvlk5BKJzvUoiIDEj9JZC9Csx1zm00s2rgcefckd1tp88GsmzOQSoOyfZdh607YfNS2LgENr4Em16GZCtgMHKWr1k7/HSoOQ5CEXjjaXjhDnhlgT+xYMhEGHO87+NWORYqDvPDkqG9H9RSSdiw2AfQ1U9B2Qg46SofMrvTWgfh2KFV67dzDfz5k7DmKTj2P+Ct10KsJN+l8kHsnz+AJ/4Xjv4AnHlN3yiXiMgA0hcD2WpgJ+CAnznnfm5mdc65imC+ATsz43vSLwJZT6VTsGMVFA+B4sF7Xq69EZYtgJfvhi0roHnLrvNDUR9wYqX+2mmxkuCL1wAHLu1DIs5fT628BgbVwKBRflgyDBo3+bJkP1JxH7RKh3cOo0Ww9mkfwtrr/T6qp8OO1dDeABPOhJM/A4ed2BkSW3bAir/A0ntg9RN+nWGToXomjJwJI4+G4Uf5a7/1J+k0LLoVHvqar4Ga+DZY+kd/vbrzfgajj8tf2eregHv+04f6kUf78Dx4PLz7pz7Ui4hIr+iLgWyUc269mQ0D/g5cCdybHcDMbKdzrrKLdT8KfBRgzJgxx6xdu7aXSt1HxZv9F+7Otb52pmkTxFv89ESzH8ZbAAcW9FUzA8zPa1jvAxhd/B1ES2DIeP/lHS7w227c7Jdvr/fLDBoDh8/1tXnjTvVhsq0env8FPPMTaNkGo+f4ptZMM2464fvOHXWer/3b8IJ/tAQVpqGIv+RI9Qwf0qpn+BMkYsU++KQTPiCmEpBOZhXY/GtzaV/71rwFmrdC8zZo2uJrFiOFu/blC0ch0QrxJh922xv980hw8d8hh/vXP3j8ni8EvHMt3PtJWP2kfx/O/ZEPt2v+AQuugPpaOOlqmPslv9/e9NLdcP9nfQg/639hxsWw9p+w4OP+7+bET8Jp/9UZgJ2D7Sth3XOw7d/+dY+Y6vs7Rov2bd+JNl8D2lUfSRGRAajPBbJdCmB2DdAEfIRDscmyP0jGoXGjDw5Nm6Gs2n8Rlw7bc/NnvMWHl+6WSbTCC7+Bf94I9W/42rip58FR7/HNstnrOef3v/FFH842LoENL3aGNMzXPO0SwPaBhXwYS7b5wNaVaLEPXbFSH8qaNu86v3ior8EsqvT9+gorfEh5+fe+fG//Fhx92a6vq70RHvwKLP6VD5XTLvBNvOlkECwTfrnCcr+9wkH+UVDu+xAmWn2QjLcEw+YgODZAW4Mfxpv8OqUjfO1lpgbzxd/C0j/A6OPhPT/b9RIu7Y3w0Fdh0W0w9EgfjjcshtrnfXN65j3LvFcW8s3kI6b5sBkr7ax9jZX4+XVrYfvrvoZ0xypo3ODfr7GnwPhTfWAfPF59H7Ol07B1BbzxDLzxL//ejz0Jxs+FEdPV309yLxn3/9cNqsnPZ3PbSlh+r/+/7Ih3BN10Dt0fcX0qkJlZCRByzjUGz/8OXAucAWzP6tQ/2Dn3he62pUDWT6QSvvZu8OH79kFzzp8gsXGJ72OXavc1LuFoMIz5IGAWNMNmKar0/elKhkFJla+5y3y5pZJ+W5n+fNEiHzB2//JrbwqabF/3w51r/Bdmax201UFrva8NHH0cnPO97q9B9+rf4L5P+VrGDAv71+LSvhw9Zj6wFZT5IBcr8WVq2uz/U8ve/twvw8mf3vPdJFY+DH++0oenqkn+ZJHRx/nhkIk+SG96GTYt9cPNS/1+9lTekmGdNYqVY/17tupxv33wNaqjj/Xlj5UEzerFfpho9e9nW10wrPfHqKDcv86CsiAwl/h5jZt9WZq2+Pc1lYTSKh9GS4d1Hvtokf9bicQ6/26c8+E880i0+dcUiQW1qMEjWrTr35cLmv1xnTW06WTn83A0uM1a5nUV+W4E8WYfnONN/nlbvf+7fuNf/vWCL3dhBWx71Y8XVsC4t/hHYYUP6Omk797gUn6ZUNTvMxTxQwsHNb6N/u833uSH4M/szgTpzPu4+2tyLujXWZK1bND9IbOPUMQ/Ml/emfUz5UpnlTOd9R5ZqHPdUMR/3iwcTA+GFu6s5e7YXrAtyNp/1P9fkk77H5OZz2jm4Vxn/9rMo3yU30YqHhyzoJY982MtUuCH4ei+BxPnOo9re4P/wQNZ71lwnLL/78o8QhFo3eFfR+NmP2zaBC07fb/iRFvnMJ3wPwzLR3Y+yqr933lBqT9JbG93jmneDrXP+b+9dc/5H2LJNv9/5ug5vhvD6OP9j+ZcdB1xDjYv8yFs+X2w5ZXO9yqd9J/bSWfBpHf5v/1I7OCXIY/6WiAbD/wpGI0Av3XOXWdmQ4C7gTHAWvxlL3Z0ty0FMulX0ikfMDJfnNnhNNHWWevVVu+bhEORznuoRouyvuhL9xxs482+Sblps/+CH3L43suVjPv/kAvLe/5akvFdm8TTCRg0uuttZJpBVz3u+w1ufGnXWr/s5vJQJKglrPDDcCwIFZkawUb/JR0u6AxeZSP8MBTxTdRNWzofmab1vmjIRDjsBBhzQnCCzjgfBBo3++bvVY/7R0Ptge0nWuK3G286GKXuZGE6+qXmhQW1uKnOSeFY5/u4c21wotR+bDdSEHTxsM4uHhbyXXEJwlpmukv50JtdjoMhWuIDUaSocxiO+C4YjRv33FoQKQzCdLH/aGVCcmbYGnythqK+O8joOb57xsYXfUjbvtLPD8egKPghmwnPmSCe+QGSSnQG3D1liVB41xCeSgR9n833L558Lkw+x/9I+PdDsOI+eO1h//9LtNj/IOsI7dZ5XDp+RLD3v8GOYwi7dG3J/JjIPJ9xMbz1G/t0mPZVnwpkB5MCmUg/51zQLNvqv3Sixd3XTjjnQ22koGe1GJmwmUr4WtFMrQhk1YIFw8wv9ESr30emVsKld/tSDvabqfnIfNF0rN+ya1NzOpFV41Ta+bwn98DNNOUn230It6wvR+hs9s6upYsWZ9WGZYX3dNp/yWVqzuLNfnrHawq+qFLxIGg3dy6XeR0dNYJBk3umK0HmB0amfNnvS+YHCK5z/Y5atGTnF2I63fncQn57oUjnNiHrdQa1by7tm9oytbLlozqXdc6H8p2rfU1tw3q/3eyaqXA0q7a0PavWtJ2OGsPMSVAdJ0TROS/TN7ejFjdriGUdn0RQMx/v/BtMxYO/yaSvwS8d7mu7yoZ3njS1J+m0//HRsN63IrTuyKoRbew8bplax+xjUz7K/wAYOavrfTRvg3XP+tqz1h1Bv91kVrBLv7nWL3Oc3vT3m35zralL+1r4SWf7H1JdSbTCqif8JaASLV2Ep3RWYM76++1S9jHMGmZqZTN/9xby3SumX7jn9/0gUCATERERybPuAtmh23NOREREpJ9QIBMRERHJMwUyERERkTxTIBMRERHJMwUyERERkTxTIBMRERHJMwUyERERkTxTIBMRERHJs359YVgz24q/zVKuDQW27XUp6Ut0zPofHbP+R8es/9Exy6/DnHNVXc3o14Gst5jZwj1dWVf6Jh2z/kfHrP/RMet/dMz6LjVZioiIiOSZApmIiIhInimQ9czP810A2Wc6Zv2Pjln/o2PW/+iY9VHqQyYiIiKSZ6ohExEREckzBTIRERGRPFMg64aZvcPMXjWzlWb2pXyXR97MzEab2WNm9oqZLTOzTwXTB5vZ383stWBYme+yyq7MLGxmL5jZX4LxcWb2bPB5+52ZxfJdRulkZhVm9gczW2Fmy83sBH3O+jYz+3Tw/+JSM7vTzAr1Oeu7FMj2wMzCwP8B7wSmAJeY2ZT8lkq6kAQ+65ybAhwPfCI4Tl8CHnHOTQQeCcalb/kUsDxr/NvA951zE4CdwIfzUirZkx8Cf3POTQJm4I+dPmd9lJmNAq4CZjvnpgJh4GL0OeuzFMj27DhgpXNulXMuDtwFzMtzmWQ3zrmNzrnFwfNG/JfEKPyxuj1Y7Hbg3XkpoHTJzGqAs4FfBOMGnA78IVhEx6wPMbNBwFuAWwCcc3HnXB36nPV1EaDIzCJAMbARfc76LAWyPRsFrMsarw2mSR9lZmOBWcCzwHDn3MZg1iZgeL7KJV36AfAFIB2MDwHqnHPJYFyft75lHLAVuC1oZv6FmZWgz1mf5ZxbD9wAvIEPYvXAIvQ567MUyOSQYGalwB+Bq51zDdnznL+2i67v0keY2TnAFufconyXRXosAhwN/NQ5NwtoZrfmSX3O+pagP988fJgeCZQA78hroaRbCmR7th4YnTVeE0yTPsbMovgwdodz7p5g8mYzqw7mVwNb8lU+eZOTgHPNbA2+K8Dp+P5JFUHTCujz1tfUArXOuWeD8T/gA5o+Z33XmcBq59xW51wCuAf/2dPnrI9SINuz54GJwRkpMXxnyHvzXCbZTdD36BZguXPue1mz7gUuC55fBvy5t8smXXPOfdk5V+OcG4v/XD3qnLsUeAy4IFhMx6wPcc5tAtaZ2ZHBpDOAV9DnrC97AzjezIqD/yczx0yfsz5KV+rvhpmdhe/rEgZudc5dl98Sye7M7GTgKeBlOvsjfQXfj+xuYAywFrjIObcjL4WUPTKzucDnnHPnmNl4fI3ZYOAF4P3OufY8Fk+ymNlM/EkYMWAVcDn+R70+Z32UmX0DeC/+bPQXgP/A9xnT56wPUiATERERyTM1WYqIiIjkmQKZiIiISJ4pkImIiIjkmQKZiIiISJ4pkImIiIjkmQKZiByyzCxlZi9mPQ7aza/NbKyZLT1Y2xORgS2y90VERPqtVufczHwXQkRkb1RDJiIDjpmtMbPvmNnLZvacmU0Ipo81s0fN7CUze8TMxgTTh5vZn8xsSfA4MdhU2MxuNrNlZvaQmRXl7UWJSL+mQCYih7Ki3Zos35s1r945Nw34Mf6OHAA/Am53zk0H7gBuDKbfCDzhnJuBv4fjsmD6ROD/nHNHAXXA+Tl9NSJyyNKV+kXkkGVmTc650i6mrwFOd86tCm5Ov8k5N8TMtgHVzrlEMH2jc26omW0FarJvMWNmY4G/O+cmBuNfBKLOuW/1wksTkUOMashEZKBye3i+L7LvAZhC/XJFZD8pkInIQPXerOEzwfOngYuD55fib1wP8AhwBYCZhc1sUG8VUkQGBv2aE5FDWZGZvZg1/jfnXObSF5Vm9hK+luuSYNqVwG1m9nlgK3B5MP1TwM/N7MP4mrArgI25LryIDBzqQyYiA07Qh2y2c25bvssiIgJqshQRERHJO9WQiYiIiOSZashERERE8kyBTERERCTPFMhERERE8kyBTERERCTPFMhERERE8uz/AzxvE+I7Ez2IAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 43.9260\n",
      "Decoding predictions...\n",
      "INFO:tensorflow:Restoring parameters from /home/undergrad/2026/wcarvalh/Documents/uvsq/cddd/cddd/data/default_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "predicted_embeddings = []\n",
    "test_losses = []\n",
    "test_loss = 0\n",
    "\n",
    "# Collect predicted embeddings from test set\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        pred = model(X_batch)\n",
    "        target = torch.ones(X_batch.size(0)).to(X_batch.device)\n",
    "        test_loss += loss_fn(pred, _, target).item()\n",
    "        predicted_embeddings.append(pred)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Decode embeddings\n",
    "#predicted_embeddings = torch.cat(predicted_embeddings, dim=0).cpu().numpy()\n",
    "\n",
    "# Decode using CDDD inference model\n",
    "print(\"Decoding predictions...\")\n",
    "#decoded_smiles = inference_model.emb_to_seq(predicted_embeddings)\n",
    "\n",
    "# Print every 100th decoded SMILES\n",
    "for i, smiles in enumerate(decoded_smiles):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"[{i}] {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as list of lists\n",
    "embedding_lists = [row.tolist() for row in predicted_embeddings]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"True_SMILES\": smiles_test,\n",
    "    \"Predicted_Emb\": embedding_lists\n",
    "})\n",
    "\n",
    "# Save as pickle (recommended for Python-only workflows)\n",
    "df.to_pickle(\"unprocessed_predictions.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14652\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_SMILES</th>\n",
       "      <th>Pred_SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1(C)C=C(CO)c2cc3c(c4c2N1CCC4)Oc1c2c4c(cc1=C3...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1ccc2sc(N(C)C)c(C(=O)c3ccc(OCCN4CCCCC4)cc3)...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCc1c(F)c(F)c(F)c(F)c1F</td>\n",
       "      <td>OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNc1cccc(C(=O)C(C)(C)C)c1</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=c1[nH]ccc2nn(C3CCNCC3)c(Nc3ccnc(F)c3)c12</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14647</th>\n",
       "      <td>O=C(C(=O)N1CCCCCC1)N(CCO)CCO</td>\n",
       "      <td>O=============================================...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14648</th>\n",
       "      <td>CCOC(=O)c1ccc(NC(=O)c2cc(-c3ccccc3)n(C)n2)cc1</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14649</th>\n",
       "      <td>C=CCS(=O)C[C@H](N)C(=O)O</td>\n",
       "      <td>CN[[[[[[[[N[[[[S[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>O=C(c1ccc2cc[nH]c2c1)N1CCC2(CC(Oc3cccnc3)CO2)C1</td>\n",
       "      <td>OOCCOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14651</th>\n",
       "      <td>CC(C#N)(c1ccccc1)c1ccccc1</td>\n",
       "      <td>C[[[[[[#[#####################################...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14652 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             True_SMILES  \\\n",
       "0      CC1(C)C=C(CO)c2cc3c(c4c2N1CCC4)Oc1c2c4c(cc1=C3...   \n",
       "1      COc1ccc2sc(N(C)C)c(C(=O)c3ccc(OCCN4CCCCC4)cc3)...   \n",
       "2                                OCc1c(F)c(F)c(F)c(F)c1F   \n",
       "3                              CNc1cccc(C(=O)C(C)(C)C)c1   \n",
       "4             O=c1[nH]ccc2nn(C3CCNCC3)c(Nc3ccnc(F)c3)c12   \n",
       "...                                                  ...   \n",
       "14647                       O=C(C(=O)N1CCCCCC1)N(CCO)CCO   \n",
       "14648      CCOC(=O)c1ccc(NC(=O)c2cc(-c3ccccc3)n(C)n2)cc1   \n",
       "14649                           C=CCS(=O)C[C@H](N)C(=O)O   \n",
       "14650    O=C(c1ccc2cc[nH]c2c1)N1CCC2(CC(Oc3cccnc3)CO2)C1   \n",
       "14651                          CC(C#N)(c1ccccc1)c1ccccc1   \n",
       "\n",
       "                                             Pred_SMILES  \n",
       "0      CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...  \n",
       "1      CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...  \n",
       "2      OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO...  \n",
       "3      CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...  \n",
       "4      CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...  \n",
       "...                                                  ...  \n",
       "14647  O=============================================...  \n",
       "14648  CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...  \n",
       "14649  CN[[[[[[[[N[[[[S[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[...  \n",
       "14650  OOCCOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO...  \n",
       "14651  C[[[[[[#[#####################################...  \n",
       "\n",
       "[14652 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "output_path = \"decoded_predictions.csv\"\n",
    "\n",
    "print(len(pd.read_csv(\"decoded_predictions.csv\")))\n",
    "existing_df = pd.read_csv(output_path)\n",
    "\n",
    "existing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from row 12000...\n",
      "INFO:tensorflow:Restoring parameters from /home/undergrad/2026/wcarvalh/Documents/uvsq/cddd/cddd/data/default_model/model.ckpt\n",
      "[Batch 13/13] Saved 826 predictions  Took 3032.32 sec\n",
      "\n",
      " All batches completed or resumed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "output_path = \"decoded_predictions.csv\"\n",
    "\n",
    "# Check how many rows are already saved (if any)\n",
    "if os.path.exists(output_path):\n",
    "    existing_df = pd.read_csv(output_path)\n",
    "    start_index = len(existing_df)\n",
    "    write_header = False\n",
    "    print(f\"Resuming from row {start_index}...\")\n",
    "else:\n",
    "    start_index = 0\n",
    "    write_header = True\n",
    "    print(\"Starting fresh...\")\n",
    "\n",
    "# Load from pickle\n",
    "df = pd.read_pickle(\"unprocessed_predictions.pkl\")\n",
    "\n",
    "# Convert list embeddings into NumPy array\n",
    "predicted_embeddings = np.stack(df[\"Predicted_Emb\"].values)\n",
    "true_smiles = df[\"True_SMILES\"].tolist()\n",
    "\n",
    "# Batch settings\n",
    "batch_size = 1000\n",
    "total = len(predicted_embeddings)\n",
    "total_batches = int(np.ceil(total / batch_size))\n",
    "\n",
    "# Loop from where we left off\n",
    "for i in range(start_index, total, batch_size):\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_end = min(i + batch_size, total)\n",
    "    batch_embs = predicted_embeddings[i:batch_end]\n",
    "    batch_true_smiles = true_smiles[i:batch_end]\n",
    "\n",
    "    # Decode\n",
    "    decoded = inference_model.emb_to_seq(batch_embs)\n",
    "\n",
    "    # Save\n",
    "    batch_df = pd.DataFrame({\n",
    "        \"True_SMILES\": batch_true_smiles,\n",
    "        \"Pred_SMILES\": decoded\n",
    "    })\n",
    "    batch_df.to_csv(output_path, mode='a', header=write_header, index=False)\n",
    "    write_header = False\n",
    "\n",
    "    # Timer\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"[Batch {i // batch_size + 1}/{total_batches}] Saved {len(batch_embs)} predictions  Took {elapsed:.2f} sec\")\n",
    "\n",
    "print(\"\\n All batches completed or resumed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
