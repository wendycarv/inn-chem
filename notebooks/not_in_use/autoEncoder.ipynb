{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import selfies as sf\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding for SMILES\n",
    "- **Input:** SMILES String, converted into SELFIES  \n",
    "- **Encoder:** Compress to low-dimensional latent vector  \n",
    "- **Decoder:** Reconstruct to original sequence  \n",
    "- **Goal:** Learn compact representation of SMILES that is invertible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 23.6473\n",
      "Epoch 2, Loss: 5.8407\n",
      "Epoch 3, Loss: 5.4546\n",
      "Epoch 4, Loss: 5.1361\n",
      "Epoch 5, Loss: 4.8057\n",
      "\n",
      "[Epoch 5] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → C=CC=CC=CC=C(CCNC=CC=CC=CC=CC=C)CCCCCC1=CC=CCCCCCCCC=2CC=21\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CCCCCCCCCCCCCCCCCCC=C\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC=CC=CCCNC=CC=CC=CCCNC=CC=CC=CC=CC=CC=CCCCC=C=CC#C\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → CCCCCNC=CC(C)C=CC=CC=CC=CC1CCCCCCCCCCCCCCC2CC21\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CCCCCCC=CC(N)C(C)C=CCCCCCCCCCCCCC=CC=CC=CC=CCCCCCCCC=C1CC1=CC\n",
      "Epoch 6, Loss: 4.5090\n",
      "Epoch 7, Loss: 4.2149\n",
      "Epoch 8, Loss: 3.9452\n",
      "Epoch 9, Loss: 3.6833\n",
      "Epoch 10, Loss: 3.3847\n",
      "\n",
      "[Epoch 10] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CCC=CC1=CC(=O)NC=CC=CC=CC1=C\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(C)CCCCCCCCC(=O)CCCC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC=CC(C=O)C=CC=CC=C1NC=CC=CC=C2C=CC1C2CCCCCC3C=C3\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → CCCCC(CCNC=O)C1CC=CCCN2CCCCCCCCCC2C1\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)OC(=O)CCN1C(=O)CCCC2C(=O)CCC2CC=CC(=C)C=CCCCC=CCCCCCCC=C1\n",
      "Epoch 11, Loss: 3.1316\n",
      "Epoch 12, Loss: 2.8912\n",
      "Epoch 13, Loss: 2.6625\n",
      "Epoch 14, Loss: 2.4666\n",
      "Epoch 15, Loss: 2.2431\n",
      "\n",
      "[Epoch 15] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CC(C=CC=CC(=O)N1C=CC=CC=CC1=C)CC=CF\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(C)CC(C)C(C)CCCC(C)C\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC(C(=O)C)OC=C1NC(=O)C=CC=COCC(C)CC=O\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → CCC=CC(C(C)C)C=CCC=CC(C1)=C1NC\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(C)C1(CC(=O)CCCC(CC)CC=CC1C=CC=CC=O)CC2C=C2C=C\n",
      "Epoch 16, Loss: 2.0580\n",
      "Epoch 17, Loss: 1.8919\n",
      "Epoch 18, Loss: 1.7212\n",
      "Epoch 19, Loss: 1.5790\n",
      "Epoch 20, Loss: 1.4242\n",
      "\n",
      "[Epoch 20] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C=CC=C(NC(=O)NC1=CC=CC=C1)C=C)S(C)(=O)C=CC=CC(C)F\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C(COC(C)CCC)Cl\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC(C(=O)[O-1])=CC=C1NC(=O)C=CC=COCC(C)CCCCC=CC\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → CSC=NC1=C(C=O)C(C)=C(N)C1CN=C2CC2\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(CC(=O)CC1CNC=C(C2CC1)C=NC2C=O)CCCCF\n",
      "Epoch 21, Loss: 1.2909\n",
      "Epoch 22, Loss: 1.1688\n",
      "Epoch 23, Loss: 1.0504\n",
      "Epoch 24, Loss: 0.9497\n",
      "Epoch 25, Loss: 0.8500\n",
      "\n",
      "[Epoch 25] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)NC=O\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C(C=NC(C)CCC)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1SC(=O)C=CC=C(OCC(C2)C)C2=N\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → C12ONN1C3=C(C(=O)C(C)=C(N)C3=O)N=CCC4CC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → C1C(C)(C)C=C1NC(=O)CCF\n",
      "Epoch 26, Loss: 0.7588\n",
      "Epoch 27, Loss: 0.6874\n",
      "Epoch 28, Loss: 0.6281\n",
      "Epoch 29, Loss: 0.5869\n",
      "Epoch 30, Loss: 0.5461\n",
      "\n",
      "[Epoch 30] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=CCC(=O)NC2=CC=CC=C2)C=C1S(=O)(=O)C3=CC4=C(S=5C=C4CCCON=5)S3\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C(C#CC(C)CCC)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1N2C(=O)C=CCC(C)CC(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → C1NCC(COC(N)=N)C2=C1C(=O)C(C)=C(N)C2=O\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)CCCN1C=C(C2CC2)C=NC1C3=CC=COC(F)(F)F)C(F)=C3\n",
      "Epoch 31, Loss: 0.5076\n",
      "Epoch 32, Loss: 0.4644\n",
      "Epoch 33, Loss: 0.4333\n",
      "Epoch 34, Loss: 0.3965\n",
      "Epoch 35, Loss: 0.3602\n",
      "\n",
      "[Epoch 35] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(CC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CC)ON=4)S3\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C(C#CC(C)CCC)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=C)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4CC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CN(C)COC(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C=O\n",
      "Epoch 36, Loss: 0.3436\n",
      "Epoch 37, Loss: 0.3169\n",
      "Epoch 38, Loss: 0.2942\n",
      "Epoch 39, Loss: 0.2817\n",
      "Epoch 40, Loss: 0.2416\n",
      "\n",
      "[Epoch 40] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NS(=O)NC2=CC=CC=C2)C=C1)S(=O)NC=O\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C=CC=C(OCC(C2)C)C2(Br)N\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → C1ON2C(COC(N)=N)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)N=NC=12)C=C4C=C(OC(F)CCF)C(F)=C4\n",
      "Epoch 41, Loss: 0.2445\n",
      "Epoch 42, Loss: 0.2460\n",
      "Epoch 43, Loss: 0.2729\n",
      "Epoch 44, Loss: 0.3089\n",
      "Epoch 45, Loss: 0.2836\n",
      "\n",
      "[Epoch 45] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C=CC=C(N1C(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C=O\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C(C#CC(C)CCC)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2CO\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 46, Loss: 0.3132\n",
      "Epoch 47, Loss: 0.2497\n",
      "Epoch 48, Loss: 0.2257\n",
      "Epoch 49, Loss: 0.1668\n",
      "Epoch 50, Loss: 0.1172\n",
      "\n",
      "[Epoch 50] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CCO)N=4)S3\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#CCC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=COCC(C)CC(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C=C(C(=O)C(C)=C(N3)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 51, Loss: 0.0985\n",
      "Epoch 52, Loss: 0.1110\n",
      "Epoch 53, Loss: 0.1344\n",
      "Epoch 54, Loss: 0.2520\n",
      "Epoch 55, Loss: 0.3783\n",
      "\n",
      "[Epoch 55] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NS(=O)NC2=CC=CC=C2)C=C1)S(=O)NC=O\n",
      "❌ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#CCCOC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → C1C=CC1([N+1](=O)[O-1])C\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → CCN1C(COC(N)=N)C2=C(C(=O)C(C)=C(N)C2=O)N1CC3NC3\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(N)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C=CC=CC=O\n",
      "Epoch 56, Loss: 0.3567\n",
      "Epoch 57, Loss: 0.2228\n",
      "Epoch 58, Loss: 0.1421\n",
      "Epoch 59, Loss: 0.0909\n",
      "Epoch 60, Loss: 0.0535\n",
      "\n",
      "[Epoch 60] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(NCO)N=4)S3\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=N)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(N)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 61, Loss: 0.0369\n",
      "Epoch 62, Loss: 0.0261\n",
      "Epoch 63, Loss: 0.0194\n",
      "Epoch 64, Loss: 0.0117\n",
      "Epoch 65, Loss: 0.0092\n",
      "\n",
      "[Epoch 65] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CCO)N=4)S3\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 66, Loss: 0.0095\n",
      "Epoch 67, Loss: 0.0148\n",
      "Epoch 68, Loss: 0.1905\n",
      "Epoch 69, Loss: 0.9108\n",
      "Epoch 70, Loss: 0.4437\n",
      "\n",
      "[Epoch 70] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → C=C(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C=O\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)O)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 71, Loss: 0.1737\n",
      "Epoch 72, Loss: 0.0670\n",
      "Epoch 73, Loss: 0.0321\n",
      "Epoch 74, Loss: 0.0111\n",
      "Epoch 75, Loss: 0.0036\n",
      "\n",
      "[Epoch 75] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CCO)N=4)S3\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 76, Loss: 0.0021\n",
      "Epoch 77, Loss: 0.0016\n",
      "Epoch 78, Loss: 0.0014\n",
      "Epoch 79, Loss: 0.0012\n",
      "Epoch 80, Loss: 0.0011\n",
      "\n",
      "[Epoch 80] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CCO)N=4)S3\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 81, Loss: 0.0010\n",
      "Epoch 82, Loss: 0.0009\n",
      "Epoch 83, Loss: 0.0008\n",
      "Epoch 84, Loss: 0.0007\n",
      "Epoch 85, Loss: 0.0006\n",
      "\n",
      "[Epoch 85] SMILES Reconstruction Test:\n",
      "❌ CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1 → CN(C1=CC=C(NC(=O)NC2=CC=CC=C2)C=C1)S(=O)(=O)C3=CC=C(C=4C=CN(CCO)N=4)S3\n",
      "✅ CC(O)CC(C)C#COC#CC(C)CC(C)O → CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "❌ Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1 → CC1=CC([N+1](=O)[O-1])=CC=C1NC(=O)C2=CC=C(OCC(C)C)C(Br)=C2\n",
      "❌ COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12 → COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC4NC42\n",
      "❌ CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1 → CC(C)(O)C(NC(=O)C=1C=NN2C=C(C3CC3)C=NC=12)C4=CC=C(OC(F)(F)F)C(F)=C4\n",
      "Epoch 86, Loss: 0.0006\n",
      "Epoch 87, Loss: 0.0005\n",
      "Epoch 88, Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "def tokenize_smiles(smiles, token2idx, max_len): \n",
    "    selfies_str = sf.encoder(smiles)\n",
    "    tokens = list(sf.split_selfies(selfies_str))\n",
    "    token_ids = [token2idx.get(tok, token2idx['[UNK]']) for tok in tokens]\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [token2idx['[PAD]']] * (max_len - len(token_ids))\n",
    "    return token_ids[:max_len]\n",
    "\n",
    "class SMILESAutoencoder(nn.Module): \n",
    "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=256, latent_dim=64, max_len=1801): \n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(max_len * embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, max_len * embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        embedded = self.embedding(x)  # (B, L, E)\n",
    "        flat = embedded.view(batch_size, -1)\n",
    "        latent = self.encoder(flat)  # (B, latent_dim)\n",
    "\n",
    "        # Normalize latent and append mu and std\n",
    "        mu = latent.mean(dim=1, keepdim=True)\n",
    "        std = latent.std(dim=1, keepdim=True) + 1e-8\n",
    "        norm_latent = (latent - mu) / std\n",
    "        latent_with_stats = torch.cat([norm_latent, mu, std], dim=1)  # (B, latent_dim + 2)\n",
    "\n",
    "        decoded_flat = self.decoder(latent)  # decode unnormalized latent\n",
    "        decoded_emb = decoded_flat.view(batch_size, self.max_len, -1)\n",
    "        logits = self.output(decoded_emb)  # (B, L, vocab_size)\n",
    "\n",
    "        return logits, latent_with_stats\n",
    "\n",
    "    def decode_from_latent(self, latent_with_stats, idx2token):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            norm_part = latent_with_stats[:-2]\n",
    "            mu = latent_with_stats[-2]\n",
    "            std = latent_with_stats[-1]\n",
    "            latent = norm_part * std + mu\n",
    "\n",
    "            decoded_flat = self.decoder(latent.unsqueeze(0))\n",
    "            decoded_emb = decoded_flat.view(1, self.max_len, -1)\n",
    "            logits = self.output(decoded_emb)\n",
    "            token_ids = logits.argmax(-1).squeeze(0).tolist()\n",
    "            tokens = [idx2token[i] for i in token_ids if idx2token[i] != '[PAD]']\n",
    "            selfies_str = ''.join(tokens)\n",
    "            return sf.decoder(selfies_str)\n",
    "\n",
    "# --- Build vocabulary from dataset ---\n",
    "token_counter = Counter()\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            selfies_str = sf.encoder(smiles)\n",
    "            tokens = list(sf.split_selfies(selfies_str))\n",
    "            token_counter.update(tokens)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "special_tokens = ['[PAD]', '[SOS]', '[EOS]', '[UNK]']\n",
    "unique_tokens = sorted(token_counter.keys())\n",
    "vocab = special_tokens + unique_tokens\n",
    "token2idx = {tok: i for i, tok in enumerate(vocab)}\n",
    "idx2token = {i: tok for tok, i in token2idx.items()}\n",
    "\n",
    "# --- Tokenize and pad SMILES ---\n",
    "smiles_list = []\n",
    "padded_sequences = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header line\n",
    "    for row in reader:\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            token_ids = tokenize_smiles(smiles, token2idx, max_len=1801)\n",
    "            padded_sequences.append(token_ids)\n",
    "            smiles_list.append(smiles)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "max_len = 1801\n",
    "X_tensor = torch.tensor(padded_sequences, dtype=torch.long)\n",
    "\n",
    "# --- Initialize model ---\n",
    "vocab_size = len(token2idx)\n",
    "model = SMILESAutoencoder(vocab_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Dataloader ---\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dataset = TensorDataset(X_tensor, X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# --- Training loop with checkpointing and evaluation ---\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(x_batch)\n",
    "        loss = loss_fn(logits.view(-1, vocab_size), y_batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:  # every 5 epochs\n",
    "        print(f\"\\n[Epoch {epoch+1}] SMILES Reconstruction Test:\")\n",
    "        test_smiles_list = smiles_list[:5]  # choose top 5 from dataset\n",
    "        for test_smiles in test_smiles_list:\n",
    "            try:\n",
    "                token_ids = tokenize_smiles(test_smiles, token2idx, max_len=1801)\n",
    "                input_tensor = torch.tensor([token_ids], dtype=torch.long)\n",
    "                _, latent_with_stats = model(input_tensor)\n",
    "                reconstructed_smiles = model.decode_from_latent(latent_with_stats.squeeze(0), idx2token)\n",
    "                match = \"✅\" if reconstructed_smiles == test_smiles else \"❌\"\n",
    "                print(f\"{match} {test_smiles} → {reconstructed_smiles}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Skipped {test_smiles}: {e}\")\n",
    "\n",
    "# --- Final test on top 5 molecules from your dataset ---\n",
    "print(\"\\n=== Final SMILES Reconstructions ===\")\n",
    "for test_smiles in smiles_list[:5]:\n",
    "    try:\n",
    "        token_ids = tokenize_smiles(test_smiles, token2idx, max_len=1801)\n",
    "        input_tensor = torch.tensor([token_ids], dtype=torch.long)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent_with_stats = model(input_tensor)\n",
    "        reconstructed_smiles = model.decode_from_latent(latent_with_stats.squeeze(0), idx2token)\n",
    "        match = \"✅\" if reconstructed_smiles == test_smiles else \"❌\"\n",
    "        print(f\"{match} {test_smiles} → {reconstructed_smiles}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipped {test_smiles}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
