{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import selfies as sf\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from cddd.inference import InferenceModel\n",
    "from cddd.preprocessing import preprocess_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From example/run_qsar_test.py:94: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0612 07:52:33.991996 136987095901696 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"example/run_qsar_test.py\", line 94, in <module>\n",
      "    tf.app.run(main=main, argv=[sys.argv[0]] + UNPARSED)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"example/run_qsar_test.py\", line 51, in main\n",
      "    infer_model = InferenceModel(model_dir, use_gpu=FLAGS.gpu, cpu_threads=FLAGS.cpu_threads)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/inference.py\", line 102, in __init__\n",
      "    self.hparams = create_hparams(flags)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/hyperparameters.py\", line 119, in create_hparams\n",
      "    hparams = hparams.parse_json(json.load(open(hparams_file_name)))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'cddd/pretrained_models/default_model/hparams.json'\n"
     ]
    }
   ],
   "source": [
    "!python3 example/run_qsar_test.py --model_dir cddd/pretrained_models/default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/run_cddd.py:99: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/run_cddd.py:55: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  sml_df = pd.read_table(file, header=None).rename({0:FLAGS.smiles_header, 1:\"EXTREG\"},\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/bin/cddd\", line 8, in <module>\n",
      "    sys.exit(main_wrapper())\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/run_cddd.py\", line 99, in main_wrapper\n",
      "    tf.app.run(main=main, argv=[sys.argv[0]] + UNPARSED)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/run_cddd.py\", line 67, in main\n",
      "    df = read_input(file)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/cddd/run_cddd.py\", line 55, in read_input\n",
      "    sml_df = pd.read_table(file, header=None).rename({0:FLAGS.smiles_header, 1:\"EXTREG\"},\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/undergrad/2026/melkoudi/miniconda3/envs/tf110/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'smiles.smi' does not exist: b'smiles.smi'\n"
     ]
    }
   ],
   "source": [
    "!cddd --input smiles.smi --output descriptors.csv  --smiles_header smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smiles Embedding:\n",
    "### Use cddd to encode smiles (yippeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cddd/data/default_model/model.ckpt\n",
      "SMILES: CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c2ccn(CCO)n2)s1\n",
      "Embedding: [-0.6485799  -0.4820745  -0.29993665  0.2840209  -0.19669785  0.23079348\n",
      " -0.45663777 -0.50177956 -0.06138841  0.28148285]...\n",
      "\n",
      "SMILES: CC(O)CC(C)C#COC#CC(C)CC(C)O\n",
      "Embedding: [-0.23311913 -0.62234724 -0.14250664  0.38820195  0.27778637 -0.15076475\n",
      "  0.01024481 -0.58167255 -0.23104398 -0.5806556 ]...\n",
      "\n",
      "SMILES: Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(Br)c1\n",
      "Embedding: [-0.47915938 -0.5277588   0.254828   -0.35512787 -0.01809985  0.02691496\n",
      " -0.17222045 -0.12126444  0.45158276  0.21312533]...\n",
      "\n",
      "SMILES: COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12\n",
      "Embedding: [ 0.95607096 -0.4094612   0.5092193   0.33736256  0.11703882  0.35932195\n",
      "  0.7206423  -0.6761475  -0.16922899  0.69493043]...\n",
      "\n",
      "SMILES: CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(F)(F)F)c(F)c1\n",
      "Embedding: [-0.8880903   0.08556144  0.20473011  0.1794778   0.02583974 -0.44063422\n",
      "  0.29907465  0.09121753 -0.60350114 -0.2038508 ]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a smiles list of 6000\n",
    "smiles_list = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header line\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 6000:\n",
    "            break\n",
    "        smiles = row[0].strip()\n",
    "        try:\n",
    "            smiles_list.append(smiles)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# make instance of autoencoder model\n",
    "inference_model = InferenceModel(model_dir=\"cddd/data/default_model\")\n",
    "\n",
    "# embed the smiles\n",
    "smiles_embedding = inference_model.seq_to_emb(smiles_list)\n",
    "\n",
    "# print example to see if it works\n",
    "for i in range(5):\n",
    "    print(f\"SMILES: {smiles_list[i]}\") # full smiles\n",
    "    print(f\"Embedding: {smiles_embedding[i][:10]}...\\n\")  # print first 10 values of the embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize & Smooth Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized spectra shape: (3568, 1801)\n",
      "Sample normalized spectrum: [0.10808033 0.10908509 0.1097319  0.11094673 0.11241841 0.11278684\n",
      " 0.11332587 0.11278429 0.11410056 0.11418134]\n",
      "Smoothed spectra shape: (3568, 1801)\n",
      "Example smoothed spectrum: [0.10755056 0.10928005 0.11052331 0.11138647 0.11197562 0.11239689\n",
      " 0.11275636 0.11316016 0.11389765 0.11500437]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "spec_len = 1801 \n",
    "spectra_list = []\n",
    "\n",
    "with open(\"computed_spectra.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 6000:\n",
    "            break\n",
    "        try:\n",
    "            spectrum = [float(x) for x in row[1:]]\n",
    "            if len(spectrum) == spec_len:\n",
    "                spectra_list.append(spectrum)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "# conver to np array\n",
    "spectra_array = np.array(spectra_list)\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler()\n",
    "normalized_spectra = scaler.fit_transform(spectra_array)\n",
    "\n",
    "# check if normalization worked \n",
    "print(\"Normalized spectra shape:\", normalized_spectra.shape)\n",
    "print(\"Sample normalized spectrum:\", normalized_spectra[0][:10])\n",
    "\n",
    "# Smooth each spectrum\n",
    "smoothed_spectra = [savgol_filter(spectrum, window_length=15, polyorder=3) for spectrum in normalized_spectra]\n",
    "\n",
    "# covert back to np array\n",
    "smoothed_spectra = np.array(smoothed_spectra)\n",
    "\n",
    "# check if smoothing worked\n",
    "print(\"Smoothed spectra shape:\", smoothed_spectra.shape)\n",
    "print(\"Example smoothed spectrum:\", smoothed_spectra[0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad Smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def pad_to_even_dim(arr, target_dim=1802):\\n    if arr.shape[1] < target_dim:\\n        padding = np.ones((arr.shape[0], target_dim - arr.shape[1]))\\n        return np.concatenate([arr, padding], axis=1)\\n    else:\\n        return arr[:, :target_dim]'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_embeddings(embeddings, target_dim=1802):\n",
    "    current_dim = embeddings.shape[1]\n",
    "    if current_dim >= target_dim:\n",
    "        return embeddings[:, :target_dim]  # truncate if too long\n",
    "    padding = np.ones((embeddings.shape[0], target_dim - current_dim*2))*2\n",
    "    return np.concatenate([embeddings, padding, embeddings], axis=1)\n",
    "\n",
    "X_padded = pad_embeddings(smiles_embedding, target_dim=1802)  # shape (6000, 1801)\n",
    "\n",
    "\"\"\"def pad_to_even_dim(arr, target_dim=1802):\n",
    "    if arr.shape[1] < target_dim:\n",
    "        padding = np.ones((arr.shape[0], target_dim - arr.shape[1]))\n",
    "        return np.concatenate([arr, padding], axis=1)\n",
    "    else:\n",
    "        return arr[:, :target_dim]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train & test sets :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (60%), val (20%), test (20%)\n",
    "min_len = min(len(X_padded), len(Y))\n",
    "X_padded = X_padded[:min_len]\n",
    "Y = Y[:min_len]\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X_padded, Y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Concatenate [X | Y]\n",
    "Z_train = np.concatenate([X_train, Y_train], axis=1)\n",
    "Z_val = np.concatenate([X_val, Y_val], axis=1)\n",
    "Z_test = np.concatenate([X_test, Y_test], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmilesSpectraDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx): return self.data[idx]\n",
    "\n",
    "train_loader = DataLoader(SmilesSpectraDataset(Z_train), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(SmilesSpectraDataset(Z_val), batch_size=64)   \n",
    "test_loader = DataLoader(SmilesSpectraDataset(Z_test), batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1802])\n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1538, 0.4912, 0.4007,  ...,    nan,    nan,    nan],\n",
       "        [0.8673, 0.5135, 0.7393,  ...,    nan,    nan,    nan],\n",
       "        [0.5837, 0.6717, 0.2780,  ...,    nan,    nan,    nan],\n",
       "        ...,\n",
       "        [0.1179, 0.5299, 0.4148,  ...,    nan,    nan,    nan],\n",
       "        [0.0615, 0.9482, 0.9723,  ...,    nan,    nan,    nan],\n",
       "        [0.0941, 0.1770, 0.5320,  ...,    nan,    nan,    nan]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.tensor(Z_train[0][:1802], dtype=torch.float32).reshape((-1, 1802))\n",
    "print(sample.shape)\n",
    "sample2 = torch.rand((32, 1802))\n",
    "print(sample[:,512:1024])\n",
    "model(sample2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, model_spectra, target_spectra):\n",
    "        loss = torch.ones_like(target_spectra)\n",
    "\n",
    "        loss = torch.mul(torch.log(torch.div(model_spectra, target_spectra)), model_spectra) \\\n",
    "            + torch.mul(torch.log(torch.div(target_spectra, model_spectra)), target_spectra)\n",
    "        loss = torch.sum(loss, dim=1)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., nan, nan,  ..., nan, nan, nan],\n",
      "        [0., nan, nan,  ..., nan, nan, nan],\n",
      "        [0., nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [0., nan, nan,  ..., nan, nan, nan],\n",
      "        [0., nan, nan,  ..., nan, nan, nan],\n",
      "        [0., nan, nan,  ..., nan, nan, nan]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    for batch in train_loader:\n",
    "        break\n",
    "    x_batch = batch[:, :1802]\n",
    "    y_batch = batch[:, 1802:]\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_batch)\n",
    "    print(y_pred[:, 900:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INN Model: (RealNVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8934,  0.0882, -0.1884,  ...,  1.3110,  0.5481,  1.6134],\n",
      "        [-0.7205,  0.2731, -0.5231,  ...,  0.2383,  0.5150, -0.5727],\n",
      "        [-0.8543, -0.1021,  0.1381,  ...,  0.2090,  0.2775,  0.4625],\n",
      "        ...,\n",
      "        [-0.8867, -0.4088, -0.5815,  ...,  0.6586,  0.6793,  0.2200],\n",
      "        [ 0.1606, -0.4492,  0.7752,  ..., -0.0997,  0.2966,  0.9169],\n",
      "        [-0.4706, -0.3259,  0.4242,  ..., -0.4137,  0.9357,  0.3206]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0973, 0.0982, 0.0989,  ..., 0.0873, 0.0862, 0.0000],\n",
      "        [0.0734, 0.0744, 0.0751,  ..., 0.0662, 0.0653, 0.0000],\n",
      "        [0.0852, 0.0860, 0.0865,  ..., 0.0616, 0.0605, 0.0000],\n",
      "        ...,\n",
      "        [0.1431, 0.1445, 0.1453,  ..., 0.0559, 0.0543, 0.0000],\n",
      "        [0.0653, 0.0667, 0.0677,  ..., 0.1556, 0.1560, 0.0000],\n",
      "        [0.0614, 0.0622, 0.0628,  ..., 0.1004, 0.0993, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6590,  0.5302, -0.4639,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5757,  0.1780,  0.2390,  ...,     nan,     nan,     nan],\n",
      "        [-0.8395, -0.1318,  0.4437,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3644, -0.2595, -0.0679,  ...,     nan,     nan,     nan],\n",
      "        [-0.5130, -0.1541,  0.5892,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6210, -0.4933,  0.3805,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0767, 0.0775, 0.0780,  ..., 0.0664, 0.0653, 0.0000],\n",
      "        [0.1201, 0.1212, 0.1219,  ..., 0.1121, 0.1115, 0.0000],\n",
      "        [0.1587, 0.1611, 0.1627,  ..., 0.0591, 0.0581, 0.0000],\n",
      "        ...,\n",
      "        [0.0417, 0.0420, 0.0421,  ..., 0.0593, 0.0578, 0.0000],\n",
      "        [0.0766, 0.0775, 0.0783,  ..., 0.0797, 0.0784, 0.0000],\n",
      "        [0.1064, 0.1077, 0.1088,  ..., 0.1021, 0.1012, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6602,  0.1017,  0.0500,  ...,     nan,     nan,     nan],\n",
      "        [-0.3974, -0.5134, -0.0073,  ...,     nan,     nan,     nan],\n",
      "        [-0.7496,  0.3702,  0.0686,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.0082, -0.5067,  0.3006,  ...,     nan,     nan,     nan],\n",
      "        [-0.1118,  0.4969,  0.3050,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2107, -0.7254, -0.1417,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1947, 0.1968, 0.1984,  ..., 0.0812, 0.0797, 0.0000],\n",
      "        [0.1514, 0.1539, 0.1556,  ..., 0.0661, 0.0651, 0.0000],\n",
      "        [0.0956, 0.0968, 0.0975,  ..., 0.0885, 0.0873, 0.0000],\n",
      "        ...,\n",
      "        [0.0174, 0.0178, 0.0181,  ..., 0.0762, 0.0754, 0.0000],\n",
      "        [0.1291, 0.1296, 0.1299,  ..., 0.0626, 0.0613, 0.0000],\n",
      "        [0.0924, 0.0933, 0.0940,  ..., 0.1345, 0.1321, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7624,  0.5875,  0.4304,  ...,     nan,     nan,     nan],\n",
      "        [-0.6929,  0.1181, -0.2378,  ...,     nan,     nan,     nan],\n",
      "        [-0.3072,  0.4894, -0.0082,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8512, -0.2715, -0.4779,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2761,  0.0514, -0.5928,  ...,     nan,     nan,     nan],\n",
      "        [-0.7412, -0.2212,  0.2468,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1382, 0.1397, 0.1407,  ..., 0.1004, 0.0995, 0.0000],\n",
      "        [0.1153, 0.1166, 0.1176,  ..., 0.0682, 0.0674, 0.0000],\n",
      "        [0.1138, 0.1147, 0.1153,  ..., 0.0526, 0.0516, 0.0000],\n",
      "        ...,\n",
      "        [0.1292, 0.1299, 0.1301,  ..., 0.0764, 0.0750, 0.0000],\n",
      "        [0.0397, 0.0403, 0.0407,  ..., 0.0690, 0.0678, 0.0000],\n",
      "        [0.1694, 0.1723, 0.1743,  ..., 0.0705, 0.0695, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.9733,  0.1320, -0.4447,  ...,     nan,     nan,     nan],\n",
      "        [-0.4903, -0.0032,  0.5440,  ...,     nan,     nan,     nan],\n",
      "        [-0.8424, -0.2875, -0.1792,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.4200, -0.2322,  0.2640,  ...,     nan,     nan,     nan],\n",
      "        [-0.7942, -0.5404,  0.6945,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9680,  0.2150, -0.3948,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0598, 0.0603, 0.0607,  ..., 0.0842, 0.0830, 0.0000],\n",
      "        [0.0830, 0.0842, 0.0852,  ..., 0.1097, 0.1084, 0.0000],\n",
      "        [0.1915, 0.1930, 0.1940,  ..., 0.1184, 0.1166, 0.0000],\n",
      "        ...,\n",
      "        [0.1049, 0.1060, 0.1069,  ..., 0.1159, 0.1148, 0.0000],\n",
      "        [0.1558, 0.1568, 0.1573,  ..., 0.1375, 0.1365, 0.0000],\n",
      "        [0.0775, 0.0788, 0.0797,  ..., 0.0940, 0.0920, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6301,  0.0534,  0.5155,  ...,     nan,     nan,     nan],\n",
      "        [-0.6628, -0.0873,  0.6045,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1604,  0.5269, -0.6025,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7415,  0.5612,  0.0676,  ...,     nan,     nan,     nan],\n",
      "        [-0.0083, -0.5735,  0.7399,  ...,     nan,     nan,     nan],\n",
      "        [-0.8201, -0.1839,  0.2714,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0713, 0.0717, 0.0720,  ..., 0.0592, 0.0583, 0.0000],\n",
      "        [0.1031, 0.1042, 0.1049,  ..., 0.0528, 0.0519, 0.0000],\n",
      "        [0.0715, 0.0721, 0.0723,  ..., 0.0732, 0.0720, 0.0000],\n",
      "        ...,\n",
      "        [0.1018, 0.1029, 0.1037,  ..., 0.1076, 0.1064, 0.0000],\n",
      "        [0.0652, 0.0661, 0.0667,  ..., 0.0907, 0.0896, 0.0000],\n",
      "        [0.1377, 0.1398, 0.1413,  ..., 0.0983, 0.0974, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.1190,  0.5855,  0.1321,  ...,     nan,     nan,     nan],\n",
      "        [-0.5388,  0.1040, -0.0729,  ...,     nan,     nan,     nan],\n",
      "        [-0.5645,  0.5031,  0.5900,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3368, -0.2776,  0.4685,  ...,     nan,     nan,     nan],\n",
      "        [-0.8064,  0.2651, -0.0861,  ...,     nan,     nan,     nan],\n",
      "        [-0.6046,  0.1625, -0.2060,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1111, 0.1120, 0.1126,  ..., 0.0660, 0.0645, 0.0000],\n",
      "        [0.0878, 0.0891, 0.0900,  ..., 0.0742, 0.0726, 0.0000],\n",
      "        [0.0561, 0.0565, 0.0568,  ..., 0.0723, 0.0712, 0.0000],\n",
      "        ...,\n",
      "        [0.0891, 0.0900, 0.0907,  ..., 0.0602, 0.0594, 0.0000],\n",
      "        [0.0520, 0.0526, 0.0530,  ..., 0.0545, 0.0533, 0.0000],\n",
      "        [0.1161, 0.1170, 0.1175,  ..., 0.0910, 0.0901, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.4278, -0.5812,  0.1182,  ...,     nan,     nan,     nan],\n",
      "        [-0.4018,  0.2235,  0.0789,  ...,     nan,     nan,     nan],\n",
      "        [-0.8611,  0.1286, -0.2025,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.2029,  0.7237, -0.7530,  ...,     nan,     nan,     nan],\n",
      "        [-0.4314, -0.1639,  0.1700,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2630, -0.5968, -0.0258,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1281, 0.1296, 0.1307,  ..., 0.0688, 0.0678, 0.0000],\n",
      "        [0.0746, 0.0753, 0.0759,  ..., 0.0585, 0.0575, 0.0000],\n",
      "        [0.0518, 0.0528, 0.0535,  ..., 0.1092, 0.1084, 0.0000],\n",
      "        ...,\n",
      "        [0.3006, 0.3032, 0.3049,  ..., 0.0955, 0.0941, 0.0000],\n",
      "        [0.1062, 0.1076, 0.1085,  ..., 0.0748, 0.0739, 0.0000],\n",
      "        [0.1820, 0.1843, 0.1857,  ..., 0.0747, 0.0732, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.1925,  0.0309, -0.1080,  ...,     nan,     nan,     nan],\n",
      "        [-0.5309,  0.2359, -0.1390,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6571,  0.5544,  0.1557,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6727, -0.2126, -0.1985,  ...,     nan,     nan,     nan],\n",
      "        [-0.3720,  0.4291, -0.3610,  ...,     nan,     nan,     nan],\n",
      "        [-0.8119,  0.0409,  0.2440,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1492, 0.1499, 0.1502,  ..., 0.0640, 0.0627, 0.0000],\n",
      "        [0.0627, 0.0638, 0.0647,  ..., 0.0542, 0.0529, 0.0000],\n",
      "        [0.0671, 0.0678, 0.0683,  ..., 0.0663, 0.0655, 0.0000],\n",
      "        ...,\n",
      "        [0.1205, 0.1218, 0.1227,  ..., 0.1010, 0.0990, 0.0000],\n",
      "        [0.0626, 0.0631, 0.0634,  ..., 0.0671, 0.0663, 0.0000],\n",
      "        [0.1326, 0.1336, 0.1343,  ..., 0.1428, 0.1411, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.2292,  0.2163,  0.1947,  ...,     nan,     nan,     nan],\n",
      "        [-0.7347, -0.4969,  0.6127,  ...,     nan,     nan,     nan],\n",
      "        [-0.1276, -0.0502, -0.3583,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5067, -0.3893, -0.3922,  ...,     nan,     nan,     nan],\n",
      "        [-0.0027,  0.6839,  0.1181,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4925, -0.1173, -0.1017,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1134, 0.1148, 0.1157,  ..., 0.0755, 0.0740, 0.0000],\n",
      "        [0.2595, 0.2617, 0.2631,  ..., 0.0882, 0.0873, 0.0000],\n",
      "        [0.2364, 0.2390, 0.2406,  ..., 0.1150, 0.1142, 0.0000],\n",
      "        ...,\n",
      "        [0.1015, 0.1024, 0.1028,  ..., 0.0224, 0.0216, 0.0000],\n",
      "        [0.1782, 0.1806, 0.1824,  ..., 0.1171, 0.1160, 0.0000],\n",
      "        [0.1017, 0.1028, 0.1036,  ..., 0.1366, 0.1340, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.2397,  0.0775,  0.2757,  ...,     nan,     nan,     nan],\n",
      "        [-0.1917, -0.4582,  0.3794,  ...,     nan,     nan,     nan],\n",
      "        [-0.8545,  0.4249,  0.6326,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.9169,  0.1524, -0.7768,  ...,     nan,     nan,     nan],\n",
      "        [-0.7152, -0.4050,  0.4383,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8215,  0.3006,  0.8098,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1154, 0.1168, 0.1179,  ..., 0.1283, 0.1275, 0.0000],\n",
      "        [0.1079, 0.1086, 0.1089,  ..., 0.0462, 0.0452, 0.0000],\n",
      "        [0.1303, 0.1315, 0.1322,  ..., 0.0849, 0.0837, 0.0000],\n",
      "        ...,\n",
      "        [0.0493, 0.0502, 0.0509,  ..., 0.0828, 0.0813, 0.0000],\n",
      "        [0.1028, 0.1043, 0.1054,  ..., 0.1438, 0.1419, 0.0000],\n",
      "        [0.0705, 0.0715, 0.0723,  ..., 0.1862, 0.1852, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0713,  0.3168, -0.1012,  ...,     nan,     nan,     nan],\n",
      "        [-0.3671, -0.1195, -0.2538,  ...,     nan,     nan,     nan],\n",
      "        [-0.8586, -0.5749, -0.8107,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.2876, -0.0511, -0.4228,  ...,     nan,     nan,     nan],\n",
      "        [-0.8483,  0.7139,  0.5323,  ...,     nan,     nan,     nan],\n",
      "        [-0.7321,  0.2304, -0.3317,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0722, 0.0732, 0.0738,  ..., 0.0903, 0.0891, 0.0000],\n",
      "        [0.1300, 0.1318, 0.1333,  ..., 0.1325, 0.1311, 0.0000],\n",
      "        [0.0781, 0.0790, 0.0797,  ..., 0.0963, 0.0953, 0.0000],\n",
      "        ...,\n",
      "        [0.0628, 0.0637, 0.0642,  ..., 0.0904, 0.0893, 0.0000],\n",
      "        [0.0898, 0.0907, 0.0912,  ..., 0.0820, 0.0808, 0.0000],\n",
      "        [0.0907, 0.0915, 0.0920,  ..., 0.0546, 0.0535, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8300, -0.0280,  0.0066,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8660,  0.0622,  0.0723,  ...,     nan,     nan,     nan],\n",
      "        [-0.5577, -0.4173,  0.0987,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.6202,  0.2637,  0.6857,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9239,  0.7382, -0.0540,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8409, -0.0536,  0.7888,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0822, 0.0830, 0.0836,  ..., 0.1016, 0.1007, 0.0000],\n",
      "        [0.0544, 0.0551, 0.0556,  ..., 0.0854, 0.0844, 0.0000],\n",
      "        [0.1374, 0.1385, 0.1391,  ..., 0.1252, 0.1240, 0.0000],\n",
      "        ...,\n",
      "        [0.0858, 0.0867, 0.0875,  ..., 0.0798, 0.0790, 0.0000],\n",
      "        [0.0676, 0.0684, 0.0689,  ..., 0.0811, 0.0800, 0.0000],\n",
      "        [0.0837, 0.0845, 0.0851,  ..., 0.0748, 0.0737, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.5945, -0.1125, -0.3565,  ...,     nan,     nan,     nan],\n",
      "        [-0.5497, -0.6448, -0.3994,  ...,     nan,     nan,     nan],\n",
      "        [-0.1282,  0.0469, -0.1639,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.2157, -0.3009, -0.1963,  ...,     nan,     nan,     nan],\n",
      "        [-0.2334, -0.1116,  0.1298,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0318, -0.2631,  0.4032,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1693, 0.1710, 0.1721,  ..., 0.1607, 0.1589, 0.0000],\n",
      "        [0.0297, 0.0301, 0.0304,  ..., 0.1183, 0.1176, 0.0000],\n",
      "        [0.2031, 0.2043, 0.2050,  ..., 0.2210, 0.2190, 0.0000],\n",
      "        ...,\n",
      "        [0.1204, 0.1227, 0.1244,  ..., 0.0781, 0.0768, 0.0000],\n",
      "        [0.1604, 0.1621, 0.1632,  ..., 0.0765, 0.0754, 0.0000],\n",
      "        [0.0678, 0.0680, 0.0682,  ..., 0.0834, 0.0821, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8791,  0.0286, -0.3715,  ...,     nan,     nan,     nan],\n",
      "        [-0.7947,  0.2001,  0.1671,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3973,  0.4096,  0.2760,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.9333,  0.2452,  0.2879,  ...,     nan,     nan,     nan],\n",
      "        [-0.8074, -0.0202,  0.3843,  ...,     nan,     nan,     nan],\n",
      "        [-0.7049, -0.5286,  0.5055,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2670, 0.2707, 0.2735,  ..., 0.1185, 0.1166, 0.0000],\n",
      "        [0.1394, 0.1410, 0.1421,  ..., 0.0703, 0.0687, 0.0000],\n",
      "        [0.0763, 0.0765, 0.0766,  ..., 0.0557, 0.0548, 0.0000],\n",
      "        ...,\n",
      "        [0.0912, 0.0923, 0.0932,  ..., 0.0752, 0.0741, 0.0000],\n",
      "        [0.2026, 0.2043, 0.2055,  ..., 0.0872, 0.0862, 0.0000],\n",
      "        [0.0469, 0.0478, 0.0486,  ..., 0.0714, 0.0704, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8279,  0.0936, -0.1788,  ...,     nan,     nan,     nan],\n",
      "        [-0.2659, -0.7944,  0.2951,  ...,     nan,     nan,     nan],\n",
      "        [-0.3722,  0.5248, -0.0203,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.4892,  0.0457, -0.6296,  ...,     nan,     nan,     nan],\n",
      "        [-0.9595,  0.1895,  0.0289,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7764, -0.4527, -0.3226,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0875, 0.0885, 0.0892,  ..., 0.1292, 0.1279, 0.0000],\n",
      "        [0.1440, 0.1459, 0.1471,  ..., 0.0860, 0.0850, 0.0000],\n",
      "        [0.1461, 0.1475, 0.1485,  ..., 0.0935, 0.0922, 0.0000],\n",
      "        ...,\n",
      "        [0.0386, 0.0389, 0.0391,  ..., 0.0993, 0.0978, 0.0000],\n",
      "        [0.1477, 0.1486, 0.1493,  ..., 0.1952, 0.1941, 0.0000],\n",
      "        [0.0737, 0.0745, 0.0750,  ..., 0.0665, 0.0654, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6108, -0.5333,  0.7457,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9484, -0.5124,  0.8624,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2977, -0.0357,  0.8728,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1282, -0.3451,  0.1585,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5877,  0.1758, -0.3024,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2499, -0.4601, -0.6120,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0989, 0.0990, 0.0989,  ..., 0.0911, 0.0903, 0.0000],\n",
      "        [0.1490, 0.1501, 0.1507,  ..., 0.0768, 0.0749, 0.0000],\n",
      "        [0.1669, 0.1689, 0.1703,  ..., 0.0725, 0.0715, 0.0000],\n",
      "        ...,\n",
      "        [0.1367, 0.1391, 0.1409,  ..., 0.0861, 0.0853, 0.0000],\n",
      "        [0.1247, 0.1258, 0.1266,  ..., 0.0930, 0.0921, 0.0000],\n",
      "        [0.0416, 0.0419, 0.0421,  ..., 0.0768, 0.0760, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4749,  0.1721,  0.4916,  ...,     nan,     nan,     nan],\n",
      "        [-0.6431, -0.3051,  0.2407,  ...,     nan,     nan,     nan],\n",
      "        [-0.3316,  0.2851, -0.3232,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8383, -0.5334, -0.1592,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7723, -0.6183,  0.6152,  ...,     nan,     nan,     nan],\n",
      "        [-0.5368, -0.7341,  0.5995,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0599, 0.0606, 0.0610,  ..., 0.0883, 0.0872, 0.0000],\n",
      "        [0.0275, 0.0276, 0.0276,  ..., 0.0867, 0.0858, 0.0000],\n",
      "        [0.0784, 0.0792, 0.0796,  ..., 0.1054, 0.1041, 0.0000],\n",
      "        ...,\n",
      "        [0.0871, 0.0880, 0.0887,  ..., 0.1132, 0.1123, 0.0000],\n",
      "        [0.0610, 0.0616, 0.0619,  ..., 0.0708, 0.0697, 0.0000],\n",
      "        [0.0780, 0.0787, 0.0792,  ..., 0.0824, 0.0814, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.4574, -0.0774,  0.8522,  ...,     nan,     nan,     nan],\n",
      "        [-0.2680, -0.5776,  0.3753,  ...,     nan,     nan,     nan],\n",
      "        [-0.3326, -0.6761,  0.1930,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7355, -0.0294, -0.0431,  ...,     nan,     nan,     nan],\n",
      "        [-0.6936, -0.4477, -0.1271,  ...,     nan,     nan,     nan],\n",
      "        [-0.8456,  0.0489, -0.3723,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1605, 0.1619, 0.1628,  ..., 0.1444, 0.1427, 0.0000],\n",
      "        [0.1610, 0.1628, 0.1638,  ..., 0.1196, 0.1177, 0.0000],\n",
      "        [0.0953, 0.0962, 0.0967,  ..., 0.0573, 0.0565, 0.0000],\n",
      "        ...,\n",
      "        [0.1592, 0.1605, 0.1612,  ..., 0.1129, 0.1116, 0.0000],\n",
      "        [0.1583, 0.1600, 0.1612,  ..., 0.1953, 0.1936, 0.0000],\n",
      "        [0.1552, 0.1569, 0.1581,  ..., 0.0636, 0.0625, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8739,  0.1460, -0.6235,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2149, -0.1628, -0.3970,  ...,     nan,     nan,     nan],\n",
      "        [-0.5369,  0.1251,  0.0529,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7710,  0.3009,  0.6040,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6196, -0.0149,  0.5544,  ...,     nan,     nan,     nan],\n",
      "        [-0.2254,  0.5412, -0.3041,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0967, 0.0978, 0.0986,  ..., 0.0753, 0.0743, 0.0000],\n",
      "        [0.1487, 0.1514, 0.1536,  ..., 0.0755, 0.0741, 0.0000],\n",
      "        [0.0979, 0.0989, 0.0996,  ..., 0.0791, 0.0784, 0.0000],\n",
      "        ...,\n",
      "        [0.1844, 0.1858, 0.1864,  ..., 0.1010, 0.1000, 0.0000],\n",
      "        [0.0803, 0.0812, 0.0817,  ..., 0.0816, 0.0806, 0.0000],\n",
      "        [0.1142, 0.1150, 0.1156,  ..., 0.0808, 0.0794, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5308, -0.0410, -0.0677,  ...,     nan,     nan,     nan],\n",
      "        [-0.4262,  0.3079, -0.7202,  ...,     nan,     nan,     nan],\n",
      "        [-0.0603, -0.0623,  0.4828,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3947, -0.0244, -0.1506,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1813,  0.7453, -0.5517,  ...,     nan,     nan,     nan],\n",
      "        [-0.7762,  0.5112,  0.1477,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1447, 0.1464, 0.1475,  ..., 0.1052, 0.1042, 0.0000],\n",
      "        [0.0864, 0.0874, 0.0880,  ..., 0.0622, 0.0613, 0.0000],\n",
      "        [0.0670, 0.0682, 0.0691,  ..., 0.1001, 0.0989, 0.0000],\n",
      "        ...,\n",
      "        [0.0561, 0.0566, 0.0569,  ..., 0.0631, 0.0616, 0.0000],\n",
      "        [0.1429, 0.1447, 0.1461,  ..., 0.0818, 0.0806, 0.0000],\n",
      "        [0.0917, 0.0928, 0.0936,  ..., 0.0567, 0.0555, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5848, -0.0445,  0.3622,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6747,  0.2776, -0.4455,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2728,  0.5716,  0.1281,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8887, -0.2723,  0.2304,  ...,     nan,     nan,     nan],\n",
      "        [-0.0561,  0.0051, -0.0750,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7838, -0.2867, -0.8690,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0810, 0.0818, 0.0824,  ..., 0.0676, 0.0666, 0.0000],\n",
      "        [0.2734, 0.2774, 0.2802,  ..., 0.0802, 0.0791, 0.0000],\n",
      "        [0.3316, 0.3347, 0.3372,  ..., 0.1987, 0.1975, 0.0000],\n",
      "        ...,\n",
      "        [0.1922, 0.1935, 0.1941,  ..., 0.0842, 0.0829, 0.0000],\n",
      "        [0.0422, 0.0429, 0.0434,  ..., 0.0769, 0.0759, 0.0000],\n",
      "        [0.1004, 0.1010, 0.1013,  ..., 0.0807, 0.0794, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9475, -0.5490,  0.3291,  ...,     nan,     nan,     nan],\n",
      "        [-0.6662, -0.1902, -0.1525,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2507,  0.4657,  0.1402,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7474, -0.0414,  0.4938,  ...,     nan,     nan,     nan],\n",
      "        [-0.8677, -0.5184,  0.3389,  ...,     nan,     nan,     nan],\n",
      "        [-0.7825,  0.3506,  0.7057,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1366, 0.1370, 0.1369,  ..., 0.0596, 0.0579, 0.0000],\n",
      "        [0.1957, 0.1977, 0.1990,  ..., 0.0941, 0.0924, 0.0000],\n",
      "        [0.1240, 0.1249, 0.1256,  ..., 0.0637, 0.0628, 0.0000],\n",
      "        ...,\n",
      "        [0.0663, 0.0670, 0.0675,  ..., 0.1246, 0.1235, 0.0000],\n",
      "        [0.0528, 0.0535, 0.0540,  ..., 0.1064, 0.1052, 0.0000],\n",
      "        [0.0702, 0.0712, 0.0720,  ..., 0.0759, 0.0744, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5439, -0.0479,  0.4732,  ...,     nan,     nan,     nan],\n",
      "        [-0.3026, -0.8014, -0.0394,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9320,  0.0540,  0.8610,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7072, -0.4562,  0.2745,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0974, -0.3794,  0.1457,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9488, -0.3883,  0.8951,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0563, 0.0581, 0.0594,  ..., 0.1101, 0.1081, 0.0000],\n",
      "        [0.1445, 0.1458, 0.1468,  ..., 0.0625, 0.0613, 0.0000],\n",
      "        [0.1058, 0.1074, 0.1085,  ..., 0.0979, 0.0969, 0.0000],\n",
      "        ...,\n",
      "        [0.0644, 0.0653, 0.0658,  ..., 0.0460, 0.0447, 0.0000],\n",
      "        [0.1249, 0.1260, 0.1268,  ..., 0.0717, 0.0710, 0.0000],\n",
      "        [0.1514, 0.1525, 0.1534,  ..., 0.1368, 0.1359, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7945, -0.2631,  0.2758,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6880, -0.5034,  0.6545,  ...,     nan,     nan,     nan],\n",
      "        [-0.7751, -0.3376, -0.0385,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8854,  0.1214, -0.6131,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2633, -0.4176, -0.1805,  ...,     nan,     nan,     nan],\n",
      "        [-0.8028, -0.3258, -0.5390,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0965, 0.0976, 0.0985,  ..., 0.0586, 0.0574, 0.0000],\n",
      "        [0.0738, 0.0748, 0.0755,  ..., 0.0950, 0.0944, 0.0000],\n",
      "        [0.0814, 0.0821, 0.0826,  ..., 0.0943, 0.0936, 0.0000],\n",
      "        ...,\n",
      "        [0.0898, 0.0910, 0.0918,  ..., 0.0786, 0.0768, 0.0000],\n",
      "        [0.0735, 0.0744, 0.0751,  ..., 0.0915, 0.0907, 0.0000],\n",
      "        [0.0855, 0.0862, 0.0867,  ..., 0.1046, 0.1037, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8348, -0.0593, -0.3748,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3785,  0.3069, -0.2000,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0580, -0.1615,  0.2202,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.4077, -0.5566,  0.4130,  ...,     nan,     nan,     nan],\n",
      "        [-0.8355,  0.3066,  0.7925,  ...,     nan,     nan,     nan],\n",
      "        [-0.4656,  0.2575, -0.3688,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1112, 0.1123, 0.1131,  ..., 0.0661, 0.0654, 0.0000],\n",
      "        [0.3741, 0.3778, 0.3801,  ..., 0.4853, 0.4849, 0.0000],\n",
      "        [0.0713, 0.0720, 0.0724,  ..., 0.0787, 0.0773, 0.0000],\n",
      "        ...,\n",
      "        [0.0911, 0.0917, 0.0922,  ..., 0.0687, 0.0676, 0.0000],\n",
      "        [0.0661, 0.0665, 0.0668,  ..., 0.0585, 0.0576, 0.0000],\n",
      "        [0.1536, 0.1553, 0.1564,  ..., 0.1021, 0.1004, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8127,  0.7043, -0.0648,  ...,     nan,     nan,     nan],\n",
      "        [-0.7035,  0.2317,  0.0766,  ...,     nan,     nan,     nan],\n",
      "        [-0.7509, -0.1724,  0.5381,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5907, -0.4830, -0.8819,  ...,     nan,     nan,     nan],\n",
      "        [-0.7580, -0.0487,  0.6530,  ...,     nan,     nan,     nan],\n",
      "        [-0.4589, -0.2091,  0.5582,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0457, 0.0461, 0.0463,  ..., 0.0716, 0.0704, 0.0000],\n",
      "        [0.0725, 0.0735, 0.0741,  ..., 0.0816, 0.0806, 0.0000],\n",
      "        [0.0953, 0.0967, 0.0979,  ..., 0.0960, 0.0951, 0.0000],\n",
      "        ...,\n",
      "        [0.0780, 0.0787, 0.0793,  ..., 0.0391, 0.0383, 0.0000],\n",
      "        [0.0829, 0.0837, 0.0843,  ..., 0.0751, 0.0741, 0.0000],\n",
      "        [0.1276, 0.1297, 0.1313,  ..., 0.0914, 0.0899, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.2429,  0.5690, -0.7932,  ...,     nan,     nan,     nan],\n",
      "        [-0.6156, -0.3796, -0.5116,  ...,     nan,     nan,     nan],\n",
      "        [-0.0060, -0.0951,  0.5566,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1268, -0.0936,  0.1282,  ...,     nan,     nan,     nan],\n",
      "        [-0.3835,  0.3393, -0.5543,  ...,     nan,     nan,     nan],\n",
      "        [-0.0581, -0.0397, -0.5936,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0860, 0.0870, 0.0877,  ..., 0.0847, 0.0831, 0.0000],\n",
      "        [0.0259, 0.0268, 0.0274,  ..., 0.1079, 0.1071, 0.0000],\n",
      "        [0.3159, 0.3191, 0.3206,  ..., 0.0891, 0.0880, 0.0000],\n",
      "        ...,\n",
      "        [0.0949, 0.0962, 0.0971,  ..., 0.0881, 0.0871, 0.0000],\n",
      "        [0.0988, 0.0993, 0.0995,  ..., 0.0584, 0.0575, 0.0000],\n",
      "        [0.1037, 0.1055, 0.1069,  ..., 0.0649, 0.0641, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0348, -0.6636, -0.0535,  ...,     nan,     nan,     nan],\n",
      "        [-0.3296,  0.2967, -0.1763,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7390, -0.0687, -0.2048,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7403, -0.3916,  0.2373,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8956,  0.8117, -0.6030,  ...,     nan,     nan,     nan],\n",
      "        [-0.0164, -0.1895,  0.7289,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0721, 0.0730, 0.0736,  ..., 0.0844, 0.0833, 0.0000],\n",
      "        [0.0562, 0.0568, 0.0571,  ..., 0.0734, 0.0725, 0.0000],\n",
      "        [0.0814, 0.0823, 0.0830,  ..., 0.0454, 0.0442, 0.0000],\n",
      "        ...,\n",
      "        [0.1598, 0.1624, 0.1642,  ..., 0.0824, 0.0815, 0.0000],\n",
      "        [0.1430, 0.1440, 0.1447,  ..., 0.1112, 0.1098, 0.0000],\n",
      "        [0.0645, 0.0656, 0.0664,  ..., 0.1007, 0.1000, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4351, -0.2839,  0.2628,  ...,     nan,     nan,     nan],\n",
      "        [-0.7033, -0.2536, -0.0145,  ...,     nan,     nan,     nan],\n",
      "        [-0.7876, -0.2873,  0.8070,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.3604,  0.2385, -0.2143,  ...,     nan,     nan,     nan],\n",
      "        [-0.7958,  0.2886,  0.8533,  ...,     nan,     nan,     nan],\n",
      "        [-0.8859,  0.1482,  0.3559,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0485, 0.0492, 0.0497,  ..., 0.0854, 0.0842, 0.0000],\n",
      "        [0.2657, 0.2692, 0.2716,  ..., 0.1304, 0.1291, 0.0000],\n",
      "        [0.1288, 0.1297, 0.1301,  ..., 0.0904, 0.0894, 0.0000],\n",
      "        ...,\n",
      "        [0.0372, 0.0377, 0.0381,  ..., 0.1053, 0.1043, 0.0000],\n",
      "        [0.0697, 0.0704, 0.0707,  ..., 0.0778, 0.0764, 0.0000],\n",
      "        [0.1371, 0.1384, 0.1392,  ..., 0.1138, 0.1129, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9073,  0.4459,  0.6644,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5083,  0.3545, -0.4808,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9791,  0.8010, -0.6674,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5720,  0.8047,  0.0440,  ...,     nan,     nan,     nan],\n",
      "        [-0.6978, -0.7009,  0.2971,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9640, -0.4918, -0.3749,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0757, 0.0768, 0.0777,  ..., 0.0986, 0.0969, 0.0000],\n",
      "        [0.0730, 0.0737, 0.0742,  ..., 0.0785, 0.0771, 0.0000],\n",
      "        [0.1098, 0.1108, 0.1114,  ..., 0.1324, 0.1308, 0.0000],\n",
      "        ...,\n",
      "        [0.1018, 0.1028, 0.1035,  ..., 0.1221, 0.1206, 0.0000],\n",
      "        [0.1906, 0.1919, 0.1927,  ..., 0.1205, 0.1194, 0.0000],\n",
      "        [0.1176, 0.1187, 0.1194,  ..., 0.1135, 0.1122, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3849, -0.4392, -0.4715,  ...,     nan,     nan,     nan],\n",
      "        [-0.8027,  0.5161,  0.1234,  ...,     nan,     nan,     nan],\n",
      "        [-0.5535,  0.4254,  0.6443,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.5938,  0.2064,  0.1284,  ...,     nan,     nan,     nan],\n",
      "        [-0.6700,  0.3841,  0.0234,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3283, -0.4715, -0.5279,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1190, 0.1203, 0.1213,  ..., 0.1043, 0.1028, 0.0000],\n",
      "        [0.0824, 0.0831, 0.0836,  ..., 0.0721, 0.0710, 0.0000],\n",
      "        [0.1883, 0.1905, 0.1922,  ..., 0.0738, 0.0727, 0.0000],\n",
      "        ...,\n",
      "        [0.1202, 0.1212, 0.1218,  ..., 0.1039, 0.1018, 0.0000],\n",
      "        [0.0516, 0.0527, 0.0533,  ..., 0.0554, 0.0544, 0.0000],\n",
      "        [0.0183, 0.0185, 0.0186,  ..., 0.0594, 0.0575, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8314, -0.6902,  0.6555,  ...,     nan,     nan,     nan],\n",
      "        [-0.2638,  0.3371, -0.6682,  ...,     nan,     nan,     nan],\n",
      "        [-0.4858, -0.3665,  0.1926,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.5381,  0.0956, -0.3491,  ...,     nan,     nan,     nan],\n",
      "        [-0.6066, -0.2457,  0.4235,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8949, -0.7181,  0.8667,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1133, 0.1144, 0.1152,  ..., 0.1126, 0.1112, 0.0000],\n",
      "        [0.1244, 0.1251, 0.1256,  ..., 0.0561, 0.0551, 0.0000],\n",
      "        [0.1298, 0.1317, 0.1330,  ..., 0.0786, 0.0774, 0.0000],\n",
      "        ...,\n",
      "        [0.0651, 0.0661, 0.0668,  ..., 0.0721, 0.0710, 0.0000],\n",
      "        [0.1749, 0.1767, 0.1779,  ..., 0.0878, 0.0856, 0.0000],\n",
      "        [0.1314, 0.1324, 0.1329,  ..., 0.0643, 0.0632, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6282, -0.5209, -0.0600,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6379,  0.3056, -0.4263,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5022, -0.1849,  0.1372,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7496,  0.3207,  0.5067,  ...,     nan,     nan,     nan],\n",
      "        [-0.1329, -0.1172,  0.4160,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8169,  0.2189,  0.2539,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1728, 0.1740, 0.1747,  ..., 0.1344, 0.1331, 0.0000],\n",
      "        [0.1046, 0.1065, 0.1081,  ..., 0.1165, 0.1153, 0.0000],\n",
      "        [0.1238, 0.1250, 0.1259,  ..., 0.0625, 0.0612, 0.0000],\n",
      "        ...,\n",
      "        [0.1862, 0.1886, 0.1903,  ..., 0.1418, 0.1407, 0.0000],\n",
      "        [0.0869, 0.0880, 0.0887,  ..., 0.0636, 0.0630, 0.0000],\n",
      "        [0.0675, 0.0682, 0.0687,  ..., 0.0683, 0.0671, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3744, -0.3886,  0.0986,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0565,  0.6127,  0.0829,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8447, -0.0136, -0.4051,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6571, -0.8199,  0.0277,  ...,     nan,     nan,     nan],\n",
      "        [-0.7950, -0.7569, -0.0171,  ...,     nan,     nan,     nan],\n",
      "        [-0.2121, -0.5520,  0.2294,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0617, 0.0623, 0.0626,  ..., 0.0833, 0.0823, 0.0000],\n",
      "        [0.0662, 0.0669, 0.0675,  ..., 0.0660, 0.0649, 0.0000],\n",
      "        [0.1791, 0.1825, 0.1850,  ..., 0.0745, 0.0735, 0.0000],\n",
      "        ...,\n",
      "        [0.1714, 0.1729, 0.1738,  ..., 0.0805, 0.0791, 0.0000],\n",
      "        [0.0844, 0.0854, 0.0862,  ..., 0.1598, 0.1575, 0.0000],\n",
      "        [0.1039, 0.1053, 0.1064,  ..., 0.0581, 0.0572, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.2614, -0.5785,  0.0512,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8536,  0.1638, -0.1655,  ...,     nan,     nan,     nan],\n",
      "        [-0.8761,  0.0855,  0.6493,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.6954,  0.2756,  0.3763,  ...,     nan,     nan,     nan],\n",
      "        [-0.8662,  0.1657,  0.5011,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8604,  0.2613,  0.0195,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1242, 0.1255, 0.1262,  ..., 0.1011, 0.0999, 0.0000],\n",
      "        [0.1046, 0.1053, 0.1056,  ..., 0.0778, 0.0767, 0.0000],\n",
      "        [0.2491, 0.2513, 0.2527,  ..., 0.0937, 0.0923, 0.0000],\n",
      "        ...,\n",
      "        [0.1274, 0.1289, 0.1300,  ..., 0.1077, 0.1068, 0.0000],\n",
      "        [0.1325, 0.1342, 0.1354,  ..., 0.1067, 0.1058, 0.0000],\n",
      "        [0.0750, 0.0756, 0.0760,  ..., 0.0902, 0.0892, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6027,  0.3974,  0.1585,  ...,     nan,     nan,     nan],\n",
      "        [-0.5248, -0.6086,  0.4446,  ...,     nan,     nan,     nan],\n",
      "        [-0.8534, -0.3887,  0.0382,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7346, -0.7562,  0.1335,  ...,     nan,     nan,     nan],\n",
      "        [-0.7805, -0.0672, -0.5344,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9858,  0.0302,  0.1029,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1351, 0.1363, 0.1372,  ..., 0.0742, 0.0734, 0.0000],\n",
      "        [0.1012, 0.1021, 0.1025,  ..., 0.0689, 0.0680, 0.0000],\n",
      "        [0.1106, 0.1114, 0.1118,  ..., 0.1027, 0.1011, 0.0000],\n",
      "        ...,\n",
      "        [0.1050, 0.1061, 0.1069,  ..., 0.0719, 0.0710, 0.0000],\n",
      "        [0.0608, 0.0612, 0.0615,  ..., 0.0587, 0.0579, 0.0000],\n",
      "        [0.0674, 0.0679, 0.0682,  ..., 0.0595, 0.0586, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7590, -0.1438, -0.3762,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6245,  0.5114,  0.3322,  ...,     nan,     nan,     nan],\n",
      "        [-0.8255, -0.6466,  0.3978,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7333, -0.4036,  0.8488,  ...,     nan,     nan,     nan],\n",
      "        [-0.5829,  0.6126,  0.1224,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9673,  0.2860, -0.4496,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0446, 0.0448, 0.0449,  ..., 0.0578, 0.0566, 0.0000],\n",
      "        [0.0915, 0.0923, 0.0929,  ..., 0.0533, 0.0520, 0.0000],\n",
      "        [0.1295, 0.1309, 0.1318,  ..., 0.0748, 0.0733, 0.0000],\n",
      "        ...,\n",
      "        [0.0626, 0.0630, 0.0632,  ..., 0.0679, 0.0668, 0.0000],\n",
      "        [0.1689, 0.1715, 0.1734,  ..., 0.0743, 0.0734, 0.0000],\n",
      "        [0.0789, 0.0800, 0.0807,  ..., 0.0564, 0.0557, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5289, -0.5239,  0.5462,  ...,     nan,     nan,     nan],\n",
      "        [-0.8163, -0.3359,  0.5445,  ...,     nan,     nan,     nan],\n",
      "        [-0.7137, -0.0551, -0.5578,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6650, -0.7016, -0.1544,  ...,     nan,     nan,     nan],\n",
      "        [-0.8481, -0.4816,  0.1331,  ...,     nan,     nan,     nan],\n",
      "        [-0.4746, -0.3098, -0.1203,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0535, 0.0542, 0.0547,  ..., 0.1034, 0.1023, 0.0000],\n",
      "        [0.2266, 0.2298, 0.2321,  ..., 0.0946, 0.0936, 0.0000],\n",
      "        [0.1560, 0.1573, 0.1582,  ..., 0.1035, 0.1017, 0.0000],\n",
      "        ...,\n",
      "        [0.1391, 0.1401, 0.1407,  ..., 0.0789, 0.0776, 0.0000],\n",
      "        [0.1080, 0.1100, 0.1114,  ..., 0.0789, 0.0775, 0.0000],\n",
      "        [0.0763, 0.0773, 0.0781,  ..., 0.0602, 0.0587, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7749, -0.0547, -0.4701,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0734, 0.0742, 0.0748,  ..., 0.0844, 0.0828, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "Epoch 1: Train Loss = nan, Val Loss = nan, Test Loss = nan\n",
      "tensor([[-0.3893,  0.1616,  0.4089,  ...,     nan,     nan,     nan],\n",
      "        [-0.5720,  0.8047,  0.0440,  ...,     nan,     nan,     nan],\n",
      "        [-0.8789,  0.3198,  0.3957,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.2988, -0.1316, -0.5239,  ...,     nan,     nan,     nan],\n",
      "        [-0.9101, -0.4888, -0.3573,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8286, -0.6179,  0.3015,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0587, 0.0599, 0.0608,  ..., 0.0661, 0.0651, 0.0000],\n",
      "        [0.1018, 0.1028, 0.1035,  ..., 0.1221, 0.1206, 0.0000],\n",
      "        [0.0910, 0.0921, 0.0928,  ..., 0.0908, 0.0887, 0.0000],\n",
      "        ...,\n",
      "        [0.2201, 0.2230, 0.2251,  ..., 0.1066, 0.1055, 0.0000],\n",
      "        [0.1156, 0.1170, 0.1179,  ..., 0.0852, 0.0837, 0.0000],\n",
      "        [0.1551, 0.1561, 0.1567,  ..., 0.1119, 0.1107, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4850,  0.3548,  0.6215,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1505, -0.4562,  0.6160,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7676,  0.1858, -0.6242,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5309,  0.2359, -0.1390,  ...,     nan,     nan,     nan],\n",
      "        [-0.6306,  0.0609,  0.3637,  ...,     nan,     nan,     nan],\n",
      "        [-0.8989, -0.7245, -0.0350,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0709, 0.0716, 0.0720,  ..., 0.1078, 0.1069, 0.0000],\n",
      "        [0.0944, 0.0952, 0.0958,  ..., 0.0737, 0.0726, 0.0000],\n",
      "        [0.0779, 0.0786, 0.0791,  ..., 0.1360, 0.1346, 0.0000],\n",
      "        ...,\n",
      "        [0.0627, 0.0638, 0.0647,  ..., 0.0542, 0.0529, 0.0000],\n",
      "        [0.0644, 0.0647, 0.0648,  ..., 0.0741, 0.0729, 0.0000],\n",
      "        [0.1490, 0.1502, 0.1510,  ..., 0.1046, 0.1035, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7128, -0.0364,  0.4927,  ...,     nan,     nan,     nan],\n",
      "        [-0.9073,  0.4459,  0.6644,  ...,     nan,     nan,     nan],\n",
      "        [-0.8932, -0.5494,  0.3739,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8313, -0.2707, -0.3265,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2086, -0.0325, -0.1821,  ...,     nan,     nan,     nan],\n",
      "        [-0.1538,  0.5627, -0.2487,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0499, 0.0512, 0.0521,  ..., 0.1552, 0.1537, 0.0000],\n",
      "        [0.0757, 0.0768, 0.0777,  ..., 0.0986, 0.0969, 0.0000],\n",
      "        [0.1032, 0.1043, 0.1050,  ..., 0.0962, 0.0950, 0.0000],\n",
      "        ...,\n",
      "        [0.0692, 0.0699, 0.0705,  ..., 0.0788, 0.0777, 0.0000],\n",
      "        [0.1326, 0.1339, 0.1347,  ..., 0.0761, 0.0748, 0.0000],\n",
      "        [0.2139, 0.2165, 0.2182,  ..., 0.0870, 0.0859, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7541, -0.2301,  0.0339,  ...,     nan,     nan,     nan],\n",
      "        [-0.5310, -0.3223, -0.0239,  ...,     nan,     nan,     nan],\n",
      "        [-0.4888, -0.0328,  0.0096,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5757,  0.0062,  0.8428,  ...,     nan,     nan,     nan],\n",
      "        [-0.7370, -0.3025,  0.3002,  ...,     nan,     nan,     nan],\n",
      "        [-0.7813, -0.2473,  0.4012,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2954, 0.2980, 0.2996,  ..., 0.1232, 0.1215, 0.0000],\n",
      "        [0.0699, 0.0708, 0.0713,  ..., 0.0736, 0.0727, 0.0000],\n",
      "        [0.0922, 0.0929, 0.0934,  ..., 0.0663, 0.0651, 0.0000],\n",
      "        ...,\n",
      "        [0.1047, 0.1055, 0.1061,  ..., 0.0886, 0.0874, 0.0000],\n",
      "        [0.0523, 0.0531, 0.0536,  ..., 0.0292, 0.0279, 0.0000],\n",
      "        [0.2197, 0.2214, 0.2228,  ..., 0.0801, 0.0792, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.4840,  0.5406,  0.1811,  ...,     nan,     nan,     nan],\n",
      "        [-0.6870,  0.1590, -0.6920,  ...,     nan,     nan,     nan],\n",
      "        [-0.2987, -0.5929,  0.1023,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.2280, -0.5957, -0.4724,  ...,     nan,     nan,     nan],\n",
      "        [-0.8464, -0.4378,  0.2007,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2107, -0.7254, -0.1417,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0448, 0.0453, 0.0457,  ..., 0.0621, 0.0614, 0.0000],\n",
      "        [0.0961, 0.0968, 0.0973,  ..., 0.0694, 0.0682, 0.0000],\n",
      "        [0.0917, 0.0928, 0.0937,  ..., 0.0988, 0.0960, 0.0000],\n",
      "        ...,\n",
      "        [0.1368, 0.1379, 0.1385,  ..., 0.1745, 0.1725, 0.0000],\n",
      "        [0.0796, 0.0804, 0.0809,  ..., 0.1229, 0.1210, 0.0000],\n",
      "        [0.0924, 0.0933, 0.0940,  ..., 0.1345, 0.1321, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6170, -0.0568, -0.0735,  ...,     nan,     nan,     nan],\n",
      "        [-0.6926, -0.7659, -0.0288,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0196, -0.3464, -0.0760,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7141, -0.2223,  0.4224,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7753,  0.0244, -0.6438,  ...,     nan,     nan,     nan],\n",
      "        [-0.6004, -0.5402, -0.2533,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1874, 0.1888, 0.1896,  ..., 0.0404, 0.0394, 0.0000],\n",
      "        [0.1028, 0.1044, 0.1056,  ..., 0.0916, 0.0904, 0.0000],\n",
      "        [0.0827, 0.0843, 0.0855,  ..., 0.1071, 0.1069, 0.0000],\n",
      "        ...,\n",
      "        [0.0519, 0.0523, 0.0526,  ..., 0.0729, 0.0721, 0.0000],\n",
      "        [0.0613, 0.0620, 0.0626,  ..., 0.1081, 0.1066, 0.0000],\n",
      "        [0.0864, 0.0874, 0.0880,  ..., 0.0515, 0.0505, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6855, -0.4798, -0.0603,  ...,     nan,     nan,     nan],\n",
      "        [-0.8071, -0.6409,  0.3870,  ...,     nan,     nan,     nan],\n",
      "        [-0.5254,  0.3899, -0.6552,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7437,  0.3771,  0.2732,  ...,     nan,     nan,     nan],\n",
      "        [-0.8175,  0.6662, -0.0287,  ...,     nan,     nan,     nan],\n",
      "        [-0.7978,  0.0260,  0.7770,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0606, 0.0613, 0.0618,  ..., 0.1059, 0.1049, 0.0000],\n",
      "        [0.0696, 0.0706, 0.0713,  ..., 0.0702, 0.0688, 0.0000],\n",
      "        [0.0586, 0.0591, 0.0595,  ..., 0.0503, 0.0491, 0.0000],\n",
      "        ...,\n",
      "        [0.0292, 0.0296, 0.0299,  ..., 0.0670, 0.0663, 0.0000],\n",
      "        [0.1428, 0.1446, 0.1459,  ..., 0.0968, 0.0955, 0.0000],\n",
      "        [0.1218, 0.1229, 0.1238,  ..., 0.1302, 0.1285, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7537,  0.0337,  0.0680,  ...,     nan,     nan,     nan],\n",
      "        [-0.2601, -0.0341, -0.0663,  ...,     nan,     nan,     nan],\n",
      "        [-0.3876,  0.2001,  0.3274,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.0289,  0.4399, -0.5163,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6596,  0.6730,  0.1640,  ...,     nan,     nan,     nan],\n",
      "        [-0.8064,  0.2651, -0.0861,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0777, 0.0781, 0.0783,  ..., 0.0706, 0.0695, 0.0000],\n",
      "        [0.0883, 0.0895, 0.0903,  ..., 0.0750, 0.0733, 0.0000],\n",
      "        [0.2142, 0.2174, 0.2197,  ..., 0.0824, 0.0810, 0.0000],\n",
      "        ...,\n",
      "        [0.1054, 0.1063, 0.1068,  ..., 0.0757, 0.0744, 0.0000],\n",
      "        [0.0753, 0.0759, 0.0763,  ..., 0.0658, 0.0647, 0.0000],\n",
      "        [0.0520, 0.0526, 0.0530,  ..., 0.0545, 0.0533, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9338, -0.6718,  0.1969,  ...,     nan,     nan,     nan],\n",
      "        [-0.6666, -0.1980, -0.2599,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1238,  0.5439, -0.0779,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6887,  0.6596, -0.2227,  ...,     nan,     nan,     nan],\n",
      "        [-0.6360,  0.3591,  0.1157,  ...,     nan,     nan,     nan],\n",
      "        [-0.4622,  0.6972, -0.1771,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0965, 0.0972, 0.0977,  ..., 0.0494, 0.0483, 0.0000],\n",
      "        [0.0433, 0.0438, 0.0443,  ..., 0.0467, 0.0457, 0.0000],\n",
      "        [0.0552, 0.0559, 0.0563,  ..., 0.0805, 0.0800, 0.0000],\n",
      "        ...,\n",
      "        [0.0790, 0.0800, 0.0806,  ..., 0.0619, 0.0607, 0.0000],\n",
      "        [0.1056, 0.1070, 0.1080,  ..., 0.0507, 0.0498, 0.0000],\n",
      "        [0.1299, 0.1313, 0.1322,  ..., 0.0807, 0.0797, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3246,  0.6530, -0.1270,  ...,     nan,     nan,     nan],\n",
      "        [-0.2348,  0.0076, -0.1368,  ...,     nan,     nan,     nan],\n",
      "        [-0.3556, -0.3619,  0.1620,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7461,  0.3585,  0.1640,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4781,  0.1669, -0.6793,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9800,  0.1226, -0.1888,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1430, 0.1440, 0.1445,  ..., 0.1209, 0.1193, 0.0000],\n",
      "        [0.1008, 0.1025, 0.1038,  ..., 0.1149, 0.1138, 0.0000],\n",
      "        [0.0779, 0.0782, 0.0781,  ..., 0.0565, 0.0557, 0.0000],\n",
      "        ...,\n",
      "        [0.0404, 0.0406, 0.0406,  ..., 0.0389, 0.0380, 0.0000],\n",
      "        [0.2815, 0.2863, 0.2898,  ..., 0.0993, 0.0980, 0.0000],\n",
      "        [0.1110, 0.1118, 0.1122,  ..., 0.0940, 0.0923, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6984,  0.0863, -0.1227,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7213,  0.3829, -0.8096,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5209, -0.7369,  0.6955,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5031,  0.7751, -0.1811,  ...,     nan,     nan,     nan],\n",
      "        [-0.7496,  0.3207,  0.5067,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3184, -0.1337,  0.8678,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1204, 0.1214, 0.1221,  ..., 0.0967, 0.0953, 0.0000],\n",
      "        [0.1776, 0.1795, 0.1807,  ..., 0.1665, 0.1639, 0.0000],\n",
      "        [0.0648, 0.0656, 0.0663,  ..., 0.0922, 0.0914, 0.0000],\n",
      "        ...,\n",
      "        [0.0557, 0.0567, 0.0574,  ..., 0.0909, 0.0895, 0.0000],\n",
      "        [0.1862, 0.1886, 0.1903,  ..., 0.1418, 0.1407, 0.0000],\n",
      "        [0.1066, 0.1074, 0.1080,  ..., 0.0801, 0.0789, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.4892,  0.0457, -0.6296,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7415,  0.5612,  0.0676,  ...,     nan,     nan,     nan],\n",
      "        [-0.7053, -0.5456,  0.6187,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7276, -0.0174,  0.1295,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6425,  0.3894,  0.5454,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2354, -0.1599, -0.1956,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0386, 0.0389, 0.0391,  ..., 0.0993, 0.0978, 0.0000],\n",
      "        [0.1018, 0.1029, 0.1037,  ..., 0.1076, 0.1064, 0.0000],\n",
      "        [0.1096, 0.1106, 0.1112,  ..., 0.1318, 0.1311, 0.0000],\n",
      "        ...,\n",
      "        [0.0858, 0.0867, 0.0873,  ..., 0.1350, 0.1339, 0.0000],\n",
      "        [0.1819, 0.1844, 0.1860,  ..., 0.0920, 0.0908, 0.0000],\n",
      "        [0.0665, 0.0670, 0.0673,  ..., 0.0990, 0.0978, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8833,  0.0458, -0.5457,  ...,     nan,     nan,     nan],\n",
      "        [-0.5047, -0.2547,  0.6474,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2165, -0.4269,  0.0450,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.8791,  0.0286, -0.3715,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6733,  0.0967,  0.1820,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1776, -0.4970,  0.8565,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2126, 0.2147, 0.2162,  ..., 0.0834, 0.0822, 0.0000],\n",
      "        [0.0655, 0.0661, 0.0665,  ..., 0.0475, 0.0470, 0.0000],\n",
      "        [0.0745, 0.0754, 0.0761,  ..., 0.0706, 0.0695, 0.0000],\n",
      "        ...,\n",
      "        [0.2670, 0.2707, 0.2735,  ..., 0.1185, 0.1166, 0.0000],\n",
      "        [0.0722, 0.0727, 0.0730,  ..., 0.0592, 0.0585, 0.0000],\n",
      "        [0.0893, 0.0902, 0.0908,  ..., 0.0709, 0.0702, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.9554, -0.0348, -0.0361,  ...,     nan,     nan,     nan],\n",
      "        [-0.5077, -0.5517,  0.2922,  ...,     nan,     nan,     nan],\n",
      "        [-0.4621, -0.0492,  0.6135,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.0948,  0.2179, -0.2485,  ...,     nan,     nan,     nan],\n",
      "        [-0.6896, -0.1584,  0.4685,  ...,     nan,     nan,     nan],\n",
      "        [-0.8592, -0.1763,  0.3144,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0441, 0.0446, 0.0448,  ..., 0.0868, 0.0855, 0.0000],\n",
      "        [0.0970, 0.0979, 0.0985,  ..., 0.0788, 0.0778, 0.0000],\n",
      "        [0.1041, 0.1052, 0.1059,  ..., 0.0656, 0.0644, 0.0000],\n",
      "        ...,\n",
      "        [0.1293, 0.1309, 0.1322,  ..., 0.0543, 0.0532, 0.0000],\n",
      "        [0.0856, 0.0868, 0.0875,  ..., 0.1104, 0.1093, 0.0000],\n",
      "        [0.1218, 0.1234, 0.1244,  ..., 0.1093, 0.1082, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6201,  0.3227, -0.1278,  ...,     nan,     nan,     nan],\n",
      "        [-0.7368, -0.4754,  0.7184,  ...,     nan,     nan,     nan],\n",
      "        [-0.1023,  0.1970,  0.3704,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.0928, -0.0018,  0.3763,  ...,     nan,     nan,     nan],\n",
      "        [-0.5135,  0.6786, -0.1065,  ...,     nan,     nan,     nan],\n",
      "        [-0.7830, -0.3116,  0.2529,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0788, 0.0800, 0.0808,  ..., 0.1062, 0.1050, 0.0000],\n",
      "        [0.0415, 0.0423, 0.0429,  ..., 0.0873, 0.0861, 0.0000],\n",
      "        [0.0770, 0.0777, 0.0780,  ..., 0.0724, 0.0713, 0.0000],\n",
      "        ...,\n",
      "        [0.0483, 0.0491, 0.0496,  ..., 0.1003, 0.0995, 0.0000],\n",
      "        [0.1015, 0.1025, 0.1030,  ..., 0.0612, 0.0600, 0.0000],\n",
      "        [0.1362, 0.1381, 0.1395,  ..., 0.0894, 0.0885, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.5073, -0.0784, -0.3032,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2086, -0.5052,  0.5459,  ...,     nan,     nan,     nan],\n",
      "        [-0.6645,  0.0582,  0.6635,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.1617,  0.2817,  0.1966,  ...,     nan,     nan,     nan],\n",
      "        [-0.7586,  0.4397, -0.1391,  ...,     nan,     nan,     nan],\n",
      "        [-0.4670,  0.0061, -0.2461,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1154, 0.1167, 0.1176,  ..., 0.0919, 0.0904, 0.0000],\n",
      "        [0.0731, 0.0739, 0.0745,  ..., 0.0614, 0.0603, 0.0000],\n",
      "        [0.0608, 0.0616, 0.0622,  ..., 0.0515, 0.0504, 0.0000],\n",
      "        ...,\n",
      "        [0.2039, 0.2061, 0.2077,  ..., 0.1881, 0.1866, 0.0000],\n",
      "        [0.1420, 0.1437, 0.1449,  ..., 0.1198, 0.1183, 0.0000],\n",
      "        [0.1166, 0.1180, 0.1191,  ..., 0.0634, 0.0623, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8613, -0.4468, -0.2708,  ...,     nan,     nan,     nan],\n",
      "        [-0.0603, -0.0623,  0.4828,  ...,     nan,     nan,     nan],\n",
      "        [-0.1380,  0.0752,  0.3394,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6027,  0.1944, -0.6177,  ...,     nan,     nan,     nan],\n",
      "        [-0.6978, -0.7009,  0.2971,  ...,     nan,     nan,     nan],\n",
      "        [-0.6480, -0.0313, -0.3604,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1317, 0.1337, 0.1351,  ..., 0.1180, 0.1157, 0.0000],\n",
      "        [0.0670, 0.0682, 0.0691,  ..., 0.1001, 0.0989, 0.0000],\n",
      "        [0.1412, 0.1422, 0.1425,  ..., 0.0867, 0.0853, 0.0000],\n",
      "        ...,\n",
      "        [0.0684, 0.0691, 0.0697,  ..., 0.0671, 0.0659, 0.0000],\n",
      "        [0.1906, 0.1919, 0.1927,  ..., 0.1205, 0.1194, 0.0000],\n",
      "        [0.0735, 0.0745, 0.0751,  ..., 0.0893, 0.0876, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.9670,  0.0506, -0.1081,  ...,     nan,     nan,     nan],\n",
      "        [-0.2422,  0.0658,  0.4930,  ...,     nan,     nan,     nan],\n",
      "        [-0.7209,  0.2254, -0.1444,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.8344, -0.3362,  0.5132,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3598,  0.5467, -0.0374,  ...,     nan,     nan,     nan],\n",
      "        [-0.6220, -0.4034, -0.6297,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1507, 0.1516, 0.1520,  ..., 0.0933, 0.0921, 0.0000],\n",
      "        [0.0785, 0.0794, 0.0800,  ..., 0.0991, 0.0980, 0.0000],\n",
      "        [0.0801, 0.0811, 0.0817,  ..., 0.1027, 0.1015, 0.0000],\n",
      "        ...,\n",
      "        [0.1044, 0.1056, 0.1065,  ..., 0.0928, 0.0916, 0.0000],\n",
      "        [0.0560, 0.0566, 0.0569,  ..., 0.1293, 0.1279, 0.0000],\n",
      "        [0.2018, 0.2040, 0.2056,  ..., 0.1334, 0.1322, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.5300, -0.0907,  0.0462,  ...,     nan,     nan,     nan],\n",
      "        [-0.8502,  0.0850,  0.4839,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0707,  0.4102,  0.0835,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6987,  0.1328, -0.6255,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5705,  0.1143,  0.2793,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5613,  0.4245, -0.5476,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0782, 0.0791, 0.0798,  ..., 0.0994, 0.0980, 0.0000],\n",
      "        [0.1122, 0.1126, 0.1128,  ..., 0.0949, 0.0937, 0.0000],\n",
      "        [0.0931, 0.0943, 0.0951,  ..., 0.0691, 0.0682, 0.0000],\n",
      "        ...,\n",
      "        [0.1018, 0.1023, 0.1025,  ..., 0.1029, 0.1019, 0.0000],\n",
      "        [0.0748, 0.0757, 0.0763,  ..., 0.1268, 0.1256, 0.0000],\n",
      "        [0.0455, 0.0463, 0.0468,  ..., 0.0877, 0.0868, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.5913,  0.5480,  0.1248,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6972,  0.7991,  0.3067,  ...,     nan,     nan,     nan],\n",
      "        [-0.8265, -0.4856, -0.2193,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.8311, -0.2156, -0.3734,  ...,     nan,     nan,     nan],\n",
      "        [-0.7191,  0.1103, -0.0055,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1565, -0.8062, -0.1825,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0580, 0.0588, 0.0594,  ..., 0.0928, 0.0919, 0.0000],\n",
      "        [0.0920, 0.0932, 0.0940,  ..., 0.0929, 0.0916, 0.0000],\n",
      "        [0.0525, 0.0528, 0.0531,  ..., 0.1158, 0.1146, 0.0000],\n",
      "        ...,\n",
      "        [0.1159, 0.1170, 0.1177,  ..., 0.1496, 0.1483, 0.0000],\n",
      "        [0.0604, 0.0610, 0.0613,  ..., 0.0715, 0.0706, 0.0000],\n",
      "        [0.0516, 0.0521, 0.0524,  ..., 0.0771, 0.0763, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7592,  0.4929,  0.1415,  ...,     nan,     nan,     nan],\n",
      "        [-0.8195, -0.3578,  0.1308,  ...,     nan,     nan,     nan],\n",
      "        [-0.7560,  0.0347, -0.4855,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.9399, -0.1018,  0.4093,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6853, -0.2849,  0.1659,  ...,     nan,     nan,     nan],\n",
      "        [-0.8014, -0.6529, -0.7092,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0833, 0.0849, 0.0859,  ..., 0.0857, 0.0846, 0.0000],\n",
      "        [0.1997, 0.2026, 0.2046,  ..., 0.0827, 0.0816, 0.0000],\n",
      "        [0.0707, 0.0720, 0.0730,  ..., 0.0548, 0.0542, 0.0000],\n",
      "        ...,\n",
      "        [0.0488, 0.0495, 0.0500,  ..., 0.0575, 0.0568, 0.0000],\n",
      "        [0.0963, 0.0981, 0.0995,  ..., 0.1174, 0.1152, 0.0000],\n",
      "        [0.1086, 0.1095, 0.1100,  ..., 0.0955, 0.0940, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6747,  0.3669,  0.7208,  ...,     nan,     nan,     nan],\n",
      "        [-0.6077,  0.3912, -0.3238,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3025, -0.4827, -0.1647,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.2856, -0.2814, -0.0479,  ...,     nan,     nan,     nan],\n",
      "        [-0.8431, -0.2400,  0.2345,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2841, -0.4912,  0.4995,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1082, 0.1093, 0.1102,  ..., 0.0619, 0.0608, 0.0000],\n",
      "        [0.0378, 0.0383, 0.0387,  ..., 0.0504, 0.0495, 0.0000],\n",
      "        [0.0913, 0.0926, 0.0936,  ..., 0.0542, 0.0534, 0.0000],\n",
      "        ...,\n",
      "        [0.0665, 0.0669, 0.0671,  ..., 0.0465, 0.0455, 0.0000],\n",
      "        [0.2737, 0.2779, 0.2808,  ..., 0.1539, 0.1523, 0.0000],\n",
      "        [0.1107, 0.1119, 0.1128,  ..., 0.1179, 0.1161, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6978, -0.2515,  0.0520,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5539,  0.0162, -0.6831,  ...,     nan,     nan,     nan],\n",
      "        [-0.5959, -0.1735, -0.0980,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7838, -0.2867, -0.8690,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9243,  0.3347,  0.2885,  ...,     nan,     nan,     nan],\n",
      "        [-0.5353,  0.2203, -0.0525,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0557, 0.0563, 0.0566,  ..., 0.0818, 0.0810, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1050, 0.1032, 0.0000],\n",
      "        [0.1579, 0.1595, 0.1605,  ..., 0.1260, 0.1245, 0.0000],\n",
      "        ...,\n",
      "        [0.1004, 0.1010, 0.1013,  ..., 0.0807, 0.0794, 0.0000],\n",
      "        [0.0573, 0.0582, 0.0588,  ..., 0.0733, 0.0722, 0.0000],\n",
      "        [0.1224, 0.1232, 0.1235,  ..., 0.0584, 0.0575, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.3445, -0.2835,  0.0123,  ...,     nan,     nan,     nan],\n",
      "        [-0.7192,  0.2580,  0.7115,  ...,     nan,     nan,     nan],\n",
      "        [-0.6584,  0.0851, -0.3537,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7721,  0.3282, -0.2034,  ...,     nan,     nan,     nan],\n",
      "        [-0.7346, -0.7562,  0.1335,  ...,     nan,     nan,     nan],\n",
      "        [-0.4327,  0.8739,  0.2924,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0789, 0.0800, 0.0806,  ..., 0.0787, 0.0778, 0.0000],\n",
      "        [0.1327, 0.1340, 0.1348,  ..., 0.0527, 0.0512, 0.0000],\n",
      "        [0.1155, 0.1168, 0.1178,  ..., 0.0784, 0.0767, 0.0000],\n",
      "        ...,\n",
      "        [0.3669, 0.3688, 0.3700,  ..., 0.0455, 0.0426, 0.0000],\n",
      "        [0.1050, 0.1061, 0.1069,  ..., 0.0719, 0.0710, 0.0000],\n",
      "        [0.0745, 0.0753, 0.0759,  ..., 0.0614, 0.0604, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.5828,  0.4729,  0.1556,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5689, -0.6516, -0.6523,  ...,     nan,     nan,     nan],\n",
      "        [-0.3239, -0.2999,  0.2175,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7462,  0.4436,  0.6087,  ...,     nan,     nan,     nan],\n",
      "        [-0.3422,  0.1460,  0.1868,  ...,     nan,     nan,     nan],\n",
      "        [-0.6628, -0.0873,  0.6045,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0822, 0.0832, 0.0838,  ..., 0.0917, 0.0907, 0.0000],\n",
      "        [0.1941, 0.1954, 0.1961,  ..., 0.0652, 0.0640, 0.0000],\n",
      "        [0.1971, 0.1988, 0.2000,  ..., 0.0862, 0.0849, 0.0000],\n",
      "        ...,\n",
      "        [0.0921, 0.0933, 0.0942,  ..., 0.1480, 0.1457, 0.0000],\n",
      "        [0.1237, 0.1244, 0.1248,  ..., 0.1172, 0.1162, 0.0000],\n",
      "        [0.1031, 0.1042, 0.1049,  ..., 0.0528, 0.0519, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5582, -0.0447, -0.0175,  ...,     nan,     nan,     nan],\n",
      "        [-0.0423,  0.3062, -0.0186,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2116, -0.4291,  0.3084,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3548,  0.2334,  0.5050,  ...,     nan,     nan,     nan],\n",
      "        [-0.7818,  0.4654, -0.1966,  ...,     nan,     nan,     nan],\n",
      "        [-0.4078, -0.3026,  0.2945,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1914, 0.1942, 0.1962,  ..., 0.0673, 0.0662, 0.0000],\n",
      "        [0.1377, 0.1392, 0.1403,  ..., 0.1781, 0.1762, 0.0000],\n",
      "        [0.0850, 0.0861, 0.0869,  ..., 0.0857, 0.0848, 0.0000],\n",
      "        ...,\n",
      "        [0.0673, 0.0677, 0.0678,  ..., 0.0997, 0.0977, 0.0000],\n",
      "        [0.1036, 0.1047, 0.1056,  ..., 0.0790, 0.0778, 0.0000],\n",
      "        [0.0700, 0.0708, 0.0712,  ..., 0.0941, 0.0932, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8786, -0.8868, -0.4377,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8570,  0.0712, -0.0951,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7284, -0.1677, -0.0266,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8738, -0.4921,  0.3548,  ...,     nan,     nan,     nan],\n",
      "        [-0.4326, -0.2297,  0.4072,  ...,     nan,     nan,     nan],\n",
      "        [-0.7734, -0.6493,  0.7797,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0937, 0.0943, 0.0946,  ..., 0.0798, 0.0787, 0.0000],\n",
      "        [0.0581, 0.0592, 0.0599,  ..., 0.0787, 0.0775, 0.0000],\n",
      "        [0.0806, 0.0813, 0.0818,  ..., 0.1004, 0.0990, 0.0000],\n",
      "        ...,\n",
      "        [0.0509, 0.0519, 0.0526,  ..., 0.1101, 0.1087, 0.0000],\n",
      "        [0.0783, 0.0798, 0.0809,  ..., 0.0942, 0.0922, 0.0000],\n",
      "        [0.0880, 0.0889, 0.0896,  ..., 0.0671, 0.0661, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7712,  0.4179,  0.5642,  ...,     nan,     nan,     nan],\n",
      "        [-0.0410,  0.4498,  0.4193,  ...,     nan,     nan,     nan],\n",
      "        [-0.0607,  0.0757,  0.3595,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.6724,  0.1821,  0.2464,  ...,     nan,     nan,     nan],\n",
      "        [-0.3026, -0.8014, -0.0394,  ...,     nan,     nan,     nan],\n",
      "        [-0.8137, -0.2417,  0.1989,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1181, 0.1193, 0.1202,  ..., 0.0906, 0.0890, 0.0000],\n",
      "        [0.1572, 0.1582, 0.1587,  ..., 0.1259, 0.1246, 0.0000],\n",
      "        [0.1118, 0.1133, 0.1145,  ..., 0.0786, 0.0778, 0.0000],\n",
      "        ...,\n",
      "        [0.0658, 0.0666, 0.0672,  ..., 0.0966, 0.0949, 0.0000],\n",
      "        [0.1445, 0.1458, 0.1468,  ..., 0.0625, 0.0613, 0.0000],\n",
      "        [0.0636, 0.0643, 0.0648,  ..., 0.1022, 0.1012, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4244,  0.1902,  0.5807,  ...,     nan,     nan,     nan],\n",
      "        [-0.8300, -0.0280,  0.0066,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9380,  0.1060,  0.2225,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7741, -0.0661,  0.1453,  ...,     nan,     nan,     nan],\n",
      "        [-0.6517,  0.2668,  0.4227,  ...,     nan,     nan,     nan],\n",
      "        [-0.4987, -0.4133,  0.3649,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0492, 0.0498, 0.0502,  ..., 0.0701, 0.0689, 0.0000],\n",
      "        [0.0822, 0.0830, 0.0836,  ..., 0.1016, 0.1007, 0.0000],\n",
      "        [0.0729, 0.0740, 0.0748,  ..., 0.0888, 0.0875, 0.0000],\n",
      "        ...,\n",
      "        [0.1098, 0.1112, 0.1123,  ..., 0.1473, 0.1464, 0.0000],\n",
      "        [0.0962, 0.0974, 0.0983,  ..., 0.0560, 0.0545, 0.0000],\n",
      "        [0.1344, 0.1348, 0.1350,  ..., 0.0302, 0.0290, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.9163,  0.3374,  0.4159,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2023, -0.3263,  0.0645,  ...,     nan,     nan,     nan],\n",
      "        [-0.8238, -0.5225,  0.7134,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5578,  0.3451, -0.0606,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7374, -0.0849, -0.2565,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3973,  0.4096,  0.2760,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1233, 0.1245, 0.1254,  ..., 0.1198, 0.1187, 0.0000],\n",
      "        [0.0533, 0.0542, 0.0549,  ..., 0.0732, 0.0721, 0.0000],\n",
      "        [0.2531, 0.2564, 0.2587,  ..., 0.0991, 0.0981, 0.0000],\n",
      "        ...,\n",
      "        [0.1833, 0.1857, 0.1875,  ..., 0.0648, 0.0637, 0.0000],\n",
      "        [0.1349, 0.1361, 0.1369,  ..., 0.0777, 0.0763, 0.0000],\n",
      "        [0.0763, 0.0765, 0.0766,  ..., 0.0557, 0.0548, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8472,  0.3339, -0.6327,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6080,  0.1420,  0.2221,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2029,  0.7237, -0.7530,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6415, -0.4903,  0.8137,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1868, -0.4876,  0.2748,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6409,  0.1009, -0.1742,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1177, 0.1203, 0.1223,  ..., 0.0925, 0.0919, 0.0000],\n",
      "        [0.0858, 0.0867, 0.0874,  ..., 0.0436, 0.0423, 0.0000],\n",
      "        [0.3006, 0.3032, 0.3049,  ..., 0.0955, 0.0941, 0.0000],\n",
      "        ...,\n",
      "        [0.1299, 0.1310, 0.1315,  ..., 0.0939, 0.0929, 0.0000],\n",
      "        [0.0814, 0.0819, 0.0823,  ..., 0.0770, 0.0758, 0.0000],\n",
      "        [0.0770, 0.0778, 0.0782,  ..., 0.1063, 0.1047, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7395,  0.1114, -0.2494,  ...,     nan,     nan,     nan],\n",
      "        [-0.7411,  0.4227,  0.7378,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4920,  0.7067,  0.2237,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8653, -0.5245,  0.2835,  ...,     nan,     nan,     nan],\n",
      "        [-0.7117,  0.5327,  0.5731,  ...,     nan,     nan,     nan],\n",
      "        [-0.7581, -0.5941,  0.6769,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0909, 0.0918, 0.0924,  ..., 0.0801, 0.0790, 0.0000],\n",
      "        [0.0656, 0.0667, 0.0675,  ..., 0.0697, 0.0688, 0.0000],\n",
      "        [0.0844, 0.0853, 0.0860,  ..., 0.0742, 0.0727, 0.0000],\n",
      "        ...,\n",
      "        [0.0747, 0.0756, 0.0762,  ..., 0.0925, 0.0913, 0.0000],\n",
      "        [0.1798, 0.1808, 0.1814,  ..., 0.0641, 0.0630, 0.0000],\n",
      "        [0.1086, 0.1096, 0.1102,  ..., 0.1108, 0.1098, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8207, -0.3101, -0.1226,  ...,     nan,     nan,     nan],\n",
      "        [-0.6410, -0.6121,  0.6614,  ...,     nan,     nan,     nan],\n",
      "        [-0.4426,  0.3733,  0.5820,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5594,  0.0303,  0.4719,  ...,     nan,     nan,     nan],\n",
      "        [-0.1475,  0.1022,  0.0153,  ...,     nan,     nan,     nan],\n",
      "        [-0.5288,  0.1266, -0.3108,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1398, 0.1421, 0.1437,  ..., 0.0751, 0.0739, 0.0000],\n",
      "        [0.0724, 0.0730, 0.0734,  ..., 0.0593, 0.0584, 0.0000],\n",
      "        [0.0765, 0.0772, 0.0778,  ..., 0.0779, 0.0768, 0.0000],\n",
      "        ...,\n",
      "        [0.2413, 0.2455, 0.2487,  ..., 0.1110, 0.1097, 0.0000],\n",
      "        [0.0688, 0.0694, 0.0698,  ..., 0.0676, 0.0667, 0.0000],\n",
      "        [0.0669, 0.0678, 0.0685,  ..., 0.0754, 0.0744, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6864,  0.0609,  0.1240,  ...,     nan,     nan,     nan],\n",
      "        [-0.0931, -0.0014,  0.3546,  ...,     nan,     nan,     nan],\n",
      "        [-0.1425,  0.5621,  0.5891,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.2591, -0.1118,  0.2734,  ...,     nan,     nan,     nan],\n",
      "        [-0.6188,  0.7446,  0.0522,  ...,     nan,     nan,     nan],\n",
      "        [-0.8364,  0.2648,  0.3426,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1059, 0.1070, 0.1077,  ..., 0.1054, 0.1044, 0.0000],\n",
      "        [0.1121, 0.1132, 0.1141,  ..., 0.0565, 0.0554, 0.0000],\n",
      "        [0.0459, 0.0466, 0.0471,  ..., 0.0658, 0.0645, 0.0000],\n",
      "        ...,\n",
      "        [0.0773, 0.0783, 0.0791,  ..., 0.0981, 0.0965, 0.0000],\n",
      "        [0.0407, 0.0413, 0.0417,  ..., 0.0580, 0.0573, 0.0000],\n",
      "        [0.0821, 0.0827, 0.0832,  ..., 0.0939, 0.0922, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5130, -0.1541,  0.5892,  ...,     nan,     nan,     nan],\n",
      "        [-0.2533, -0.7052,  0.8154,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2193, -0.2602, -0.4820,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6128,  0.4047, -0.7556,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8447, -0.0136, -0.4051,  ...,     nan,     nan,     nan],\n",
      "        [-0.6881,  0.3072,  0.0414,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0766, 0.0775, 0.0783,  ..., 0.0797, 0.0784, 0.0000],\n",
      "        [0.1061, 0.1071, 0.1077,  ..., 0.0881, 0.0871, 0.0000],\n",
      "        [0.1044, 0.1057, 0.1066,  ..., 0.0820, 0.0808, 0.0000],\n",
      "        ...,\n",
      "        [0.0779, 0.0782, 0.0783,  ..., 0.0851, 0.0841, 0.0000],\n",
      "        [0.1791, 0.1825, 0.1850,  ..., 0.0745, 0.0735, 0.0000],\n",
      "        [0.1080, 0.1092, 0.1102,  ..., 0.0859, 0.0843, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8388,  0.4583,  0.4919,  ...,     nan,     nan,     nan],\n",
      "        [-0.8157, -0.0148, -0.2538,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9283,  0.1103,  0.0656,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.4993, -0.2303,  0.6184,  ...,     nan,     nan,     nan],\n",
      "        [-0.0139,  0.0086, -0.0426,  ...,     nan,     nan,     nan],\n",
      "        [-0.3772, -0.4419,  0.0240,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0744, 0.0753, 0.0758,  ..., 0.0847, 0.0837, 0.0000],\n",
      "        [0.1026, 0.1038, 0.1048,  ..., 0.0714, 0.0707, 0.0000],\n",
      "        [0.0570, 0.0575, 0.0579,  ..., 0.1027, 0.1009, 0.0000],\n",
      "        ...,\n",
      "        [0.1455, 0.1472, 0.1484,  ..., 0.0774, 0.0763, 0.0000],\n",
      "        [0.0836, 0.0845, 0.0851,  ..., 0.0546, 0.0538, 0.0000],\n",
      "        [0.0640, 0.0647, 0.0651,  ..., 0.1024, 0.1012, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7087, -0.0952,  0.0472,  ...,     nan,     nan,     nan],\n",
      "        [-0.4989, -0.3547, -0.2221,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8815,  0.3518,  0.5308,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5958,  0.3251,  0.0117,  ...,     nan,     nan,     nan],\n",
      "        [-0.4733, -0.0944,  0.5703,  ...,     nan,     nan,     nan],\n",
      "        [-0.8065,  0.4889, -0.1814,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1275, 0.1276, 0.1274,  ..., 0.1277, 0.1258, 0.0000],\n",
      "        [0.2462, 0.2486, 0.2501,  ..., 0.1171, 0.1162, 0.0000],\n",
      "        [0.0942, 0.0951, 0.0956,  ..., 0.1022, 0.1009, 0.0000],\n",
      "        ...,\n",
      "        [0.0487, 0.0496, 0.0502,  ..., 0.0734, 0.0726, 0.0000],\n",
      "        [0.0556, 0.0565, 0.0571,  ..., 0.0786, 0.0779, 0.0000],\n",
      "        [0.1017, 0.1023, 0.1026,  ..., 0.0698, 0.0687, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9282, -0.3107,  0.3161,  ...,     nan,     nan,     nan],\n",
      "        [-0.5620, -0.5399,  0.1391,  ...,     nan,     nan,     nan],\n",
      "        [-0.7372, -0.0452,  0.5323,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.3867,  0.1913,  0.6469,  ...,     nan,     nan,     nan],\n",
      "        [-0.0027,  0.4712, -0.2847,  ...,     nan,     nan,     nan],\n",
      "        [-0.5388,  0.2361,  0.2120,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0996, 0.1010, 0.1021,  ..., 0.0930, 0.0922, 0.0000],\n",
      "        [0.0764, 0.0776, 0.0785,  ..., 0.0792, 0.0779, 0.0000],\n",
      "        [0.1266, 0.1277, 0.1284,  ..., 0.0653, 0.0638, 0.0000],\n",
      "        ...,\n",
      "        [0.1081, 0.1095, 0.1104,  ..., 0.0883, 0.0874, 0.0000],\n",
      "        [0.2217, 0.2245, 0.2265,  ..., 0.1760, 0.1740, 0.0000],\n",
      "        [0.0771, 0.0779, 0.0783,  ..., 0.0566, 0.0554, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6132,  0.0442,  0.1784,  ...,     nan,     nan,     nan],\n",
      "        [-0.8109,  0.5873, -0.0906,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6202,  0.2637,  0.6857,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.3160,  0.4632,  0.1538,  ...,     nan,     nan,     nan],\n",
      "        [-0.6514, -0.3561, -0.2805,  ...,     nan,     nan,     nan],\n",
      "        [-0.7805,  0.3868,  0.6650,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0259, 0.0266, 0.0271,  ..., 0.0385, 0.0378, 0.0000],\n",
      "        [0.1626, 0.1643, 0.1656,  ..., 0.1297, 0.1279, 0.0000],\n",
      "        [0.0858, 0.0867, 0.0875,  ..., 0.0798, 0.0790, 0.0000],\n",
      "        ...,\n",
      "        [0.0678, 0.0686, 0.0693,  ..., 0.0852, 0.0836, 0.0000],\n",
      "        [0.2574, 0.2600, 0.2617,  ..., 0.0855, 0.0842, 0.0000],\n",
      "        [0.1154, 0.1173, 0.1187,  ..., 0.1148, 0.1127, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8903,  0.2826, -0.2224,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0723, 0.0731, 0.0736,  ..., 0.1040, 0.1029, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "Epoch 2: Train Loss = nan, Val Loss = nan, Test Loss = nan\n",
      "tensor([[-0.7211,  0.3625,  0.4829,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9000,  0.5221,  0.5406,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6346,  0.4201, -0.5688,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1200, -0.1869,  0.1633,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8981,  0.3899,  0.0745,  ...,     nan,     nan,     nan],\n",
      "        [-0.7387,  0.0554,  0.4575,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0650, 0.0655, 0.0659,  ..., 0.0869, 0.0860, 0.0000],\n",
      "        [0.1005, 0.1018, 0.1027,  ..., 0.0660, 0.0651, 0.0000],\n",
      "        [0.0613, 0.0617, 0.0619,  ..., 0.0782, 0.0765, 0.0000],\n",
      "        ...,\n",
      "        [0.1502, 0.1522, 0.1537,  ..., 0.1917, 0.1903, 0.0000],\n",
      "        [0.0639, 0.0647, 0.0653,  ..., 0.0957, 0.0946, 0.0000],\n",
      "        [0.0946, 0.0949, 0.0950,  ..., 0.0677, 0.0665, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7328,  0.1767, -0.8369,  ...,     nan,     nan,     nan],\n",
      "        [-0.8263,  0.1458,  0.5227,  ...,     nan,     nan,     nan],\n",
      "        [-0.7321,  0.2304, -0.3317,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7496, -0.4293, -0.1187,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8348,  0.3873, -0.3600,  ...,     nan,     nan,     nan],\n",
      "        [-0.5269,  0.0371,  0.2132,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0482, 0.0487, 0.0490,  ..., 0.0451, 0.0442, 0.0000],\n",
      "        [0.0433, 0.0440, 0.0445,  ..., 0.0736, 0.0722, 0.0000],\n",
      "        [0.0907, 0.0915, 0.0920,  ..., 0.0546, 0.0535, 0.0000],\n",
      "        ...,\n",
      "        [0.0744, 0.0754, 0.0760,  ..., 0.1308, 0.1284, 0.0000],\n",
      "        [0.0489, 0.0495, 0.0498,  ..., 0.0935, 0.0918, 0.0000],\n",
      "        [0.0703, 0.0709, 0.0712,  ..., 0.0712, 0.0698, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3769, -0.1045, -0.6342,  ...,     nan,     nan,     nan],\n",
      "        [-0.7187, -0.0773,  0.7261,  ...,     nan,     nan,     nan],\n",
      "        [-0.0393, -0.0965, -0.5115,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7705,  0.5890,  0.5432,  ...,     nan,     nan,     nan],\n",
      "        [-0.6751, -0.1707, -0.2395,  ...,     nan,     nan,     nan],\n",
      "        [-0.6360,  0.3591,  0.1157,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1085, 0.1095, 0.1102,  ..., 0.0898, 0.0883, 0.0000],\n",
      "        [0.0887, 0.0894, 0.0900,  ..., 0.1022, 0.1008, 0.0000],\n",
      "        [0.0563, 0.0568, 0.0572,  ..., 0.0450, 0.0442, 0.0000],\n",
      "        ...,\n",
      "        [0.1501, 0.1519, 0.1532,  ..., 0.0931, 0.0916, 0.0000],\n",
      "        [0.0840, 0.0855, 0.0866,  ..., 0.0565, 0.0556, 0.0000],\n",
      "        [0.1056, 0.1070, 0.1080,  ..., 0.0507, 0.0498, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8997,  0.0527, -0.1995,  ...,     nan,     nan,     nan],\n",
      "        [-0.1810, -0.1359,  0.1385,  ...,     nan,     nan,     nan],\n",
      "        [-0.5214, -0.0629,  0.6480,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5697,  0.3969,  0.4203,  ...,     nan,     nan,     nan],\n",
      "        [-0.8315, -0.5657,  0.8373,  ...,     nan,     nan,     nan],\n",
      "        [-0.3579, -0.0636,  0.3129,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0714, 0.0724, 0.0731,  ..., 0.1025, 0.1013, 0.0000],\n",
      "        [0.0119, 0.0123, 0.0126,  ..., 0.0694, 0.0684, 0.0000],\n",
      "        [0.0881, 0.0894, 0.0904,  ..., 0.0689, 0.0674, 0.0000],\n",
      "        ...,\n",
      "        [0.1250, 0.1260, 0.1265,  ..., 0.0593, 0.0583, 0.0000],\n",
      "        [0.0834, 0.0843, 0.0850,  ..., 0.1147, 0.1140, 0.0000],\n",
      "        [0.1078, 0.1089, 0.1096,  ..., 0.0653, 0.0639, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5637, -0.2712,  0.5793,  ...,     nan,     nan,     nan],\n",
      "        [-0.8141,  0.2832,  0.6237,  ...,     nan,     nan,     nan],\n",
      "        [-0.7993, -0.1151, -0.0293,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.2806,  0.6157, -0.2956,  ...,     nan,     nan,     nan],\n",
      "        [-0.7697,  0.6786, -0.1707,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0807,  0.1228, -0.4155,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1536, 0.1549, 0.1557,  ..., 0.1000, 0.0989, 0.0000],\n",
      "        [0.1139, 0.1152, 0.1163,  ..., 0.1104, 0.1095, 0.0000],\n",
      "        [0.0675, 0.0683, 0.0688,  ..., 0.1014, 0.1002, 0.0000],\n",
      "        ...,\n",
      "        [0.2008, 0.2021, 0.2029,  ..., 0.0625, 0.0613, 0.0000],\n",
      "        [0.0489, 0.0494, 0.0498,  ..., 0.0721, 0.0707, 0.0000],\n",
      "        [0.1373, 0.1385, 0.1393,  ..., 0.1439, 0.1421, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.1119, -0.2302,  0.2803,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1565, -0.8062, -0.1825,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1026,  0.1090,  0.8809,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7427,  0.4871,  0.8892,  ...,     nan,     nan,     nan],\n",
      "        [-0.9431,  0.0677,  0.6978,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2816, -0.3314, -0.2075,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2625, 0.2640, 0.2650,  ..., 0.1123, 0.1106, 0.0000],\n",
      "        [0.0516, 0.0521, 0.0524,  ..., 0.0771, 0.0763, 0.0000],\n",
      "        [0.1715, 0.1721, 0.1724,  ..., 0.1142, 0.1134, 0.0000],\n",
      "        ...,\n",
      "        [0.1913, 0.1926, 0.1934,  ..., 0.1224, 0.1207, 0.0000],\n",
      "        [0.0794, 0.0800, 0.0803,  ..., 0.0728, 0.0714, 0.0000],\n",
      "        [0.0457, 0.0463, 0.0467,  ..., 0.0828, 0.0818, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6472, -0.3171,  0.2212,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3445, -0.2835,  0.0123,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8913, -0.4894,  0.7735,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8908, -0.7781,  0.1508,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7274,  0.0954, -0.5686,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7374, -0.0849, -0.2565,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0281, 0.0283, 0.0285,  ..., 0.0705, 0.0694, 0.0000],\n",
      "        [0.0789, 0.0800, 0.0806,  ..., 0.0787, 0.0778, 0.0000],\n",
      "        [0.0644, 0.0655, 0.0663,  ..., 0.1021, 0.1009, 0.0000],\n",
      "        ...,\n",
      "        [0.1611, 0.1621, 0.1627,  ..., 0.1783, 0.1766, 0.0000],\n",
      "        [0.0589, 0.0591, 0.0592,  ..., 0.0782, 0.0763, 0.0000],\n",
      "        [0.1349, 0.1361, 0.1369,  ..., 0.0777, 0.0763, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0803,  0.1290, -0.3994,  ...,     nan,     nan,     nan],\n",
      "        [-0.7712,  0.4179,  0.5642,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4354, -0.6441, -0.2164,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.1859, -0.2955, -0.1977,  ...,     nan,     nan,     nan],\n",
      "        [-0.7308, -0.5099,  0.3893,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9680,  0.2150, -0.3948,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0424, 0.0429, 0.0432,  ..., 0.0708, 0.0698, 0.0000],\n",
      "        [0.1181, 0.1193, 0.1202,  ..., 0.0906, 0.0890, 0.0000],\n",
      "        [0.0648, 0.0653, 0.0657,  ..., 0.1056, 0.1045, 0.0000],\n",
      "        ...,\n",
      "        [0.0867, 0.0871, 0.0873,  ..., 0.0809, 0.0800, 0.0000],\n",
      "        [0.0849, 0.0862, 0.0872,  ..., 0.0584, 0.0571, 0.0000],\n",
      "        [0.0775, 0.0788, 0.0797,  ..., 0.0940, 0.0920, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9116,  0.3376,  0.5388,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6833, -0.2120,  0.6450,  ...,     nan,     nan,     nan],\n",
      "        [-0.1425,  0.5621,  0.5891,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7567,  0.2367, -0.1853,  ...,     nan,     nan,     nan],\n",
      "        [-0.7033,  0.1264, -0.5949,  ...,     nan,     nan,     nan],\n",
      "        [ 0.6659,  0.0839,  0.1353,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1257, 0.1269, 0.1276,  ..., 0.0778, 0.0770, 0.0000],\n",
      "        [0.0824, 0.0836, 0.0844,  ..., 0.0576, 0.0565, 0.0000],\n",
      "        [0.0459, 0.0466, 0.0471,  ..., 0.0658, 0.0645, 0.0000],\n",
      "        ...,\n",
      "        [0.0911, 0.0923, 0.0931,  ..., 0.0526, 0.0516, 0.0000],\n",
      "        [0.0878, 0.0889, 0.0896,  ..., 0.0599, 0.0586, 0.0000],\n",
      "        [0.0786, 0.0795, 0.0802,  ..., 0.0872, 0.0865, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8914,  0.0736, -0.9135,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3107, -0.3438,  0.0543,  ...,     nan,     nan,     nan],\n",
      "        [-0.4434,  0.6512, -0.4863,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1967,  0.4822, -0.9180,  ...,     nan,     nan,     nan],\n",
      "        [-0.8932, -0.5494,  0.3739,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7415,  0.5612,  0.0676,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0407, 0.0411, 0.0414,  ..., 0.0726, 0.0713, 0.0000],\n",
      "        [0.0815, 0.0821, 0.0825,  ..., 0.1066, 0.1056, 0.0000],\n",
      "        [0.1309, 0.1330, 0.1347,  ..., 0.0818, 0.0805, 0.0000],\n",
      "        ...,\n",
      "        [0.1344, 0.1358, 0.1368,  ..., 0.1510, 0.1498, 0.0000],\n",
      "        [0.1032, 0.1043, 0.1050,  ..., 0.0962, 0.0950, 0.0000],\n",
      "        [0.1018, 0.1029, 0.1037,  ..., 0.1076, 0.1064, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.9326,  0.1071,  0.0982,  ...,     nan,     nan,     nan],\n",
      "        [ 0.0948,  0.2179, -0.2485,  ...,     nan,     nan,     nan],\n",
      "        [-0.5034, -0.3872,  0.8333,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7307, -0.5039,  0.2193,  ...,     nan,     nan,     nan],\n",
      "        [-0.5877,  0.3484, -0.3140,  ...,     nan,     nan,     nan],\n",
      "        [-0.8356,  0.7331,  0.7799,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0518, 0.0526, 0.0532,  ..., 0.0935, 0.0925, 0.0000],\n",
      "        [0.1293, 0.1309, 0.1322,  ..., 0.0543, 0.0532, 0.0000],\n",
      "        [0.0696, 0.0704, 0.0710,  ..., 0.0413, 0.0400, 0.0000],\n",
      "        ...,\n",
      "        [0.0438, 0.0445, 0.0451,  ..., 0.0719, 0.0706, 0.0000],\n",
      "        [0.1421, 0.1449, 0.1469,  ..., 0.1076, 0.1064, 0.0000],\n",
      "        [0.0851, 0.0860, 0.0867,  ..., 0.0948, 0.0933, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5829,  0.6126,  0.1224,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7192, -0.0234,  0.1823,  ...,     nan,     nan,     nan],\n",
      "        [-0.3196,  0.1085,  0.4432,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.0715,  0.4579, -0.4725,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5780,  0.1104, -0.5750,  ...,     nan,     nan,     nan],\n",
      "        [-0.7802, -0.1451, -0.5269,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1689, 0.1715, 0.1734,  ..., 0.0743, 0.0734, 0.0000],\n",
      "        [0.1280, 0.1289, 0.1295,  ..., 0.0825, 0.0813, 0.0000],\n",
      "        [0.1964, 0.1995, 0.2017,  ..., 0.1378, 0.1368, 0.0000],\n",
      "        ...,\n",
      "        [0.0686, 0.0691, 0.0695,  ..., 0.0553, 0.0543, 0.0000],\n",
      "        [0.1494, 0.1507, 0.1515,  ..., 0.1080, 0.1061, 0.0000],\n",
      "        [0.0493, 0.0498, 0.0501,  ..., 0.0560, 0.0547, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8127,  0.7043, -0.0648,  ...,     nan,     nan,     nan],\n",
      "        [-0.7128, -0.0364,  0.4927,  ...,     nan,     nan,     nan],\n",
      "        [-0.6748, -0.9283,  0.5936,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3229, -0.3975, -0.5457,  ...,     nan,     nan,     nan],\n",
      "        [-0.8252, -0.7430,  0.4937,  ...,     nan,     nan,     nan],\n",
      "        [-0.5650, -0.3323, -0.0460,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0457, 0.0461, 0.0463,  ..., 0.0716, 0.0704, 0.0000],\n",
      "        [0.0499, 0.0512, 0.0521,  ..., 0.1552, 0.1537, 0.0000],\n",
      "        [0.0752, 0.0760, 0.0765,  ..., 0.0644, 0.0635, 0.0000],\n",
      "        ...,\n",
      "        [0.1311, 0.1322, 0.1329,  ..., 0.0842, 0.0833, 0.0000],\n",
      "        [0.0752, 0.0760, 0.0765,  ..., 0.0594, 0.0582, 0.0000],\n",
      "        [0.2824, 0.2829, 0.2820,  ..., 0.1142, 0.1130, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5067, -0.2141, -0.5675,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7437,  0.3771,  0.2732,  ...,     nan,     nan,     nan],\n",
      "        [-0.7370, -0.3025,  0.3002,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6702,  0.2600,  0.5440,  ...,     nan,     nan,     nan],\n",
      "        [-0.1158,  0.0641,  0.4122,  ...,     nan,     nan,     nan],\n",
      "        [-0.5063,  0.0075,  0.3612,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2097, 0.2129, 0.2155,  ..., 0.0976, 0.0961, 0.0000],\n",
      "        [0.0292, 0.0296, 0.0299,  ..., 0.0670, 0.0663, 0.0000],\n",
      "        [0.0523, 0.0531, 0.0536,  ..., 0.0292, 0.0279, 0.0000],\n",
      "        ...,\n",
      "        [0.1180, 0.1193, 0.1203,  ..., 0.0662, 0.0650, 0.0000],\n",
      "        [0.0339, 0.0342, 0.0345,  ..., 0.0435, 0.0425, 0.0000],\n",
      "        [0.0381, 0.0391, 0.0398,  ..., 0.0840, 0.0824, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.2522,  0.1017,  0.4298,  ...,     nan,     nan,     nan],\n",
      "        [-0.7220, -0.4130,  0.5169,  ...,     nan,     nan,     nan],\n",
      "        [-0.8542, -0.3927, -0.3336,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3772, -0.4419,  0.0240,  ...,     nan,     nan,     nan],\n",
      "        [-0.7901,  0.2450, -0.2595,  ...,     nan,     nan,     nan],\n",
      "        [-0.1320, -0.5109, -0.8003,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1851, 0.1900, 0.1935,  ..., 0.2247, 0.2245, 0.0000],\n",
      "        [0.0410, 0.0419, 0.0427,  ..., 0.1117, 0.1108, 0.0000],\n",
      "        [0.0963, 0.0968, 0.0972,  ..., 0.0794, 0.0780, 0.0000],\n",
      "        ...,\n",
      "        [0.0640, 0.0647, 0.0651,  ..., 0.1024, 0.1012, 0.0000],\n",
      "        [0.2328, 0.2359, 0.2380,  ..., 0.1755, 0.1735, 0.0000],\n",
      "        [0.0748, 0.0757, 0.0763,  ..., 0.0446, 0.0438, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.2576, -0.4642,  0.3099,  ...,     nan,     nan,     nan],\n",
      "        [-0.7734, -0.6493,  0.7797,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5603, -0.1131, -0.3713,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.3967, -0.2595,  0.0294,  ...,     nan,     nan,     nan],\n",
      "        [-0.8483,  0.7139,  0.5323,  ...,     nan,     nan,     nan],\n",
      "        [-0.2758, -0.5943, -0.1107,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0713, 0.0717, 0.0719,  ..., 0.0879, 0.0868, 0.0000],\n",
      "        [0.0880, 0.0889, 0.0896,  ..., 0.0671, 0.0661, 0.0000],\n",
      "        [0.1008, 0.1018, 0.1025,  ..., 0.1590, 0.1574, 0.0000],\n",
      "        ...,\n",
      "        [0.0593, 0.0598, 0.0601,  ..., 0.0716, 0.0706, 0.0000],\n",
      "        [0.0898, 0.0907, 0.0912,  ..., 0.0820, 0.0808, 0.0000],\n",
      "        [0.0727, 0.0735, 0.0740,  ..., 0.1103, 0.1090, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3557, -0.6170,  0.6489,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3521, -0.0464,  0.3505,  ...,     nan,     nan,     nan],\n",
      "        [-0.6588, -0.2488,  0.7750,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8223,  0.2581, -0.5237,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7087, -0.0952,  0.0472,  ...,     nan,     nan,     nan],\n",
      "        [-0.5398,  0.6079,  0.4756,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0818, 0.0824, 0.0829,  ..., 0.0735, 0.0724, 0.0000],\n",
      "        [0.1419, 0.1426, 0.1427,  ..., 0.1239, 0.1233, 0.0000],\n",
      "        [0.0944, 0.0959, 0.0969,  ..., 0.0907, 0.0893, 0.0000],\n",
      "        ...,\n",
      "        [0.0772, 0.0774, 0.0774,  ..., 0.0781, 0.0768, 0.0000],\n",
      "        [0.1275, 0.1276, 0.1274,  ..., 0.1277, 0.1258, 0.0000],\n",
      "        [0.1087, 0.1095, 0.1097,  ..., 0.1392, 0.1381, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7741, -0.0661,  0.1453,  ...,     nan,     nan,     nan],\n",
      "        [-0.7503, -0.2131, -0.7845,  ...,     nan,     nan,     nan],\n",
      "        [-0.8753,  0.0141,  0.0908,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5392,  0.1444,  0.0215,  ...,     nan,     nan,     nan],\n",
      "        [-0.2175, -0.3570, -0.2779,  ...,     nan,     nan,     nan],\n",
      "        [-0.3225, -0.3000,  0.5123,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1098, 0.1112, 0.1123,  ..., 0.1473, 0.1464, 0.0000],\n",
      "        [0.1240, 0.1244, 0.1244,  ..., 0.0880, 0.0863, 0.0000],\n",
      "        [0.1186, 0.1197, 0.1205,  ..., 0.0901, 0.0891, 0.0000],\n",
      "        ...,\n",
      "        [0.0528, 0.0533, 0.0537,  ..., 0.0498, 0.0490, 0.0000],\n",
      "        [0.0720, 0.0725, 0.0728,  ..., 0.0959, 0.0946, 0.0000],\n",
      "        [0.0664, 0.0667, 0.0670,  ..., 0.0552, 0.0541, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8208,  0.0028, -0.2497,  ...,     nan,     nan,     nan],\n",
      "        [-0.7205,  0.6408,  0.2833,  ...,     nan,     nan,     nan],\n",
      "        [-0.5201, -0.4466,  0.0202,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3836,  0.1061,  0.4113,  ...,     nan,     nan,     nan],\n",
      "        [-0.3487, -0.2732,  0.2915,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4568,  0.2239,  0.2576,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1514, 0.1528, 0.1539,  ..., 0.1277, 0.1268, 0.0000],\n",
      "        [0.1124, 0.1135, 0.1142,  ..., 0.0754, 0.0746, 0.0000],\n",
      "        [0.0612, 0.0619, 0.0624,  ..., 0.0612, 0.0600, 0.0000],\n",
      "        ...,\n",
      "        [0.0430, 0.0435, 0.0437,  ..., 0.0461, 0.0451, 0.0000],\n",
      "        [0.0782, 0.0792, 0.0800,  ..., 0.0480, 0.0473, 0.0000],\n",
      "        [0.0821, 0.0830, 0.0836,  ..., 0.0841, 0.0832, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7265, -0.6847, -0.6483,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3188, -0.2111, -0.3632,  ...,     nan,     nan,     nan],\n",
      "        [-0.8529, -0.1043,  0.4932,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.2174,  0.7905, -0.2185,  ...,     nan,     nan,     nan],\n",
      "        [-0.7632, -0.2033, -0.0358,  ...,     nan,     nan,     nan],\n",
      "        [-0.6494, -0.1482, -0.3974,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0509, 0.0514, 0.0517,  ..., 0.1137, 0.1113, 0.0000],\n",
      "        [0.0712, 0.0718, 0.0721,  ..., 0.0798, 0.0788, 0.0000],\n",
      "        [0.0851, 0.0861, 0.0869,  ..., 0.0977, 0.0964, 0.0000],\n",
      "        ...,\n",
      "        [0.0717, 0.0732, 0.0743,  ..., 0.1025, 0.1014, 0.0000],\n",
      "        [0.1194, 0.1208, 0.1219,  ..., 0.0966, 0.0951, 0.0000],\n",
      "        [0.0933, 0.0943, 0.0949,  ..., 0.0882, 0.0871, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6922, -0.7672, -0.3086,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3818,  0.2526,  0.1036,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8304,  0.2477,  0.5953,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.1240,  0.0362, -0.0848,  ...,     nan,     nan,     nan],\n",
      "        [-0.2940,  0.6690, -0.1379,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9749,  0.1259, -0.5591,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0413, 0.0417, 0.0420,  ..., 0.0666, 0.0656, 0.0000],\n",
      "        [0.0905, 0.0912, 0.0916,  ..., 0.0969, 0.0960, 0.0000],\n",
      "        [0.0899, 0.0908, 0.0915,  ..., 0.0702, 0.0691, 0.0000],\n",
      "        ...,\n",
      "        [0.1272, 0.1287, 0.1299,  ..., 0.0579, 0.0571, 0.0000],\n",
      "        [0.0841, 0.0851, 0.0857,  ..., 0.0916, 0.0903, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110,  ..., 0.1435, 0.1434, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8352, -0.4281,  0.4345,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5435, -0.0242, -0.3524,  ...,     nan,     nan,     nan],\n",
      "        [-0.2659, -0.7944,  0.2951,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.5022, -0.1849,  0.1372,  ...,     nan,     nan,     nan],\n",
      "        [-0.4519, -0.6053, -0.6075,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2276,  0.1996, -0.0515,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0881, 0.0892, 0.0900,  ..., 0.0606, 0.0597, 0.0000],\n",
      "        [0.0551, 0.0557, 0.0561,  ..., 0.1052, 0.1042, 0.0000],\n",
      "        [0.1440, 0.1459, 0.1471,  ..., 0.0860, 0.0850, 0.0000],\n",
      "        ...,\n",
      "        [0.1238, 0.1250, 0.1259,  ..., 0.0625, 0.0612, 0.0000],\n",
      "        [0.0490, 0.0495, 0.0498,  ..., 0.0992, 0.0983, 0.0000],\n",
      "        [0.0545, 0.0549, 0.0550,  ..., 0.0891, 0.0876, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8915,  0.1113,  0.5527,  ...,     nan,     nan,     nan],\n",
      "        [-0.6429,  0.5584,  0.2824,  ...,     nan,     nan,     nan],\n",
      "        [-0.7125, -0.0214, -0.4569,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.7700, -0.1172,  0.0923,  ...,     nan,     nan,     nan],\n",
      "        [-0.6584,  0.0851, -0.3537,  ...,     nan,     nan,     nan],\n",
      "        [-0.4885, -0.0354,  0.3131,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1286, 0.1295, 0.1299,  ..., 0.0909, 0.0892, 0.0000],\n",
      "        [0.0885, 0.0892, 0.0896,  ..., 0.0786, 0.0771, 0.0000],\n",
      "        [0.0995, 0.1002, 0.1005,  ..., 0.0665, 0.0654, 0.0000],\n",
      "        ...,\n",
      "        [0.0851, 0.0859, 0.0864,  ..., 0.0855, 0.0840, 0.0000],\n",
      "        [0.1155, 0.1168, 0.1178,  ..., 0.0784, 0.0767, 0.0000],\n",
      "        [0.1037, 0.1052, 0.1063,  ..., 0.0899, 0.0885, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4904,  0.7525, -0.1797,  ...,     nan,     nan,     nan],\n",
      "        [-0.3621,  0.0231, -0.3630,  ...,     nan,     nan,     nan],\n",
      "        [-0.4314, -0.1639,  0.1700,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8003, -0.6303,  0.0526,  ...,     nan,     nan,     nan],\n",
      "        [-0.7492,  0.2182,  0.0403,  ...,     nan,     nan,     nan],\n",
      "        [-0.8780, -0.3239, -0.2386,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0700, 0.0711, 0.0719,  ..., 0.0983, 0.0975, 0.0000],\n",
      "        [0.0660, 0.0665, 0.0668,  ..., 0.0752, 0.0742, 0.0000],\n",
      "        [0.1062, 0.1076, 0.1085,  ..., 0.0748, 0.0739, 0.0000],\n",
      "        ...,\n",
      "        [0.0816, 0.0824, 0.0830,  ..., 0.0859, 0.0850, 0.0000],\n",
      "        [0.1109, 0.1120, 0.1127,  ..., 0.1111, 0.1096, 0.0000],\n",
      "        [0.1522, 0.1537, 0.1546,  ..., 0.1468, 0.1454, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6938,  0.2919,  0.3668,  ...,     nan,     nan,     nan],\n",
      "        [-0.7624, -0.0094,  0.7219,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2819, -0.3315, -0.3829,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6275,  0.3054, -0.3342,  ...,     nan,     nan,     nan],\n",
      "        [-0.9135, -0.3861,  0.2307,  ...,     nan,     nan,     nan],\n",
      "        [-0.1795, -0.7687,  0.0754,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0720, 0.0725, 0.0729,  ..., 0.0802, 0.0790, 0.0000],\n",
      "        [0.0209, 0.0213, 0.0216,  ..., 0.1105, 0.1091, 0.0000],\n",
      "        [0.1727, 0.1743, 0.1755,  ..., 0.1212, 0.1198, 0.0000],\n",
      "        ...,\n",
      "        [0.1560, 0.1566, 0.1567,  ..., 0.1053, 0.1040, 0.0000],\n",
      "        [0.0913, 0.0922, 0.0929,  ..., 0.1312, 0.1298, 0.0000],\n",
      "        [0.0750, 0.0763, 0.0772,  ..., 0.0548, 0.0536, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8791,  0.0286, -0.3715,  ...,     nan,     nan,     nan],\n",
      "        [-0.1888,  0.4664,  0.2245,  ...,     nan,     nan,     nan],\n",
      "        [-0.6258,  0.0145,  0.1337,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.2558,  0.6466,  0.4069,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3785,  0.3069, -0.2000,  ...,     nan,     nan,     nan],\n",
      "        [-0.9484, -0.3131,  0.6400,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.2670, 0.2707, 0.2735,  ..., 0.1185, 0.1166, 0.0000],\n",
      "        [0.2692, 0.2718, 0.2734,  ..., 0.0873, 0.0863, 0.0000],\n",
      "        [0.0614, 0.0621, 0.0625,  ..., 0.0642, 0.0632, 0.0000],\n",
      "        ...,\n",
      "        [0.0484, 0.0489, 0.0493,  ..., 0.0962, 0.0950, 0.0000],\n",
      "        [0.3741, 0.3778, 0.3801,  ..., 0.4853, 0.4849, 0.0000],\n",
      "        [0.1288, 0.1299, 0.1306,  ..., 0.0891, 0.0874, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6384, -0.0938,  0.2929,  ...,     nan,     nan,     nan],\n",
      "        [-0.8872,  0.3790,  0.2455,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2666,  0.1677, -0.5166,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1505, -0.4562,  0.6160,  ...,     nan,     nan,     nan],\n",
      "        [-0.0576, -0.6205, -0.3033,  ...,     nan,     nan,     nan],\n",
      "        [-0.5439, -0.0479,  0.4732,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0874, 0.0879, 0.0880,  ..., 0.0834, 0.0824, 0.0000],\n",
      "        [0.0671, 0.0678, 0.0683,  ..., 0.0937, 0.0925, 0.0000],\n",
      "        [0.1361, 0.1380, 0.1392,  ..., 0.1122, 0.1102, 0.0000],\n",
      "        ...,\n",
      "        [0.0944, 0.0952, 0.0958,  ..., 0.0737, 0.0726, 0.0000],\n",
      "        [0.0661, 0.0677, 0.0688,  ..., 0.0704, 0.0694, 0.0000],\n",
      "        [0.0563, 0.0581, 0.0594,  ..., 0.1101, 0.1081, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0103,  0.8132, -0.3955,  ...,     nan,     nan,     nan],\n",
      "        [-0.3441, -0.2672,  0.1313,  ...,     nan,     nan,     nan],\n",
      "        [-0.6431, -0.3051,  0.2407,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.0855, -0.3604,  0.2087,  ...,     nan,     nan,     nan],\n",
      "        [-0.2312,  0.3234,  0.3484,  ...,     nan,     nan,     nan],\n",
      "        [-0.8137, -0.2417,  0.1989,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1752, 0.1769, 0.1780,  ..., 0.1250, 0.1240, 0.0000],\n",
      "        [0.0898, 0.0910, 0.0918,  ..., 0.0783, 0.0769, 0.0000],\n",
      "        [0.0275, 0.0276, 0.0276,  ..., 0.0867, 0.0858, 0.0000],\n",
      "        ...,\n",
      "        [0.0710, 0.0721, 0.0730,  ..., 0.0856, 0.0847, 0.0000],\n",
      "        [0.1013, 0.1025, 0.1034,  ..., 0.1056, 0.1047, 0.0000],\n",
      "        [0.0636, 0.0643, 0.0648,  ..., 0.1022, 0.1012, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7936, -0.4251,  0.6112,  ...,     nan,     nan,     nan],\n",
      "        [-0.5305, -0.5074, -0.4253,  ...,     nan,     nan,     nan],\n",
      "        [ 0.2041,  0.6000,  0.6707,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.1833, -0.2917, -0.7034,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8148, -0.2727, -0.6537,  ...,     nan,     nan,     nan],\n",
      "        [-0.7207, -0.2411,  0.1604,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1139, 0.1153, 0.1164,  ..., 0.0864, 0.0855, 0.0000],\n",
      "        [0.0899, 0.0909, 0.0915,  ..., 0.1235, 0.1219, 0.0000],\n",
      "        [0.0471, 0.0479, 0.0485,  ..., 0.1367, 0.1356, 0.0000],\n",
      "        ...,\n",
      "        [0.0590, 0.0596, 0.0600,  ..., 0.0845, 0.0836, 0.0000],\n",
      "        [0.0467, 0.0471, 0.0473,  ..., 0.0989, 0.0974, 0.0000],\n",
      "        [0.2333, 0.2363, 0.2386,  ..., 0.0847, 0.0837, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.6409,  0.1009, -0.1742,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5945, -0.1125, -0.3565,  ...,     nan,     nan,     nan],\n",
      "        [-0.4974, -0.6602,  0.3645,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.3563, -0.4087,  0.3549,  ...,     nan,     nan,     nan],\n",
      "        [-0.8178, -0.5427,  0.5223,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4781,  0.1669, -0.6793,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0770, 0.0778, 0.0782,  ..., 0.1063, 0.1047, 0.0000],\n",
      "        [0.1693, 0.1710, 0.1721,  ..., 0.1607, 0.1589, 0.0000],\n",
      "        [0.1241, 0.1252, 0.1258,  ..., 0.0742, 0.0728, 0.0000],\n",
      "        ...,\n",
      "        [0.0678, 0.0688, 0.0696,  ..., 0.0548, 0.0539, 0.0000],\n",
      "        [0.0612, 0.0619, 0.0623,  ..., 0.1056, 0.1048, 0.0000],\n",
      "        [0.2815, 0.2863, 0.2898,  ..., 0.0993, 0.0980, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.2004,  0.7447, -0.0383,  ...,     nan,     nan,     nan],\n",
      "        [ 0.3006, -0.5093, -0.0092,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9099,  0.1259,  0.6427,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7720, -0.5634,  0.7686,  ...,     nan,     nan,     nan],\n",
      "        [-0.5687, -0.3431, -0.0712,  ...,     nan,     nan,     nan],\n",
      "        [ 0.5499, -0.6223, -0.0046,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1070, 0.1083, 0.1090,  ..., 0.0550, 0.0543, 0.0000],\n",
      "        [0.0724, 0.0735, 0.0743,  ..., 0.0872, 0.0861, 0.0000],\n",
      "        [0.0808, 0.0820, 0.0829,  ..., 0.0660, 0.0650, 0.0000],\n",
      "        ...,\n",
      "        [0.1370, 0.1381, 0.1387,  ..., 0.1257, 0.1246, 0.0000],\n",
      "        [0.1065, 0.1072, 0.1075,  ..., 0.0749, 0.0735, 0.0000],\n",
      "        [0.1143, 0.1153, 0.1158,  ..., 0.1054, 0.1043, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4242, -0.4095,  0.6297,  ...,     nan,     nan,     nan],\n",
      "        [ 0.4038,  0.2074,  0.2592,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9690, -0.1480, -0.2333,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.6188,  0.7446,  0.0522,  ...,     nan,     nan,     nan],\n",
      "        [ 0.8793,  0.5296,  0.3574,  ...,     nan,     nan,     nan],\n",
      "        [-0.8215, -0.2070,  0.5956,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0856, 0.0864, 0.0870,  ..., 0.0733, 0.0724, 0.0000],\n",
      "        [0.1154, 0.1163, 0.1171,  ..., 0.1152, 0.1143, 0.0000],\n",
      "        [0.0726, 0.0732, 0.0735,  ..., 0.0896, 0.0889, 0.0000],\n",
      "        ...,\n",
      "        [0.0407, 0.0413, 0.0417,  ..., 0.0580, 0.0573, 0.0000],\n",
      "        [0.0745, 0.0754, 0.0761,  ..., 0.0705, 0.0696, 0.0000],\n",
      "        [0.3178, 0.3212, 0.3236,  ..., 0.1395, 0.1379, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.7628,  0.0633, -0.5914,  ...,     nan,     nan,     nan],\n",
      "        [-0.8257,  0.0682, -0.4348,  ...,     nan,     nan,     nan],\n",
      "        [-0.3306, -0.4243, -0.1693,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.5324,  0.2686,  0.4914,  ...,     nan,     nan,     nan],\n",
      "        [-0.5419, -0.4378, -0.0759,  ...,     nan,     nan,     nan],\n",
      "        [-0.3628,  0.8147,  0.5496,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1601, 0.1620, 0.1633,  ..., 0.0819, 0.0809, 0.0000],\n",
      "        [0.1066, 0.1079, 0.1088,  ..., 0.1208, 0.1192, 0.0000],\n",
      "        [0.0888, 0.0898, 0.0905,  ..., 0.0677, 0.0668, 0.0000],\n",
      "        ...,\n",
      "        [0.1020, 0.1028, 0.1034,  ..., 0.0617, 0.0605, 0.0000],\n",
      "        [0.1425, 0.1436, 0.1443,  ..., 0.1199, 0.1184, 0.0000],\n",
      "        [0.1991, 0.2017, 0.2033,  ..., 0.1215, 0.1202, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.4880, -0.6633,  0.5286,  ...,     nan,     nan,     nan],\n",
      "        [-0.6835, -0.2441,  0.1184,  ...,     nan,     nan,     nan],\n",
      "        [-0.1617,  0.2817,  0.1966,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.1678,  0.3027,  0.2204,  ...,     nan,     nan,     nan],\n",
      "        [-0.6620,  0.0067,  0.3600,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9364,  0.0229,  0.3415,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0910, 0.0929, 0.0943,  ..., 0.1485, 0.1475, 0.0000],\n",
      "        [0.1822, 0.1849, 0.1867,  ..., 0.0869, 0.0858, 0.0000],\n",
      "        [0.2039, 0.2061, 0.2077,  ..., 0.1881, 0.1866, 0.0000],\n",
      "        ...,\n",
      "        [0.0627, 0.0635, 0.0641,  ..., 0.0874, 0.0862, 0.0000],\n",
      "        [0.2160, 0.2184, 0.2196,  ..., 0.0812, 0.0802, 0.0000],\n",
      "        [0.0904, 0.0914, 0.0920,  ..., 0.0663, 0.0653, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8030,  0.2719, -0.9176,  ...,     nan,     nan,     nan],\n",
      "        [-0.5037, -0.2268, -0.3718,  ...,     nan,     nan,     nan],\n",
      "        [ 0.1424, -0.1843, -0.1290,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.7679,  0.4561,  0.2305,  ...,     nan,     nan,     nan],\n",
      "        [ 0.9820, -0.2889,  0.7796,  ...,     nan,     nan,     nan],\n",
      "        [-0.4147,  0.3819,  0.6306,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1304, 0.1323, 0.1336,  ..., 0.1723, 0.1703, 0.0000],\n",
      "        [0.1225, 0.1237, 0.1247,  ..., 0.0538, 0.0527, 0.0000],\n",
      "        [0.0325, 0.0331, 0.0336,  ..., 0.0572, 0.0560, 0.0000],\n",
      "        ...,\n",
      "        [0.0865, 0.0876, 0.0884,  ..., 0.1090, 0.1083, 0.0000],\n",
      "        [0.0891, 0.0900, 0.0905,  ..., 0.0549, 0.0539, 0.0000],\n",
      "        [0.0835, 0.0840, 0.0843,  ..., 0.0752, 0.0742, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.8570,  0.0712, -0.0951,  ...,     nan,     nan,     nan],\n",
      "        [-0.4168,  0.2473, -0.0709,  ...,     nan,     nan,     nan],\n",
      "        [-0.9282, -0.3107,  0.3161,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [-0.8639,  0.5171,  0.6812,  ...,     nan,     nan,     nan],\n",
      "        [-0.3717, -0.5873, -0.2902,  ...,     nan,     nan,     nan],\n",
      "        [ 0.7157,  0.4263,  0.0233,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.0581, 0.0592, 0.0599,  ..., 0.0787, 0.0775, 0.0000],\n",
      "        [0.0324, 0.0329, 0.0332,  ..., 0.0815, 0.0805, 0.0000],\n",
      "        [0.0996, 0.1010, 0.1021,  ..., 0.0930, 0.0922, 0.0000],\n",
      "        ...,\n",
      "        [0.1096, 0.1106, 0.1113,  ..., 0.1068, 0.1056, 0.0000],\n",
      "        [0.1560, 0.1570, 0.1577,  ..., 0.0955, 0.0941, 0.0000],\n",
      "        [0.0154, 0.0159, 0.0162,  ..., 0.1181, 0.1173, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7355, -0.0294, -0.0431,  ...,     nan,     nan,     nan],\n",
      "        [-0.1529, -0.1135, -0.3279,  ...,     nan,     nan,     nan],\n",
      "        [-0.4670,  0.0061, -0.2461,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.3348, -0.0683,  0.0777,  ...,     nan,     nan,     nan],\n",
      "        [-0.7632, -0.0064, -0.4934,  ...,     nan,     nan,     nan],\n",
      "        [-0.7845, -0.2818,  0.2909,  ...,     nan,     nan,     nan]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[0.1592, 0.1605, 0.1612,  ..., 0.1129, 0.1116, 0.0000],\n",
      "        [0.1632, 0.1657, 0.1675,  ..., 0.0831, 0.0819, 0.0000],\n",
      "        [0.1166, 0.1180, 0.1191,  ..., 0.0634, 0.0623, 0.0000],\n",
      "        ...,\n",
      "        [0.0570, 0.0577, 0.0581,  ..., 0.1023, 0.1011, 0.0000],\n",
      "        [0.0687, 0.0694, 0.0698,  ..., 0.0728, 0.0717, 0.0000],\n",
      "        [0.1401, 0.1416, 0.1427,  ..., 0.0870, 0.0859, 0.0000]])\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-1014d89ef577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf110/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# RealNVP model (unchanged from what you wrote)\n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        hidden = 512\n",
    "        self.scale = nn.Sequential(\n",
    "            nn.Linear(dim // 2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, dim // 2),\n",
    "            nn.ReLU()\n",
    "            #nn.Tanh()\n",
    "        )\n",
    "        self.translate = nn.Sequential(\n",
    "            nn.Linear(dim // 2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, dim // 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x, reverse=False):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        s, t = self.scale(x1), self.translate(x1)\n",
    "        y2 = x2 * torch.exp(s) + t if not reverse else (x2 - t) * torch.exp(-s)\n",
    "        return torch.cat([x1, y2], dim=1)\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, dim, num_layers=3):  #  only 3 layers\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([CouplingLayer(dim) for _ in range(num_layers)])\n",
    "    def forward(self, x, reverse=False):\n",
    "        for layer in (self.layers if not reverse else reversed(self.layers)):\n",
    "            x = layer(x, reverse=reverse)\n",
    "        return x\n",
    "\n",
    "# Instantiate with 3 layers\n",
    "input_dim = 1802\n",
    "model = RealNVP(dim=input_dim, num_layers=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = SIDLoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch[:, :1802]\n",
    "        y_batch = batch[:, 1802:]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        #loss = loss_fn(y_pred[:, 800:], y_batch[:, 800:])\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        print(y_pred)\n",
    "        print(y_batch)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    train_losses.append(total_loss)\n",
    "\n",
    "    # Eval on val and test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_loader:\n",
    "            x_batch = batch[:, :1802]\n",
    "            y_batch = batch[:, 1802:]\n",
    "            y_pred = model(x_batch)\n",
    "            val_loss += loss_fn(y_pred[:, 800:], y_batch[:, 800:]).item()\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        test_loss = 0\n",
    "        for batch in test_loader:\n",
    "            x_batch = batch[:, :1802]\n",
    "            y_batch = batch[:, 1802:]\n",
    "            y_pred = model(x_batch)\n",
    "            test_loss += loss_fn(y_pred[:, 800:], y_batch[:, 800:]).item()\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}, Val Loss = {val_loss:.4f}, Test Loss = {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1802\n",
    "model = RealNVP(dim=input_dim, num_layers=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = SIDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6505e-05, 8.1909e-05, 6.1232e-05,  ..., 2.8554e-02, 3.7877e-02,\n",
       "         7.7821e-03],\n",
       "        [4.7800e-05, 3.7571e-05, 1.8801e-05,  ..., 2.8569e-02, 3.7874e-02,\n",
       "         7.7865e-03],\n",
       "        [2.5125e-05, 6.3787e-05, 4.0418e-05,  ..., 2.8524e-02, 3.7803e-02,\n",
       "         7.7103e-03],\n",
       "        ...,\n",
       "        [6.6687e-05, 5.6700e-05, 8.4251e-05,  ..., 2.8569e-02, 3.7921e-02,\n",
       "         7.7148e-03],\n",
       "        [9.0995e-05, 5.4451e-05, 9.9603e-05,  ..., 2.8514e-02, 3.8144e-02,\n",
       "         7.7443e-03],\n",
       "        [6.6049e-05, 2.5114e-05, 3.3071e-05,  ..., 2.8600e-02, 3.8140e-02,\n",
       "         7.7509e-03]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = torch.rand((32,1802))\n",
    "s1 = s1/10000\n",
    "model(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.plot(test_losses, label=\"Test\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot predicted vs true spectrum\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
    "\n",
    "idx = 0\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(Y_test[idx], label=\"True Spectrum\")\n",
    "plt.plot(y_pred_test[idx], label=\"Predicted Spectrum\")\n",
    "plt.title(\"SMILES  Spectra Prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
